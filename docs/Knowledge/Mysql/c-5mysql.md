### 1、一条SQL语句引发的思考
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220101171608.png)

创建了一张数据库表，表里的字段只有主键索引（id）和联合索引（a，b，c），然后执行 select * from t where c = 0; 这条语句发现走的是索引，困惑有两点：

- 第一点，where c 这个条件并不符合联合索引的最左匹配原则，怎么就查询的时候走了索引呢？

- 第二点，在这个数据表加了非索引字段，执行同样的查询语句后，怎么变成走的是全表扫描呢？

tips：最左匹配原则？

这个数据库表创建了（a，b，c）这个联合索引，要能使其生效必须保证 where 条件里最左边是 a 字段，比如以下这几种情况：

where a = 0;

where a = 0 and b = 0;

where a = 0 and c = 0;

where a = 0 and b = 0 and c = 0;

where a = 0 and c = 0 and b = 0;


而如果 where 条件里最左边的字段不是 a 时，就无法使用到联合索引，比如以下这种情况，就是不符合最左匹配规则：

where b = 0;

where c = 0;

where b = 0 and c =0;

where c = 0 and b = 0;


知道了联合索引的最左匹配原则后，再来看看第一个问题。

为什么  select * from t where c = 0; 这条不符合联合索引的最左匹配原则的查询语句走了索引查询呢？



首先，这张表的字段没有「非索引」字段，所以 select * 相当于 select id,a,b,c，然后这个查询的内容和条件 都在联合索引树里，因为联合索引树的叶子节点包含「索引列+主键」，所以查联合索引树就能查到全部结果了，这个就是覆盖索引。


但是执行计划里的 type 是 index，这代表着是通过全扫描联合索引树的方式查询到数据的，这是因为 where c 并不符合联合索引最左匹配原则。


那么，如果写了个符合最左原则的 select 语句，那么 type 就是 ref，这个效率就比 index 全扫描要高一些。


那为什么选择全扫描联合索引树，而不扫描全表（聚集索引树）呢？

因为联合索引树的记录比要小的多，而且这个 select * 不用执行回表操作，所以直接遍历联合索引树要比遍历聚集索引树要小的多，因此 MySQL 选择了全扫描联合索引树。



为什么这个数据表加了非索引字段，执行同样的查询语句后，怎么变成走的是全表扫描呢？

因为加了其他字段后，select * from t where c = 0; 查询的内容就不能在联合索引树里找到了，而且条件也不符合最左匹配原则，这样既不能覆盖索引也不能执行回表操作，所以这时只能通过扫描全表来查询到所有的数据。


cookies:
- 覆盖索引：我们把这种索引中已经包含所有需要读取的列的查询方式称为**覆盖索引。**


- 联合索引指的是索引组织的类型；

- 覆盖索引可以看作是联合索引的最优解，某种意义上可以看成包含的列“最全“。


### 2、索引为什么能提高查询性能-多叉树之 B+tree

做为数据库的索引，无论用什么样的数据结构维护，这些数据最终都会存储到磁盘中。

鉴于磁盘  I/O 的性能问题，以及每次 I/O 获取数据量上限所限，提高索引本身 I/O 的方法最好是，减少 I/O 次数和每次获取有用的数据。

B-tree 已经大大改进了树家族的性能，它把多个数据集中存储在一个节点中，本身就可能减少了 I/O 次数或者寻道次数。

但是仍然有一个致命的缺陷，那就是它的索引数据与业务绑定在一块，而业务数据的大小很有可能远远超过了索引数据，这会大大减小一次 I/O 有用数据的获取，间接的增加 I/O 次数去获取有用的索引数据。

因为业务数据才是我们查询最终的目的，但是它又是在「二分」查找中途过程无用的数据，因此，如果只把业务数据存储在最终查询到的那个节点是不是就可以了？

理想很丰满，现实很骨瘦如柴，谁知道哪个节点就是最终要查询的节点呢？

B+tree 横空出世，B+ 树就是为了拆分索引数据与业务数据的平衡多叉树。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220101195120.png)


B+ 树中，非叶子节点只保存索引数据，叶子节点保存索引数据与业务数据。这样即保证了叶子节点的简约干净，数据量大大减小，又保证了最终能查到对应的业务数据。既提高了单次 I/O 数据的有效性，又减少了 I/O 次数，还实现了业务。

但是，在数据中索引与数据是分离的，不像示例那样的？

如图：我们只需要把真实的业务数据，换成数据所在地址就可以了，此时，业务数据所在的地址在 B+ 树中充当业务数据

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220101204611.png)

# 总结：

- 数据存储在磁盘（ SSD 跟 CPU 性能也不在一个量级），而磁盘处理数据很慢；

- 提高磁盘性能主要通过减少 I/O 次数，以及单次 I/O 有效数据量；

- 索引通过多阶（一个节点保存多个数据，指向多个子节点）使树的结构更矮胖，从而减少 I/O 次数；

- 索引通过 B+ 树，把业务数据与索引数据分离，来提高单次 I/O 有效数据量，从而减少 I/O 次数；

- 索引通过树数据的有序和「二分查找」（多阶树可以假设为多分查找），大大缩小查询范围；

- 索引针对的是单个字段或部分字段，数据量本身比一条记录的数据量要少的多，这样即使通过扫描的方式查询索引也比扫描数据库表本身快的多；



### 3、图解Mysql事务

众所周知，转账会涉及到一系列操作，假如我向你转账100万的过程是由下面这几个步骤组成的：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102111939.jpg)

可以看到这个转账的过程涉及到了两次修改数据库的操作。

假设在执行第三步骤之后，服务器忽然掉电了，就会发生一个蛋疼的事情，我的账户扣了 100 万，但是钱并没有到你的账户上，也就是说这 100 万消失了！

要解决这个问题，就要保证转账业务里的所有数据库的操作是不可分割的，要么全部执行成功 ，要么全部失败，不允许出现中间状态的数据。

数据库中的「**事务（Transaction）**」就能达到这样的效果，我们在转账操作前先开启事务，等所有数据库操作执行完成后，才提交事务，对于已经提交的事务来说，该事务对数据库所做的修改将永久生效，如果中途发生发生中断或错误，那么该事务期间对数据库所做的修改将会被回滚到没执行该事务之前的状态。

接下来就开始图解事务啦！！！

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102112510.png)

#### 3.1 事务有哪些特性？
事务是由 MySQL 的引擎来实现的，我们常见的 InnoDB 引擎它是支持事务的。
实现事务必须要遵守4个特性：

- 原子性（Atomicity）：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样；

- 一致性（Consistency）：数据库的完整性不会因为事务的执行而受到破坏，比如表中有一个字段为姓名，它有唯一约束，也就是表中姓名不能重复，如果一个事务对姓名字段进行了修改，但是在事务提交后，表中的姓名变得非唯一性了，这就破坏了事务的一致性要求，这时数据库就要撤销该事务，返回初始化的状态。

- 隔离性（Isolation）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。

- 持久性（Durability）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。


InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？

- 原子性和持久性是通过 redo log （重做日志）来保证的；

- 一致性是通过 undo log（回滚日志） 来保证的；

- **隔离性**是通过 MVCC（多版本并发控制） 或锁机制来保证的；


#### 3.2 并行事务会引发什么问题?

Mysql 服务端是允许多个客户端连接的，这意味着Mysql会出现同时处理多个事务的情况。

那么在同时处理多个事务的时候，就可能出现脏读，不可重复读，幻读的问题。

接下来，通过举例说明这些情况是如何发生的。

##### 脏读
如果一个事务读到了另一个未提交事务修改过的数据，就意味着发生了脏读现象。

举个栗子。

假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库中读取小林的余额数据，然后再执行更新操作，如果此时事务 A 还没有提交事务，而此时正好事务 B 也从数据库中读取小林的余额数据，那么事务 B 读取到的余额数据是刚才事务 A 更新后的数据，即使没有提交事务。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102112514.png)


因为事务 A 是还没提交事务的，也就是它随时可能发生回滚操作，**如果在上面这种情况事务 A 发生了回滚，那么事务 B 刚才得到的数据就是过期的数据，这种现象就被称为脏读。**

##### 不可重复读

在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。

举个栗子。

假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库中读取小林的余额数据，然后继续执行代码逻辑处理，在这过程中如果事务 B 更新了这条数据，并提交了事务，那么当事务 A 再次读取该数据时，就会发现前后两次读到的数据是不一致的，这种现象就被称为不可重复读。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102112517.png)


##### 幻读
在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。

举个栗子。

假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库查询账户余额大于 100 万的记录，发现共有 5 条，然后事务 B 也按相同的搜索条件也是查询出了 5 条记录。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102112522.png)

接下来，事务 A 插入了一条余额超过 100 万的账号，并提交了事务，此时数据库超过 100 万余额的账号个数就变为 6。
然后事务 B 再次查询账户余额大于 100 万的记录，此时查询到的记录数量有 6 条，发现和前一次读到的记录数量不一样了，就感觉发生了幻觉一样，这种现象就被称为幻读。

#### 3.3事务的隔离级别有哪些？


前面我们提到，当多个事务并发执行时可能会遇到「脏读、不可重复读、幻读」的现象，这些现象会对事务的一致性产生不同程度的影响。

- 脏读：读到其他事务未提交的数据；

- 不可重复读：前后读取的数据不一致； 

- 幻读：前后读取的记录数量不一致。

这三个现象的严重性排序如下：
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102112526.png)

SQL 标准提出了四种隔离级别来规避这些现象，隔离级别约高，性能效率就越低，这四个隔离级别如下：

- 读未提交（read uncommitted），指一个事务还没提交时，它做的变更就能被其他事务看到；

- 读提交（read committed），指一个事务提交之后，它做的变更才能被其他事务看到；

- 可重复读（repeatable read），指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别；

- 串行化（serializable ）；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；

按隔离水平高低排序如下：
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102112530.png)

针对不同的隔离级别，并发事务时可能发生的现象也会不同。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102112534.png)

所以，要解决脏读现象，就要升级到「读提交」以上的隔离级别；要解决不可重复读现象，就要升级到「可重复读」的隔离级别。


不过，要解决幻读现象不建议将隔离级别升级到「串行化」，因为这样会导致数据库在并发事务时性能很差。InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它通过next-key lock 锁（行锁和间隙锁的组合）来锁住记录之间的“间隙”和记录本身，防止其他事务在这个记录之间插入新的记录，这样就避免了幻读现象。



举个具体的例子来说明这四种隔离级别，有一张账户余额表，里面有一条记录：

然后有两个并发的事务，事务 A 只负责查询余额，事务 B 则会将我的余额改成 200 万，下面是按照时间顺序执行两个事务的行为：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102112537.png)


在不同隔离级别下，事务 A 执行过程中查询到的余额可能会不同：

- 在「读未提交」隔离级别下，事务 B 修改余额后，虽然没有提交事务，但是此时的余额已经可以被事务 A 看见了，于是事务 A 中余额 V1 查询的值是 200 万，余额 V2、V3 自然也是 200 万了；

- 在「读提交」隔离级别下，事务 B 修改余额后，因为没有提交事务，所以事务 A 中余额 V1 的值还是 100 万，等事务 B 提交完后，最新的余额数据才能被事务 A 看见，因此额 V2、V3 都是 200 万；

- 在「可重复读」隔离级别下，事务 A 只能看见启动事务时的数据，所以余额 V1、余额 V2 的值都是 100 万，当事务 A 提交事务后，就能看见最新的余额数据了，所以余额 V3 的值是 200 万；

- 在「串行化」隔离级别下，事务 B 在执行将余额 100 万修改为 200 万时，由于此前事务 A 执行了读操作，这样就发生了读写冲突，于是就会被锁住，直到事务 A 提交后，事务 B 才可以继续执行，所以从 A 的角度看，余额 V1、V2 的值是 100 万，余额 V3 的值是 200万。


这四种隔离级别具体是如何实现的呢？

- 对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了；

- 对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问；

- 对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 **Read View **来实现的，它们的区别在于创建 Read View 的时机不同，大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。「读提交」隔离级别是在每个读取数据前都生成一个 Read View，而「可重复读」隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View。

接下来详细说下，「读提交」和「可重复读」隔离级别到底怎样实现的，Read View 又是如何工作的？

#### 3.4可重复读隔离级别是如何实现的？
「可重复读」隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View。

想要更清楚的知道可重复读隔离级别是如何实现的，我们需要了解两个知识：

- Read View 中四个字段作用；

- 聚族索引记录中两个跟事务有关的隐藏列；

那 Read View 到底是个什么东西？

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102112541.png)

Read View 有四个重要的字段：

- creator_trx_id ：指的是创建该 Read View 的事务的事务 id。

- m_ids ：指的是创建 Read View 时当前数据库中活跃且未提交的事务的事务 id 列表，注意是一个列表。

- min_trx_id ：指的是创建 Read View 时当前数据库中活跃且未提交的事务中最小事务的事务 id，也就是 m_ids 的最小值。

- max_trx_id ：这个并不是 m_ids 的最大值，而是创建 Read View 时当前数据库中应该给下一个事务的 id 值；


知道了 Read View 的字段，我们还需要了解聚族索引记录中的两个隐藏列，假设在账户余额表插入一条小林余额为 100 万的记录，然后我把这两个隐藏列也画出来，该记录的整个示意图如下：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102112546.png)

对于使用 InnoDB 存储引擎的数据库表，它的聚族索引记录中都包含下面两个隐藏列：

- trx_id，当一个事务对某条聚族索引记录进行改动时，就会把该事务的事务 id 记录在 trx_id 隐藏列里；

- roll_pointer，每次对某条聚族索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后这个隐藏列是个指针，指向每一个旧版本记录，于是就可以通过它找到修改前的记录。

了解完这两个知识点后，就可以跟大家说说可重复读隔离级别是如何实现的。

假设事务 A 和 事务 B 差不多同一时刻启动，那这两个事务创建的 Read View 如下：



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102112549.png)

事务 A 和 事务 B 的 Read View 具体内容如下：

- 在事务 A 的 Read View 中，它的事务 id 是 51，由于与事务 B 同时启动，所以此时活跃的事务的事务 id 列表是 51 和 52，活跃的事务 id 中最小的事务 id 是事务 A 本身，下一个事务 id 应该是 53。

- 在事务 B 的 Read View 中，它的事务 id 是 52，由于与事务 A 同时启动，所以此时活跃的事务的事务 id 列表是 51 和 52，活跃的事务 id 中最小的事务 id 是事务 A，下一个事务 id 应该是 53。

然后让事务 A 去读账户余额为 100 万的记录，在找到记录后，它会先看这条记录的 trx_id，此时发现 trx_id 为 50，通过和事务 A 的 Read View 的 m_ids 字段发现，该记录的事务 id 并不在活跃事务的列表中，并且小于事务 A 的事务 id，这意味着，这条记录的事务早就在事务 A 前提交过了，所以该记录对事务 A 可见，也就是事务 A 可以获取到这条记录。

接着，事务 B 通过 update 语句将这条记录修改了，将小林的余额改成 200 万，这时 MySQL 会记录相应的 undo log，并以链表的方式串联起来，形成版本链，如下图：



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102112553.jpg)


你可以在上图的「记录字段」看到，由于事务 B 修改了该记录，以前的记录就变成旧版本记录了，于是最新记录和旧版本记录通过链表的方式串起来，而且最新记录的 trx_id 是事务 B 的事务 id。

然后如果事务 A 再次读取该记录，发现这条记录的 trx_id 为 52，比自己的事务 id 还大，并且比下一个事务 id 53 小，这意味着，事务 A 读到是和自己同时启动事务的事务 B 修改的数据，这时事务 A 并不会读取这条记录，而是沿着 undo log 链条往下找旧版本的记录，直到找到 trx_id 等于或者小于事务 A 的事务 id 的第一条记录，所以事务 A 再一次读取到 trx_id 为 50 的记录，也就是小林余额是 100 万的这条记录。

「可重复读」隔离级别就是在启动时创建了 Read View，然后在事务期间读取数据的时候，在找到数据后，先会将该记录的 trx_id 和该事务的 Read View 里的字段做个比较：

- 如果记录的 trx_id 比该事务的 Read View 中的 creator_trx_id 要小，且不在 m_ids 列表里，这意味着这条记录的事务早就在该事务前提交过了，所以该记录对该事务可见；

- 如果记录的 trx_id 比该事务的 Read View 中的 creator_trx_id 要大，且在 m_ids 列表里，这意味着该事务读到的是和自己同时启动的另外一个事务修改的数据，这时就不应该读取这条记录，而是沿着 undo log 链条往下找旧版本的记录，直到找到 trx_id 等于或者小于该事务 id 的第一条记录。

就是通过这样的方式实现了，「可重复读」隔离级别下在事务期间读到的数据都是事务启动前的记录。

**这种通过记录的版本链来控制并发事务访问同一个记录时的行为，这就叫 MVCC（多版本并发控制）。**

#### 读提交隔离级别是如何实现的？

「读提交」隔离级别是在每个 select 都会生成一个新的 Read View，也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。

那读提交隔离级别是怎么实现呢？我们还是以前面的例子来聊聊。

假设事务 A 和 事务 B 差不多同一时刻启动，然后事务 B 将小林的账户余额修改成了 200 万，但是事务 B 还未提交，这时事务 A 读到的数据，应该还是小林账户余额为 100 万的数据，那具体怎么做到的呢？



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102112557.jpg)

事务 A 在找到小林这条记录时，会看这条记录的 trx_id，发现和事务 A 的 Read View 中的 creator_trx_id 要大，而且还在 m_ids 列表里，说明这条记录被事务 B 修改过，而且还可以知道事务 B 并没有提交事务，因为如果提交了事务，那么这条记录的 trx_id 就不会在 m_ids 列表里。因此，事务 A 不能读取该记录，而是沿着 undo log 链条往下找。


当事务 B 修改数据并提交了事务后，这时事务 A 读到的数据，就是小林账户余额为 200 万的数据，那具体怎么做到的呢？


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102112601.png)

事务 A 在找到小林这条记录时，会看这条记录的 trx_id，发现和事务 A 的 Read View 中的 creator_trx_id 要大，而且不在 m_ids 列表里，说明该记录的 trx_id 的事务是已经提交过的了，于是事务 A 就可以读取这条记录，这也就是所谓的读已提交机制。

### 4、图解Mysql之锁

#### 全局锁

##### 全局锁怎么用的？

>flush tables with read lock</font>。

执行后，整个数据库就处于只读状态了，这时其他线程执行以下操作，都会被阻塞

- 对数据的增删查改操作，比如 insert、delete、update等语句；

- 对表结构的更改操作，比如 alter table、drop table 等语句。


##### 如果要释放全局锁，则要执行这条命令：
>unlock tables</font>。

当然，当会话断开了，全局锁会被自动释放。

##### 全局锁应用场景是什么？
全局锁主要应用于做**全局逻辑备份**，这样在备份数据库期间，不会因为数据或表结构的更改，而出现备份文件的数据与预期的不一样。

举个栗子。

在全库逻辑备份期间，假设不加全局锁的场景，看看会出现什么意外的情况。

如果在全库逻辑备份期间，有用户购买了一件商品，一般购买商品的业务逻辑是会涉及到多张数据表的更新，比如在用户表更新该用户的余额，然后在商品表更新被购买的商品的库存。

那么，有可能出现这样的顺序：

1、先备份了用户表的数据；
2、然后有用户发起了购买商品的操作；
3、接着再备份商品表的数据。

也就是在备份用户表和商品表之间，有用户购买了商品。

这种情况下，备份的结果是用户表中该用户的余额并没有扣除，反而商品表中该商品的库存被减少了，如果后面用这个备份文件恢复数据库数据的话，用户钱没少，而库存少了，等于用户白嫖了一件商品。

所以，在全库逻辑备份期间，加上全局锁，就不会出现上面这种情况了。

##### 加上全局锁又会带来什么缺点呢？

加上全局锁，意味着整个数据库都是只读状态。

那么如果数据库里有很多数据，备份就会花费很多的时间，关键是备份期间，业务只能读数据，而不能更新数据，这样会造成业务停滞。

##### 既然备份数据库数据的时候，使用全局锁会影响业务，那有什么其他方式可以避免？

有的，如果数据库的引擎支持的事务支持可重复读的隔离级别，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。

因为在可重复读的隔离级别下，即使其他事务更新了表的数据，也不会影响备份数据库时的 Read View，这就是事务四大特性中的隔离性，这样备份期间备份的数据一直是在开启事务时的数据。

备份数据库的工具是 mysqldump，在使用 mysqldump 时加上 –single-transaction 参数的时候，就会在备份数据库之前先开启事务。这种方法只适用于支持「可重复读隔离级别的事务」的存储引擎。

InnoDB 存储引擎默认的事务隔离级别正是可重复读，因此可以采用这种方式来备份数据库。

但是，对于 MyISAM 这种不支持事务的引擎，在备份数据库时就要使用全局锁的方法。


#### 表级锁
##### MySQL 表级锁有哪些？具体怎么用的

- 表锁；

- 元数据锁（MDL）;

- 意向锁；

- AUTO-INC 锁；

###### 表锁

>//表级别的共享锁，也就是读锁；

>lock tables t_student read;

>//表级别的独占锁，也就是写锁；

>lock tables t_stuent wirte; </font>


需要注意的是，表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作。

也就是说如果本线程对学生表加了「共享表锁」，那么本线程接下来如果要对学生表执行写操作的语句，是会被阻塞的，当然其他线程对学生表进行写操作时也会被阻塞，直到锁被释放。

要释放表锁，可以使用下面这条命令，会释放当前会话的所有表锁：

>unlock tables

另外，当会话退出后，也会释放所有表锁。

不过尽量避免在使用 InnoDB 引擎的表使用表锁，因为表锁的颗粒度太大，会影响并发性能，**InnoDB 牛逼的地方在于实现了颗粒度更细的行级锁。**


###### 元数据锁(MDL)
我们不需要显式的使用MDL，因为当我们对数据库表进行操作时，会自动给这个表加上MDL:

- 对一张表进行 CRUD 操作时，加的是 MDL 读锁；

- 对一张表做结构变更操作的时候，加的是 MDL 写锁；

MDL是为了保证当用户对表执行CEUD操作时，防止其他线程对这个表结构做了变更。

当有线程在执行 select 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 select 语句（ 释放 MDL 读锁）。

反之，当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 CRUD 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）。

##### MDL 不需要显示调用，那它是在什么时候释放的?

MDL 是在事务提交后才会释放，这意味着事务执行期间，MDL 是一直持有的。
那如果数据库有一个长事务（所谓的长事务，就是开启了事务，但是一直还没提交），那在对表结构做变更操作的时候，可能会发生意想不到的事情，比如下面这个顺序的场景：

- 首先，线程 A 先启用了事务（但是一直不提交），然后执行一条 select 语句，此时就先对该表加上 MDL 读锁；

- 然后，线程 B 也执行了同样的 select 语句，此时并不会阻塞，因为「读读」并不冲突；

- 接着，线程 C 修改了表字段，此时由于线程 A 的事务并没有提交，也就是 MDL 读锁还在占用着，这时线程 C 就无法申请到 MDL 写锁，就会被阻塞，

那么在线程 C 阻塞后，后续有对该表的 select 语句，就都会被阻塞，如果此时有大量该表的 select 语句的请求到来，就会有大量的线程被阻塞住，这时数据库的线程很快就会爆满了。


##### 为什么线程 C 因为申请不到 MDL 写锁，而导致后续的申请读锁的查询操作也会被阻塞？

这是因为申请 MDL 锁的操作会形成一个队列，队列中写锁获取优先级高于读锁，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。

所以为了能安全的对表结构进行变更，在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，如果可以考虑 kill 掉这个长事务，然后再做表结构的变更。

###### 意向锁
- 在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；

- 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；

也就是，当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁。

而普通的 select 是不会加行级锁的，普通的 select 语句是利用 MVCC 实现一致性读，是无锁的。

不过，select 也是可以对记录加共享锁和独占锁的，具体方式如下：

>//先在表上加上意向共享锁，然后对读取的记录加独占锁

>select ... lock in share mode;

>//先表上加上意向独占锁，然后对读取的记录加独占锁

> select ... for update;

**意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（lock tables … read）和独占表锁（lock tables … write）发生冲突。**

表锁和行锁是满足读读共享、读写互斥、写写互斥的。

如果没有「意向锁」，那么加「独占表锁」时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢。

那么有了「意向锁」，由于在对记录加独占锁前，先会加上表级别的意向独占锁，那么在加「独占表锁」时，直接查该表是否有意向独占锁，如果有就意味着表里已经有记录被加了独占锁，这样就不用去遍历表里的记录。

所以，**意向锁的目的是为了快速判断表里是否有记录被加锁。**

##### AUTO-INC 锁
在为某个字段声明 AUTO_INCREMENT 属性时，之后可以在插入数据时，可以不指定该字段的值，数据库会自动给该字段赋值递增的值，这主要是通过 AUTO-INC 锁实现的。

AUTO-INC 锁是特殊的表锁机制，锁不是再一个事务提交后才释放，而是再执行完插入语句后就会立即释放。


在插入数据时，会加一个表级别的 AUTO-INC 锁，然后为被 AUTO_INCREMENT 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。

那么，一个事务在持有 AUTO-INC 锁的过程中，其他事务的如果要向该表插入语句都会被阻塞，从而保证插入数据时，被 AUTO_INCREMENT 修饰的字段的值是连续递增的。

但是， AUTO-INC 锁再对大量数据进行插入的时候，会影响插入性能，因为另一个事务中的插入会被阻塞。

因此， 在 MySQL 5.1.22 版本开始，InnoDB 存储引擎提供了一种**轻量级的锁**来实现自增。

一样也是在插入数据的时候，会为被 AUTO_INCREMENT 修饰的字段加上轻量级锁，然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁。

InnoDB 存储引擎提供了个 innodb_autoinc_lock_mode 的系统变量，是用来控制选择用 AUTO-INC 锁，还是轻量级的锁。

- 当 innodb_autoinc_lock_mode = 0，就采用 AUTO-INC 锁；

- 当 innodb_autoinc_lock_mode = 2，就采用轻量级锁；

- 当 innodb_autoinc_lock_mode = 1，这个是默认值，两种锁混着用，如果能够确定插入记录的数量就采用轻量级锁，不确定时就采用 AUTO-INC 锁。

不过，当 innodb_autoinc_lock_mode = 2 是性能最高的方式，但是会带来一定的问题。因为并发插入的存在，在每次插入时，自增长的值可能不是连续的，**这在有主从赋值的场景中是不安全的。**



#### 行级锁
##### 行级锁有哪些？
InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁。

行级锁的类型主要有三类：

- Record Lock，记录锁，也就是仅仅把一条记录锁上；

- Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；

- Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。


前面也提到，普通的 select 语句是不会对记录加锁的，如果要在查询时对记录加行锁，可以使用下面这两个方式：

>//先在表上加上意向共享锁，然后对读取的记录加独占锁

>select ... lock in share mode;

>//先表上加上意向独占锁，然后对读取的记录加独占锁

> select ... for update;

上面这两条语句必须再一个事务中，当事务提交了，锁就会被释放，因此在使用这两条语句的时候，要加上 begin、start transaction 或者 set autocommit = 0。

那具体要在哪些纪录上加锁，就跟具体的 select 语句有关系了，比较复杂。


对记录加锁时，加锁的基本单位是 next-key lock，它是由记录锁和间隙锁组合而成的，next-key lock 是前开后闭区间，而间隙锁是前开后开区间。

但是，next-key lock 在一些场景下会退化成记录锁或间隙锁。
那到底是什么场景呢？今天，我们就以下面这个表来进行实验说明。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102172012.jpg)

其中，id 是主键索引（唯一索引），b 是普通索引（非唯一索引），a 是普通的列。

注意，我的 MySQL 的版本是 8.0.26，不同版本的加锁规则可能是不同的。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102154454.png)

###### 唯一索引等值查询
当我们用唯一索引进行等值查询的时候，查询的记录存不存在，加锁的规则也会不同：

- 当查询的记录是存在的，在用「唯一索引进行等值查询」时，next-key lock 会退化成「记录锁」。

- 当查询的记录是不存在的，在用「唯一索引进行等值查询」时，next-key lock 会退化成「间隙锁」。


接下里用两个案例来说明。

1、先看看记录是存在的。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102194256.jpg)

会话1加锁变化过程如下：

- 加锁的基本单位是 next-key lock，因此会话1的加锁范围是(8, 16];

- 但是由于是用唯一索引进行等值查询，且查询的记录存在，所以 next-key lock 退化成记录锁，因此最终加锁的范围是 id = 16 这一行。

所以，会话 2 在修改 id=16 的记录时会被锁住，而会话 3 插入 id=9 的记录可以被正常执行。


2、接下来，看看记录不存在的情况。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102194440.png)


会话1加锁变化过程如下：

- 加锁的基本单位是 next-key lock，因此主键索引 id 的加锁范围是(8, 16];

- 但是由于查询记录不存在，next-key lock 退化成间隙锁，因此最终加锁的范围是 (8,16)。

所以，会话 2 要往这个间隙里面插入 id=9 的记录会被锁住，但是会话 3 修改 id =16 是可以正常执行的，因为 id = 16 这条记录并没有加锁。



###### 唯一索引范围查询

范围查询和等值查询的加锁规则是不同的。

举个例子，下面这两条查询语句，查询的结果虽然是一样的，但是加锁的范围是不一样的。

>select * from t_test where id=8 for update;

>select * from t_test where id>=8 and id<9 for update;


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220103160600.png)


会话 1 加锁变化过程如下：

- 最开始要找的第一行是 id = 8，因此 next-key lock(4,8]，但是由于 id 是唯一索引，且该记录是存在的，因此会退化成记录锁，也就是只会对 id = 8 这一行加锁；

- 由于是范围查找，就会继续往后找存在的记录，也就是会找到 id = 16 这一行停下来，然后加 next-key lock (8, 16]，但由于 id = 16 不满足 id < 9，所以会退化成间隙锁，加锁范围变为 (8, 16)。

所以，会话 1 这时候主键索引的锁是记录锁 id=8 和间隙锁(8, 16)。

会话 2 由于往间隙锁里插入了 id = 9 的记录，所以会被锁住了，而 id = 8 是被加锁的，因此会话 3 的语句也会被阻塞。

由于 id = 16 并没有加锁，所以会话 4 是可以正常被执行。

###### 非唯一索引等值查询
当我们用非唯一索引进行等值查询的时候，查询的记录存不存在，加锁的规则也会不同：

- 当查询的记录存在时，除了会加 next-key lock 外，还额外加间隙锁，也就是会加两把锁。

- 当查询的记录不存在时，只会加 next-key lock，然后会退化为间隙锁，也就是只会加一把锁。

1、先来看看查询的值存在的情况。



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102194444.png)


会话1加锁变化过程如下：
- 先会对普通索引b加上next-key lock，范围时(4,8]。

- 然后因为是非唯一索引，且查询的记录是存在的，所以还会加上间隙锁，规则是向下遍历到第一个不符合条件的值才能停止，因此间隙锁的范围是(8,,16)。

所以，会话1的普通索引b上共有两个锁，分别是next-key lock(4,8]和间隙锁（8,16)。

那么，当会话 2 往间隙锁里插入 id = 9 的记录就会被锁住，而会话 3 和会话 4 是因为更改了 next-key lock 范围里的记录而被锁住的。


然后因为b=16这条记录没有加锁，所以会话5是可以正常执行的

我们看看查询的值不存在的情况

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102194450.jpg)

会话一改成10

会话 1 加锁变化过程如下：

- 先会对普通索引 b 加上 next-key lock，范围是(8,16];

- 但是由于查询的记录是不存在的，所以不会再额外加个间隙锁，但是 next-key lock 会退化为间隙锁，最终加锁范围是 (8,16)。

会话 2 因为往间隙锁里插入了 b = 9 的记录，所以会被锁住，而 b = 16 是没有被加锁的，因此会话 3 的语句可以正常执行。


##### 非唯一索引范围查询

非唯一索引和主键索引的范围查询的加锁也有所不同，不同之处在于**普通索引范围查询，next-key lock 不会退化为间隙锁和记录锁。**

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220102194454.jpg)



会话 1 加锁变化过程如下：

- 最开始要找的第一行是 b = 8，因此 next-key lock(4,8]，但是由于 b 不是唯一索引，并不会退化成记录锁。

- 但是由于是范围查找，就会继续往后找存在的记录，也就是会找到 b = 16 这一行停下来，然后加 next-key lock (8, 16]，因为是普通索引查询，所以并不会退化成间隙锁。

所以，会话 1 的普通索引 b 有两个 next-key lock，分别是 (4,8] 和(8, 16]。这样，你就明白为什么会话 2 、会话 3 、会话 4 的语句都会被锁住了。


总结Mysql 8.0.26版本加锁规则:

唯一索引等值查询：
- 当查询的记录是存在的，next-key lock 会退化成「记录锁」。

- 当查询的记录是不存在的，next-key lock 会退化成「间隙锁」。

非唯一索引等值查询：

- 当查询的记录存在时，除了会加 next-key lock 外，还额外加间隙锁，也就是会加两把锁。

- 当查询的记录不存在时，只会加 next-key lock，然后会退化为间隙锁，也就是只会加一把锁。

非唯一索引和主键索引的范围查询的加锁规则不同之处在于：

- 唯一索引在满足一些条件的时候，next-key lock 退化为间隙锁和记录锁。

- 非唯一索引范围查询，next-key lock 不会退化为间隙锁和记录锁。

补充说明：
如果是用select...in share mode 的语句，能走覆盖索引，那么主键索引就不会被加锁，因为不会访问主键上的数据。

如果是用select...for update，不管是不是覆盖索引，都会给主键索引上满足条件的行加上锁。


### 5、避免被一条update语句干趴下

在线上执行一条 update 语句修改数据库数据的时候，
where 条件没有带上索引，导致业务直接崩了。

- 为什么会发生这种事故？
- 如何避免？

说个前提，接下来说的案例都是基于 InnoDB 存储引擎，且事务的隔离级别是可重复读。


#### 为什么会发生这种事故？
InnoDB 存储引擎的默认事务隔离级别是「可重复读」，但是在这个隔离级别下，在多个事务并发的时候，会出现幻读的问题，所谓的幻读是指在同一事务下，连续执行两次同样的查询语句，第二次的查询语句可能会返回之前不存在的行。


因此 InnoDB 存储引擎自己实现了行锁，通过 next-key 锁（记录锁和间隙锁的组合）来锁住记录本身和记录之间的“间隙”，防止其他事务在这个记录之间插入新的记录，从而避免了幻读现象。

当我们执行 update 语句时，实际上是会对记录加独占锁（X 锁）的，如果其他事务对持有独占锁的记录进行修改时是会被阻塞的。另外，这个锁并不是执行完 update 语句就会释放的，而是会等事务结束时才会释放。

在 InnoDB 事务中，对记录加锁带基本单位是 next-key 锁，但是会因为一些条件会退化成间隙锁，或者记录锁。加锁的位置准确的说，锁是加在索引上的而非行上。

比如，在 update 语句的 where 条件使用了唯一索引，那么 next-key 锁会退化成记录锁，也就是只会给一行记录加锁。

这里举个例子，这里有一张数据库表，其中 id 为主键索引。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220103160825.png)


假设有两个事务的执行顺序如下

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220103160829.png)

可以看到，事务 A 的 update 语句中 where 是等值查询，并且 id 是唯一索引，所以只会对 id = 1 这条记录加锁，因此，事务 B 的更新操作并不会阻塞。

但是，**在 update 语句的 where 条件没有使用索引，就会全表扫描，于是就会对所有记录加上 next-key 锁（记录锁 + 间隙锁），相当于把整个表锁住了。**




假设有两个事务的执行顺序如下：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220103160833.png)


可以看到，这次事务 B 的 update 语句被阻塞了。
这是因为事务 A的 update 语句中 where 条件没有索引列，所有记录都会被加锁，也就是这条 update 语句产生了 4 个记录锁和 5 个间隙锁，相当于锁住了全表。



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220103160838.png)

因此，当在数据量非常大的数据库表执行 update 语句时，如果没有使用索引，就会给全表的加上 next-key 锁， 那么锁就会持续很长一段时间，直到事务结束。

而这期间除了 select ... from语句，其他语句都会被锁住不能执行，业务会因此停滞，接下来等着你的，就是老板的挨骂。

那 update 语句的 where 带上索引就能避免全表记录加锁了吗？


并不是。

**关键还得看这条语句在执行过程中，优化器最终选择的是索引扫描，还是全表扫描，如果走了全表扫描，就会对全表的记录加锁了。**


##### 又该如何避免这种事故的发生？
我们可以将 MySQL 里的 sql_safe_updates 参数设置为 1，开启安全更新模式。



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220103160842.png)

大致的意思是，当 sql_safe_updates 设置为 1 时。

update 语句必须满足如下条件之一才能执行成功：

- 使用 where，并且 where 条件中必须有索引列；

- 使用 limit；

- 同时使用 where 和 limit，此时 where 条件中可以没有索引列；


delete 语句必须满足如下条件之一才能执行成功：

- 使用 where，并且 where 条件中必须有索引列；

- 同时使用 where 和 limit，此时 where 条件中可以没有索引列；

如果 where 条件带上了索引列，但是优化器最终扫描选择的是全表，而不是索引的话，我们可以使用 force index([index_name]) 可以告诉优化器使用哪个索引，以此避免有几率锁全表带来的隐患。

6、幻读是怎么被解决的？
幻读补充定义：幻读仅专指“新插入的行”。

中途通过update更新数据而出现同一个事务前后两次查询的【结果集合】不一样，这种不算幻读。

然后前几天有位读者跟我说，这个幻读例子不是已经被「可重复读」隔离级别解决了吗？为什么还要有 next-key 呢？

他有这个质疑，是因为他做了这个实验。

实验的数据库表 t_stu 如下，其中 id 为主键。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220103164530.jpg)

然后在可重复读隔离级别下，有两个事务的执行顺序如下：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220103164534.png)

从这个实验结果可以看到，即使事务 B 中途插入了一条记录，事务 A 前后两次查询的结果集都是一样的，并没有出现所谓的幻读现象。

读者做的实验之所以看不到幻读现象，是因为在可重复读隔离级别下，**普通的查询是快照读，是不会看到别的事务插入的数据的。**

可重复读隔离级是由 MVCC（多版本并发控制）实现的，实现的方式是启动事务后，在执行第一个查询语句后，会创建一个视图，然后后续的查询语句都用这个视图，「快照读」读的就是这个视图的数据，视图你可以理解为版本数据，这样就使得每次查询的数据都是一样的。


MySQL 里除了普通查询是快照度，其他都是**当前读**，比如update、insert、delete，这些语句执行前都会查询最新版本的数据，然后再做进一步的操作。


这很好理解，假设你要 update 一个记录，另一个事务已经 delete 这条记录并且 提交事务了，这样不是会产生冲突吗，所以 update 的时候肯定要知道最新的数据。


另外，**select ... for update 这种查询语句是当前读**，每次执行的时候都是读取最新的数据。 

**因此，要讨论「可重复读」隔离级别的幻读现象，是要建立在「当前读」的情况下。**


接下来，我们假设select ... for update当前读是不会加锁的（实际上是会加锁的），


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220103164538.png)

这时候，事务 B 插入的记录，就会被事务 A 的第二条查询语句查询到（因为是当前读），这样就会出现前后两次查询的结果集合不一样，这就出现了幻读。

所以，**Innodb 引擎为了解决「可重复读」隔离级别使用「当前读」而造成的幻读问题，就引出了 next-key 锁***，就是记录锁和间隙锁的组合。


- 记录锁，锁的是记录本身；

- 间隙锁，锁的就是两个值之间的空隙，以防止其他事务在这个空隙间插入新的数据，从而避免幻读现象。


比如，下面事务 A 查询语句会锁住(2, +∞]范围的记录，然后期间如果有其他事务在这个锁住的范围插入数据就会被阻塞。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220103164541.jpg)


next-key 锁的加锁规则其实挺复杂的，在一些场景下会退化成记录锁或间隙锁

需要注意的是，next-key lock 锁的是索引，而不是数据本身，所以如果 update 语句的 where 条件没有用到索引列，那么就会全表扫描，在一行行扫描的过程中，不仅给行加上了行锁，还给行两边的空隙也加上了间隙锁，相当于锁住整个表，然后直到事务结束才会释放锁。


所以在线上千万不要执行没有带索引条件的 update 语句，不然会造成业务停滞.

tips:可重复读只解决了快照读方式的幻读，并没有解决当前读方式的幻读。

幻读会导致数据和binlog日志逻辑上不一样。



6、[聊聊Mysql的优化思路](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247499357&idx=2&sn=67ff00339e19d1dda62652dd588932b7&chksm=f98dbaf7cefa33e130d64e020bd53d74d52432eade6a4c22f0cd36d826f58bcb49ae8cbba347&scene=178&cur_album_id=1955634887135199237#rd)


### 7、换一个角度看B+树
都知道 MySQL 里 InnoDB 存储引擎是采用**B+树**来组织数据的。

但是大家知道 B+ 树里的节点里存放的是什么呢？查询数据的过程又是怎样的？

这次，我们从**数据页的**角度看 B+ 树，看看每个节点长啥样。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220103184937.png)

#### InnoDB 是如何存储数据的？

MySQL 支持多种存储引擎，不同的存储引擎，存储数据的方式也是不同的，我们最常使用的是 InnoDB 存储引擎，所以就跟大家图解下InnoDB 是如何存储数据的。


记录是按照行来存储的，但是数据库的读取并不以「行」为单位，否则一次读取（也就是一次 I/O 操作）只能处理一行数据，效率会非常低。


因此，**InnoDB 的数据是按「数据页」为单位来读写的**，也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。


数据库的 I/O 操作的最小单位是页，InnoDB 数据页的默认大小是 **16KB**，意味着数据库每次读写都是以 16KB 为单位的，一次最少从磁盘中读取 16K 的内容到内存中，一次最少把内存中的 16K 内容刷新到磁盘中。

数据页包括七个部分，结构如下图：



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220103184958.png)


这 7 个部分的作用如下图：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220103185002.jpg)

在 File Header 中有两个指针，分别指向上一个数据页和下一个数据页，连接起来的页相当于一个双向的链表，如下图所示:
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220103185005.png)


采用链表的结构是让数据页之间不需要是物理上的连续的，而是逻辑上的连续。

数据页的主要作用是存储记录，也就是数据库的数据，所以重点说一下数据页中的 User Records 是怎么组织数据的。

**数据页中的记录按照「主键」顺序组成单向链表**，单向链表的特点就是插入、删除非常方便，但是检索效率不高，最差的情况下需要遍历链表上的所有节点才能完成检索。

因此，数据页中有一个**页目录**，起到记录的索引作用，就像我们书那样，针对书中内容的每个章节设立了一个目录，想看某个章节的时候，可以查看目录，快速找到对应的章节的页数，而数据页中的页目录就是为了能快速找到记录。


那 InnoDB 是如何给记录创建页目录的呢？页目录与记录的关系如下图：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220103185008.png)


页目录创建的过程如下：

- 将所有的记录划分成几个组，这些记录包括最小记录和最大记录，但不包括标记为“已删除”的记录；

- 每个记录组的最后一条记录就是组内最大的那条记录，并且最后一条记录的头信息中会存储该组一共有多少条记录，作为 n_owned 字段（上图中粉红色字段）

- 页目录用来存储每组最后一条记录的地址偏移量，这些地址偏移量会按照先后顺序存储起来，每组的地址偏移量也被称之为槽（slot），每个槽相当于指针指向了不同组的最后一个记录。

从图可以看到，页目录就是由多个槽组成的，槽相当于分组记录的索引。

然后，因为记录是按照「主键值」从小到大排序的，所以我们通过槽查找记录时，可以使用二分法快速定位要查询的记录在哪个槽（哪个记录分组）


定位到槽后，再遍历槽内的所有记录，找到对应的记录，无需从最小记录开始遍历整个页中的记录链表。

以上面那张图举个例子，5 个槽的编号分别为 0，1，2，3，4，我想查找主键为 11 的用户记录：

- 先二分得出槽中间位是 (0+4)/2=2 ，2号槽里最大的记录为 8。因为 11 > 8，所以需要从 2 号槽后继续搜索记录；

- 再使用二分搜索出 2 号和 4 槽的中间位是 (2+4)/2= 3，3 号槽里最大的记录为 12。因为 11 < 12，所以主键为 11 的记录在 3 号槽里；

- 再从 2 号槽找到3号槽的第一条记录，然后在遍历找到对应的记录。


看到第三步的时候，可能有的同学会疑问，如果某个槽内的记录很多，然后因为记录都是单向链表串起来的，那这样在槽内查找某个记录的时间复杂度不就是 O(n) 了吗？


这点不用担心，InnoDB 对每个分组中的记录条数都是有规定的，槽内的记录就只有几条：

- 第一个分组中的记录只能有 1 条记录；

- 最后一个分组中的记录条数范围只能在 1-8 条之间；

- 剩下的分组中记录条数范围只能在 4-8 条之间。

#### B+ 树是如何进行查询的？

上面我们都是在说一个数据页中的记录检索，因为一个数据页中的记录是有限的，且主键值是有序的，所以通过对所有记录进行分组，然后将组号（槽号）存储到页目录，使其起到索引作用，通过二分查找的方法快速检索到记录在哪个分组，来降低检索的时间复杂度。


但是，当我们需要存储大量的记录时，就需要多个数据页，这时我们就需要考虑如何建立合适的索引，才能方便定位记录所在的页。

为了解决这个问题，InnoDB 采用了 B+ 树作为索引。磁盘的 I/O 操作次数对索引的使用效率至关重要，因此在构造索引的时候，我们更倾向于采用“矮胖”的 B+ 树数据结构，这样所需要进行的**磁盘 I/O 次数更少**，而且 B+ 树 更**适合进行关键字的范围查询。**

InnoDB 里的 B+ 树中的**每个节点都是一个数据页**，结构示意图如下：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220103185011.jpg)

通过上图，我们看出  B+ 树的特点：

- 只有叶子节点（最底层的节点）才存放了数据，非叶子节点（其他上层节）仅用来存放目录项作为索引。

- 非叶子节点分为不同层次，通过分层来降低每一层的搜索量；

- 所有节点按照索引键大小排序，构成一个双向链表，便于范围查询；

我们再看看 B+ 树如何实现快速查找主键为 6 的记录，以上图为例子：

- 从根节点开始，通过二分法快速定位到符合页内范围包含查询值的页，因为查询的主键值为 6，在[1, 7)范围之间，所以到页 30 中查找更详细的目录项；

- 在非叶子节点（页30）中，继续通过二分法快速定位到符合页内范围包含查询值的页，主键值大于 5，所以就到叶子节点（页16）查找记录；

- 接着，在叶子节点（页16）中，通过槽查找记录时，使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到主键为 6 的记录。

可以看到，在定位记录所在哪一个页时，也是通过二分法快速定位到包含该记录的页。定位到该页后，又会在该页内进行二分法快速定位记录所在的分组（槽号），最后在分组内进行遍历查找。

#### 聚集索引和二级索引
另外，索引又可以分成聚簇索引和非聚簇索引（二级索引），它们区别就在于叶子节点存放的是什么数据：

- 聚簇索引的叶子节点存放的是实际数据，所有完整的用户记录都存放在聚集索引的叶子节点；

- 二级索引的叶子节点存放的是主键值，而不是实际数据。


因为表的数据都是存放在聚集索引的叶子节点里，所以 InnoDB 存储引擎一定会为表创建一个聚集索引，且由于数据在物理上只会保存一份，所以聚簇索引只能有一个。


InnoDB 在创建聚簇索引时，会根据不同的场景选择不同的列作为索引：


- 如果有主键，默认会使用主键作为聚簇索引的索引键；

- 如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键；

- 在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键；

一张表只能有一个聚簇索引，那为了实现非主键字段的快速搜索，就引出了二级索引（非聚簇索引/辅助索引），它也是利用了 B+ 树的数据结构，但是二级索引的叶子节点存放的是主键值，不是实际数据。

二级索引的 B+ 树如下图，数据部分为主键值：



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220103185015.png)




### 8、为什么 MySQL 采用 B+ 树作为索引？
要解释这个问题，其实不单单要从数据结构的角度出发，还要考虑磁盘 I/O 操作次数，因为 MySQL 的数据是存储在磁盘中的嘛。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220104101822.png)


#### 怎样的索引的数据结构是好的？
MySQL 的数据是持久化的，意味着数据（索引+记录）是保存到磁盘上的，因为这样即使设备断电了，数据也不会丢失

磁盘是一个慢的离谱的存储设备，有多离谱呢？

人家内存的访问速度是纳秒级别的，而磁盘访问的速度是毫秒级别的，也就是说读取同样大小的数据，磁盘中读取的速度比从内存中读取的速度要慢上万倍，甚至几十万倍。

磁盘读写的最小单位是**扇区**，扇区的大小只有 **512B** 大小，操作系统一次会读写多个扇区，所以操作系统的最小读写单位是**块（Block）**。Linux 中的块大小为 **4KB**，也就是一次磁盘  I/O 操作会直接读写 **8**个扇区。

由于数据库的索引是保存到磁盘上的，因此当我们通过索引查找某行数据的时候，就需要先从磁盘读取索引到内存，再通过索引从磁盘中找到某行数据，然后读入到内存，也就是说查询过程中会发生多次磁盘 I/O，而磁盘 I/O 次数越多，所消耗的时间也就越大。


所以，我们希望索引的数据结构能在尽可能少的磁盘的 I/O 操作中完成查询工作，因为磁盘  I/O 操作越少，所消耗的时间也就越小。

另外，MySQL 是支持范围查找的，所以索引的数据结构不仅要能高效地查询某一个记录，而且也要能高效地执行范围查找。


所以，要设计一个适合 MySQL 索引的数据结构，至少满足以下要求：

- 能在尽可能少的磁盘的 I/O 操作中完成查询工作；

- 要能高效地查询某一个记录，也要能高效地执行范围查找；

分析完要求后，我们针对每一个数据结构分析一下。





#### 什么是二分查找？
索引数据最好能按顺序排列，这样可以使用「二分查找法」高效定位数据。

假设我们现在用数组来存储索引，比如下面有一个排序的数组，如果要从中找出数字 3，最简单办法就是从头依次遍历查询，这种方法的时间复杂度是 O(n)，查询效率并不高。因为该数组是有序的，所以我们可以采用二分查找法，比如下面这张采用二分法的查询过程图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220104102137.png)


可以看到，二分查找法每次都把查询的范围减半，这样时间复杂度就降到了 O(logn)，但是每次查找都需要不断计算中间位置。



#### 什么是二分查找树？

用数组来实现线性排序的数据虽然简单好用，但是插入新元素的时候性能太低。

因为插入一个元素，需要将这个元素之后的所有元素后移一位，如果这个操作发生在磁盘中呢？这必然是灾难性的。因为磁盘的速度比内存慢几十万倍，所以我们不能用一种线性结构将磁盘排序。

其次，有序的数组在使用二分查找的时候，每次查找都要不断计算中间的位置。

那我们能不能设计一个非线形且天然适合二分查找的数据结构呢？

有的，请看下图这个神奇的操作，找到所有二分查找中用到的所有中间节点，把他们用指针连起来，并将最中间的节点作为根节点。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/640.gif)


怎么样？是不是变成了二叉树，不过它不是普通的二叉树，它是一个二叉查找树。

二叉查找树的特点是一个节点的左子树的所有节点都小于这个节点，右子树的所有节点都大于这个节点，这样我们在查询数据时，不需要计算中间节点的位置了，只需将查找的数据与节点的数据进行比较。

假设，我们查找索引值为 key 的节点：

- 如果 key 大于根节点，则在右子树中进行查找；

- 如果 key 小于根节点，则在左子树中进行查找；

- 如果 key 等于根节点，也就是找到了这个节点，返回根节点即可。

二叉查找树查找某个节点的动图演示如下，比如要查找节点 3 ：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/641.gif)



另外，二叉查找树解决了插入新节点的问题，因为二叉查找树是一个跳跃结构，不必连续排列。这样在插入的时候，新节点可以放在任何位置，不会像线性结构那样插入一个元素，所有元素都需要向后排列。

下面是二叉查找树插入某个节点的动图演示：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/642.gif)


因此，二叉查找树解决了连续结构插入新元素开销很大的问题，同时又保持着天然的二分结构。

那是不是二叉查找树就可以作为索引的数据结构了呢？

不行不行，二叉查找树存在一个极端情况，会导致它变成一个瘸子！

**当每次插入的元素都是二叉查找树中最大的元素，二叉查找树就会退化成了一条链表，查找数据的时间复杂度变成了 O(n)**，如下动图演示：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/643.gif)

由于树是存储在磁盘中的，访问每个节点，都对应一次磁盘 I/O 操作（假设一个节点的大小「小于」操作系统的最小读写单位块的大小），也就是说树的高度就等于每次查询数据时磁盘 IO 操作的次数，所以**树的高度越高，就会影响查询性能。**



二叉查找树由于存在退化成链表的可能性，会使得查询操作的时间复杂度从 O(logn)降低为 O(n)。

而且会随着插入的元素越多，树的高度也变高，意味着需要磁盘 IO 操作的次数就越多，这样导致查询性能严重下降，再加上不能范围查询，所以不适合作为数据库的索引结构。


#### 什么是自平衡二叉树？

为了解决二叉查找树会在极端情况下退化成链表的问题，后面就有人提出**平衡二叉查找树（AVL 树）。**


主要是在二叉查找树的基础上增加了一些条件约束：**每个节点的左子树和右子树的高度差不能超过 1**。也就是说节点的左子树和右子树仍然为平衡二叉树，这样查询操作的时间复杂度就会一直维持在 O(logn) 。


下图是每次插入的元素都是平衡二叉查找树中最大的元素，可以看到，它会维持自平衡：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/645.gif)




除了平衡二叉查找树，还有很多自平衡的二叉树，比如红黑树，它也是通过一些约束条件来达到自平衡，不过红黑树的约束条件比较复杂，不是本篇的重点重点，大家可以看《数据结构》相关的书籍来了解红黑树的约束条件。

下面是红黑树插入节点的过程，这左旋右旋的操作，就是为了自平衡。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/647.gif)


**不管平衡二叉查找树还是红黑树，都会随着插入的元素增多，而导致树的高度变高，这就意味着磁盘 I/O 操作次数多，会影响整体数据查询的效率。**

比如，下面这个平衡二叉查找树的高度为 5，那么在访问最底部的节点时，就需要磁盘 5 次 I/O 操作。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220104141239.png)

根本原因是因为它们都是二叉树，也就是每个节点只能保存 2 个子节点 ，如果我们把二叉树改成 M 叉树（M>2）呢？

比如，当 M=3 时，在同样的节点个数情况下，三叉树比二叉树的树高要矮。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220104141243.png)


因此，**当树的节点越多的时候，并且树的分叉数 M 越大的时候，M 叉树的高度会远小于二叉树的高度。**


#### 什么是 B 树

自平衡二叉树虽然能保持查询操作的时间复杂度在O(logn)，但是因为它本质上是一个二叉树，每个节点只能有 2 个子节点，那么当节点个数越多的时候，树的高度也会相应变高，这样就会增加磁盘的 I/O 次数，从而影响数据查询的效率。

为了解决降低树的高度的问题，后面就出来了 B 树，它不再限制一个节点就只能有 2 个子节点，而是允许 M 个子节点 (M>2)，从而降低树的高度。

B 树的每一个节点最多可以包括 M 个子节点，M 称为 B 树的阶，所以 B 树就是一个多叉树。

假设 M = 3，那么就是一棵 3 阶的 B 树，特点就是每个节点最多有 2 个（M-1个）数据和最多有 3 个（M个）子节点，超过这些要求的话，就会分裂节点，比如下面的的动图：



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/648.gif)


我们来看看一棵 3 阶的 B 树的查询过程是怎样的？

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/649.gif)

假设我们在上图一棵 3 阶的 B 树中要查找的索引值是 9 的记录那么步骤可以分为以下几步：

- 与根节点的索引(4，8）进行比较，9 大于 8，那么往右边的子节点走；

- 然后该子节点的索引为（10，12），因为 9 小于 10，所以会往该节点的左边子节点走；

- 走到索引为9的节点，然后我们找到了索引值 9 的节点。

可以看到，一棵 3 阶的 B 树在查询叶子节点中的数据时，由于树的高度是 3 ，所以在查询过程中会发生 3 次磁盘 I/O 操作。

而如果同样的节点数量在平衡二叉树的场景下，树的高度就会很高，意味着磁盘 I/O 操作会更多。所以，B 树在数据查询中比平衡二叉树效率要高。

但是 B 树的每个节点都包含数据（索引+记录），而用户的记录数据的大小很有可能远远超过了索引数据，这就需要花费更多的磁盘 I/O 操作次数来读到「有用的索引数据」。

而且，在我们查询位于底层的某个节点（比如 A 记录）过程中，「非 A 记录节点」里的记录数据会从磁盘加载到内存，但是这些记录数据是没用的，我们只是想读取这些节点的索引数据来做比较查询，而「非 A 记录节点」里的记录数据对我们是没用的，这样不仅**增多磁盘 I/O 操作次数，也占用内存资源。**

另外，**如果使用 B 树来做范围查询的话，需要使用中序遍历，这会涉及多个节点的磁盘 I/O  问题，从而导致整体速度下降。**

#### 什么是 B+ 树？
B+ 树就是对 B 树做了一个升级，MySQL 中索引的数据结构就是采用了 B+ 树，B+ 树结构如下图：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220104143041.png)


B+ 树与 B 树差异的点，主要是以下这几点：

叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引；

所有索引都会在叶子节点出现，叶子节点之间构成一个有序链表；

非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小）。

非叶子节点中有多少个子节点，就有多少个索引；

下面通过三个方面，比较下 B+ 和 B 树的性能区别。

##### 1、单点查询
B 树进行单个索引查询时，最快可以在 O(1) 的时间代价内就查到，而从平均时间代价来看，会比 B+ 树稍快一些。

但是 B 树的查询波动会比较大，因为每个节点即存索引又存记录，所以有时候访问到了非叶子节点就可以找到索引，而有时需要访问到叶子节点才能找到索引。


**B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少。**

##### 2、插入和删除效率

B+ 树有大量的冗余节点，这样使得删除一个节点的时候，可以直接从叶子节点中删除，甚至可以不动非叶子节点，这样删除非常快，

比如下面这个动图是删除 B+ 树某个叶子节点节点的过程：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/650.gif)



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220104143045.png)


甚至，B+ 树在删除根节点的时候，由于存在冗余的节点，所以不会发生复杂的树的变形，比如下面这个动图是删除 B+ 树根节点的过程：
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/651.gif)


B 树则不同，B 树没有冗余节点，删除节点的时候非常复杂，比如删除根节点中的数据，可能涉及复杂的树的变形，比如下面这个动图是删除 B 树根节点的过程：
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/652.gif)

B+ 树的插入也是一样，有冗余节点，插入可能存在节点的分裂（如果节点饱和），但是最多只涉及树的一条路径。而且 B+ 树会自动平衡，不需要像更多复杂的算法，类似红黑树的旋转操作等。

因此，**B+ 树的插入和删除效率更高。**


##### 3、范围查询
B 树和 B+ 树等值查询原理基本一致，先从根节点查找，然后对比目标数据的范围，最后递归的进入子节点查找。


因为 **B+ 树所有叶子节点间还有一个链表进行连接，这种设计对范围查找非常有帮助**，比如说我们想知道 12 月 1 日和 12 月 12 日之间的订单，这个时候可以先查找到 12 月 1 日所在的叶子节点，然后利用链表向右遍历，直到找到 12 月12 日的节点，这样就不需要从根节点查询了，进一步节省查询需要的时间。

而**B 树没有将所有叶子节点用链表串联起来的结构，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。**

因此，存在大量范围检索的场景，适合使用 B+树，比如数据库。而对于大量的单个索引查询的场景，可以考虑 B 树，比如 nosql 的MongoDB。


#### MySQL 中的 B+ 树

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220104180204.png)


- B+ 树的叶子节点之间是用「双向链表」进行连接，这样的好处是既能向右遍历，也能向左遍历。

- B+ 树点节点内容是数据页，数据页里存放了用户的记录以及各种信息，每个数据页默认大小是 16 KB。


Innodb 根据索引类型不同，分为聚集和二级索引。他们区别在于，聚集索引的叶子节点存放的是实际数据，所有完整的用户记录都存放在聚集索引的叶子节点，而二级索引的叶子节点存放的是主键值，而不是实际数据。

因为表的数据都是存放在聚集索引的叶子节点里，所以 InnoDB 存储引擎一定会为表创建一个聚集索引，且由于数据在物理上只会保存一份，所以聚簇索引只能有一个，而二级索引可以创建多个。

### 总结
MySQL 是会将数据持久化在硬盘，而存储功能是由 MySQL 存储引擎实现的，所以讨论 MySQL 使用哪种数据结构作为索引，实际上是在讨论存储引使用哪种数据结构作为索引，InnoDB 是 MySQL 默认的存储引擎，它就是采用了 B+ 树作为索引的数据结构。

要设计一个 MySQL 的索引数据结构，不仅仅考虑数据结构增删改的时间复杂度，更重要的是要考虑磁盘 I/0 的操作次数。因为索引和记录都是存放在硬盘，硬盘是一个非常慢的存储设备，我们在查询数据的时候，最好能在尽可能少的磁盘 I/0 的操作次数内完成。

二分查找树虽然是一个天然的二分结构，能很好的利用二分查找快速定位数据，但是它存在一种极端的情况，每当插入的元素都是树内最大的元素，就会导致二分查找树退化成一个链表，此时查询复杂度就会从 O(logn)降低为 O(n)。

为了解决二分查找树退化成链表的问题，就出现了自平衡二叉树，保证了查询操作的时间复杂度就会一直维持在 O(logn) 。但是它本质上还是一个二叉树，每个节点只能有 2 个子节点，随着元素的增多，树的高度会越来越高。

而树的高度决定于磁盘  I/O 操作的次数，因为树是存储在磁盘中的，访问每个节点，都对应一次磁盘 I/O 操作，也就是说树的高度就等于每次查询数据时磁盘 IO 操作的次数，所以树的高度越高，就会影响查询性能。

B 树和 B+ 都是通过多叉树的方式，会将树的高度变矮，所以这两个数据结构非常适合检索存于磁盘中的数据。

但是 MySQL 默认的存储引擎 InnoDB 采用的是 B+ 作为索引的数据结构，原因有：

- B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少。

- B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；

- B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。



### 8、详解死锁
说个很早之前自己遇到过数据库死锁问题。

有个业务主要逻辑就是新增订单、修改订单、查询订单等操作。然后因为订单是不能重复的，所以当时在新增订单的时候做了幂等性校验，做法就是在新增订单记录之前，先通过 select ... for update 语句查询订单是否存在，如果不存在才插入订单记录。

而正是因为这样的操作，当业务量很大的时候，就可能会出现死锁。

接下来跟大家聊下为什么会发生死锁，以及怎么避免死锁。

#### 死锁的发生
本次案例使用存储引擎 Innodb，隔离级别不可重复读（RR）。

接下来，我用实战的方式来带大家看看死锁是怎么发生的。

我建了一张订单表，其中 id 字段为主键索引，order_no 字段普通索引，也就是非唯一索引：

```cpp
CREATE TABLE `t_order` (
  `id` int NOT NULL AUTO_INCREMENT,
  `order_no` int DEFAULT NULL,
  `create_date` datetime DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `index_order` (`order_no`) USING BTREE
) ENGINE=InnoDB ;
```

假如现在 t_order 表里已经有了 6 条记录：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220104211055.png)

假设这时有两事务，一个事务要插入订单 1007 ，另外一个事务要插入订单 1008，因为需要对订单做幂等性校验，所以两个事务先要查询该订单是否存在，不存在才插入记录，过程如下：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220104211058.png)


可以看到，两个事务都陷入了等待状态（前提没有打开死锁检测），也就是发生了死锁，因为都在相互等待对方释放锁。

这里在查询记录是否存在的时候，使用了 select ... for update 语句，目的为了防止事务执行的过程中，有其他事务插入了记录，而出现幻读的问题。

如果没有使用 select ... for update 语句，而使用了单纯的select 语句，如果是两个订单号一样的请求同时进来，就会出现两个重复的订单，有可能出现幻读，如下图：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220104211102.jpg)



#### 为什么会产生死锁？
可重复读隔离级别下，是存在幻读的问题。

Innodb 引擎为了解决「可重复读」隔离级别下的幻读问题，就引出了 next-key 锁，它是记录锁和间隙锁的组合。

Record Loc，记录锁，锁的是记录本身；

Gap Lock，间隙锁，锁的就是两个值之间的空隙，以防止其他事务在这个空隙间插入新的数据，从而避免幻读现象。

普通的 select 语句是不会对记录加锁的，因为它是通过 MVCC 的机制实现的快照读，如果要在查询时对记录加行锁，可以使用下面这两个方式：

```cpp
begin;
//对读取的记录加共享锁
select ... lock in share mode;
commit; //锁释放

begin;
//对读取的记录加排他锁
select ... for update;
commit; //锁释放

```
行锁的释放时机是在事务提交（commit）后，锁就会被释放，并不是一条语句执行完就释放行锁。

比如，下面事务 A 查询语句会锁住(2, +∞]范围的记录，然后期间如果有其他事务在这个锁住的范围插入数据就会被阻塞。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20220104211108.png)


next-key 锁的加锁规则其实挺复杂的，在一些场景下会退化成记录锁或间隙锁.

需要注意的是，next-key lock 锁的是索引，而不是数据本身，所以如果 update 语句的 where 条件没有用到索引列，那么就会全表扫描，在一行行扫描的过程中，不仅给行加上了行锁，还给行两边的空隙也加上了间隙锁，相当于锁住整个表，然后直到事务结束才会释放锁。

所以在线上千万不要执行没有带索引条件的 update 语句，不然会造成业务停滞.

回到前面死锁的例子，在执行下面这条语句的时候：

```cpp
select id from t_order where order_no = 1008 for update;

```


因为 order_no 不是唯一索引，所以行锁的类型是间隙锁，于是间隙锁的范围是（1006, +∞）。那么，当事务 B 往间隙锁里插入 id = 1008 的记录就会被锁住。

因为当我们执行以下插入语句时，会在插入间隙上再次获取插入意向锁。

```cpp
insert into t_order (order_no, create_date) values (1008, now());

```


**插入意向锁与间隙锁是冲突的**，所以当其它事务持有该间隙的间隙锁时，需要等待其它事务释放间隙锁之后，才能获取到插入意向锁。而间隙锁与间隙锁之间是兼容的，所以两个事务中 select ... for update 语句并不会相互影响。

案例中的事务 A 和事务 B 在执行完后 select ... for update 语句后都持有范围为(1006,+∞）的间隙锁，而接下来的插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待，导致死锁。

#### 如何避免死锁？
死锁的四个必要条件：**互斥、占有且等待、不可强占用、循环等待**。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。

在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态：

- **设置事务等待锁的超时时间。**当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。在 InnoDB 中，参数 **innodb_lock_wait_timeout** 是用来设置超时时间的，默认值时 50 秒。

当发生超时后，就出现下面这个提示：

ERROR 1205 (HY000):Lock wait timeout exceede;try..

- **开启主动死锁检测。**主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑，默认就开启。

当检测到死锁后，就会出现下面这个提示：

ERROR 1213(40001):Deadlock found when trying to get lock;try...

上面这个两种策略是「当有死锁发生时」的避免方式。

我们可以回归业务的角度来预防死锁，对订单做幂等性校验的目的是为了保证不会出现重复的订单，那我们可以直接将 order_no 字段设置为唯一索引列，利用它的唯一性来保证订单表不会出现重复的订单，不过有一点不好的地方就是在我们插入一个已经存在的订单记录时就会抛出异常。








