## 一、基础篇

### 1.1 TCP/IP ⽹络模型

对于同⼀台设备上的进程间通信，有很多种⽅式，⽐如**管道、消息队列、共享内存、信号**等⽅式，⽽对于不同设备上的进程间通信，就需要⽹络通信，⽽设备是多样性的，所以要兼容多种多样的设备，就协商出了⼀套通⽤的**⽹络协议**。

这个⽹络协议是分层的，每⼀层都有各⾃的作⽤和职责。

#### 应用层
最上层的，也是我们能直接接触到的就是应⽤层（Application Layer），我们电脑或⼿机使⽤的应⽤软件都是在应⽤层实现。那么，当两个不同设备的应⽤需要通信的时候，应⽤就把应⽤数据传给下⼀层，也就是传输层。
所以，应⽤层只需要专注于为⽤户提供应⽤功能，不⽤去关⼼数据是如何传输的，就类似于，我们寄快递的时候，
只需要把包裹交给快递员，由他负责运输快递，我们不需要关⼼快速是如何被运输的。
⽽且**应⽤层是⼯作在操作系统中的⽤户态，传输层及以下则⼯作在内核态**。

#### 传输层
应⽤层的数据包会传给传输层，传输层（Transport Layer）是为应⽤层提供⽹络⽀持的。

![](https://img-blog.csdnimg.cn/img_convert/6301b3b9215e239874c8dd8ca412b2f0.png)

在传输层会有两个传输协议，分别是 TCP 和 UDP。

TCP 的全称叫传输层控制协议（Transmission Control Protocol），⼤部分应⽤使⽤的正是 TCP 传输层协议，⽐
如 HTTP 应⽤层协议。TCP 相⽐ UDP 多了很多特性，⽐如流量控制、超时重传、拥塞控制等，这些都是为了保证数据包能可靠地传输给对⽅。

UDP 就相对很简单，简单到只负责发送数据包，不保证数据包是否能抵达对⽅，但它实时性相对更好，传输效率也⾼。

**当然，UDP 也可以实现可靠传输，把 TCP 的特性在应⽤层上实现就可以**，不过要实现⼀个商⽤的可靠 UDP传输协议，也不是⼀件简单的事情。应⽤需要传输的数据可能会⾮常⼤，如果直接传输就不好控制，因此**当传输层的数据包⼤⼩超过 MSS（TCP 最⼤报⽂段⻓度） ，就要将数据包分块**，这样即使中途有⼀个分块丢失或损坏了，只需要重发这⼀个分块，⽽不⽤重新发送整个数据包。在 TCP 协议中，我们把每个分块称为⼀个 TCP （TCP Segment）。


![](https://img-blog.csdnimg.cn/img_convert/55a3ce0b0fce882f32bf0f16ddfc6314.png)

当设备作为接收⽅时，传输层则要负责把数据包传给应⽤，但是⼀台设备上可能会有很多应⽤在接收或者传输数据，因此需要⽤⼀个编号将应⽤区分开来，这个编号就是端⼝。

⽐如 80 端⼝通常是 Web 服务器⽤的，22 端⼝通常是远程登录服务器⽤的。⽽对于浏览器（客户端）中的每个标签栏都是⼀个独⽴的进程，操作系统会为这些进程分配临时的端⼝号。

由于传输层的报⽂中会携带端⼝号，因此接收⽅可以识别出该报⽂是发送给哪个应⽤。


#### ⽹络层
传输层可能⼤家刚接触的时候，会认为它负责将数据从⼀个设备传输到另⼀个设备，事实上它并不负责。

实际场景中的⽹络环节是错综复杂的，中间有各种各样的线路和分叉路⼝，如果⼀个设备的数据要传输给另⼀个设备，就需要在各种各样的路径和节点进⾏选择，⽽传输层的设计理念是简单、⾼效、专注，如果传输层还负责这⼀块功能就有点违背设计原则了。

也就是说，我们不希望传输层协议处理太多的事情，只需要服务好应⽤即可，让其作为应⽤间数据传输的媒介，帮助实现应⽤到应⽤的通信，⽽实际的传输功能就交给下⼀层，也就是⽹络层（Internet Layer）。

![](https://img-blog.csdnimg.cn/img_convert/fbb69a4e9f2058ec56ee078646642bd9.png)

⽹络层最常使⽤的是 IP 协议（Internet Protocol），**IP 协议会将传输层的报⽂作为数据部分，再加上 IP 包头组装成 IP 报⽂，如果 IP 报⽂⼤⼩超过 MTU（以太⽹中⼀般为 1500 字节）就会再次进⾏分⽚，得到⼀个即将发送到⽹络的 IP 报⽂。**


![](https://img-blog.csdnimg.cn/img_convert/37283dea169f93700501ce83f9295bce.png)
⽹络层负责将数据从⼀个设备传输到另⼀个设备，世界上那么多设备，⼜该如何找到对⽅呢？因此，⽹络层需要有
区分设备的编号。

我们⼀般⽤ IP 地址给设备进⾏编号，对于 IPv4 协议， IP 地址共 32 位，分成了四段，每段是 8 位。只有⼀个单纯的 IP 地址虽然做到了区分设备，但是寻址起来就特别麻烦，全世界那么多台设备，难道⼀个⼀个去匹配？这显然不科学。

因此，需要将 IP 地址分成两种意义：

 - List item ⼀个是 **⽹络号**，负责标识该 IP 地址是属于哪个⼦⽹的；

 - List item ⼀个是 **主机号**，负责标识同⼀⼦⽹下的不同主机；

怎么分的呢？这需要配合**⼦⽹掩码**才能算出 IP 地址 的⽹络号和主机号。那么在寻址的过程中，先匹配到相同的⽹络号，才会去找对应的主机。

除了寻址能⼒， IP 协议还有另⼀个重要的能⼒就是**路由**。实际场景中，两台设备并不是⽤⼀条⽹线连接起来的，⽽是通过很多⽹关、路由器、交换机等众多⽹络设备连接起来的，那么就会形成很多条⽹络的路径，因此当数据包到达⼀个⽹络节点，就需要通过算法决定下⼀步⾛哪条路径。

所以，**IP 协议的寻址作⽤是告诉我们去往下⼀个⽬的地该朝哪个⽅向⾛，路由则是根据「下⼀个⽬的地」选择路径。寻址更像在导航，路由更像在操作⽅向盘。**


#### 数据链路层
实际场景中，⽹络并不是⼀个整体，⽐如你家和我家就不属于⼀个⽹络，所以数据不仅可以在同⼀个⽹络中设备间进⾏传输，也可以跨⽹络进⾏传输。

⼀旦数据需要跨⽹络传输，就需要有⼀个设备同时在两个⽹络当中，这个设备⼀般是路由器，路由器可以通过路由表计算出下⼀个要去的IP 地址。

那问题来了，路由器怎么知道这个 IP 地址是哪个设备的呢？

于是，就需要有⼀个专⻔的层来标识⽹络中的设备，让数据在⼀个链路中传输，这就是数据链路层（Data LinkLayer），它主要为⽹络层提供链路级别传输的服务。

![](https://img-blog.csdnimg.cn/img_convert/68736cc1fcbf2b8344e927c65515f124.png)
每⼀台设备的⽹卡都会有⼀个 MAC 地址，它就是⽤来唯⼀标识设备的。路由器计算出了下⼀个⽬的地 IP 地址，再通过 ARP 协议找到该⽬的地的 MAC 地址，这样就知道这个 IP 地址是哪个设备的了。


#### 物理层
当数据准备要从设备发送到⽹络时，需要把数据包转换成电信号，让其可以在物理介质中传输，这⼀层就是物理层（Physical Layer），它主要是为数据链路层提供⼆进制传输的服务。
![](https://img-blog.csdnimg.cn/img_convert/d38184e84df101d5c69fbb36ec9d50d7.png)

综上所述，⽹络协议通常是由上到下，分成 5 层没，分别是**应⽤层，传输层，⽹络层，数据链路层和物理层。**


## 二、HTTP 篇
![](https://img-blog.csdnimg.cn/img_convert/cb3ad09f3c639711e8579eb11d7cc660.png)

### 2.1 HTTP 是什么？描述⼀下。
HTTP 是超⽂本传输协议，也就是HyperText Transfer Protocol。
### 2.2 能否详细解释「超⽂本传输协议」？
HTTP的名字「超⽂本协议传输」，它可以拆成三个部分：

 - 超⽂本
   
 - 传输
   
 - 协议

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20211130211900.png)

#### 1. 「协议」

在⽣活中，我们也能随处可⻅「协议」，例如：

刚毕业时会签⼀个「三⽅协议」；

找房⼦时会签⼀个「租房协议」；

⽣活中的协议，本质上与计算机中的协议是相同的，协议的特点:

「**协**」字，代表的意思是必须有**两个以上的参与者**。例如三⽅协议⾥的参与者有三个：你、公司、学校三个；租房协议⾥的参与者有两个：你和房东。

「**议**」字，代表的意思是对参与者的⼀种 **⾏为约定和规范**。例如三⽅协议⾥规定试⽤期期限、毁约⾦等；租房协议⾥规定租期期限、每⽉租⾦⾦额、违约如何处理等。

针对 HTTP 协议，我们可以这么理解。

HTTP 是⼀个⽤在计算机世界⾥的协议。它使⽤计算机能够理解的语⾔确⽴了⼀种计算机之间交流通信的规范（**两个以上的参与者**），以及相关的各种控制和错误处理⽅式（**⾏为约定和规范**）。


#### 2. 「传输」
所谓的「传输」，很好理解，就是把⼀堆东⻄从 A 点搬到 B 点，或者从 B 点 搬到 A 点。
别轻视了这个简单的动作，它⾄少包含两项重要的信息。

HTTP 协议是⼀个**双向协议**。
我们在上⽹冲浪时，浏览器是请求⽅ A ，百度⽹站就是应答⽅ B。双⽅约定⽤ HTTP 协议来通信，于是浏览器把请求数据发送给⽹站，⽹站再把⼀些数据返回给浏览器，最后由浏览器渲染在屏幕，就可以看到图⽚、视频了。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201094110.png)

数据虽然是在 A 和 B 之间传输，但允许中间有**中转或接⼒**。

就好像第⼀排的同学想传递纸条给最后⼀排的同学，那么传递的过程中就需要经过好多个同学（中间⼈），这样的传输⽅式就从「A < --- > B」，变成了「A <-> N <-> M <-> B」。

⽽在 HTTP ⾥，需要中间⼈遵从 HTTP 协议，只要不打扰基本的数据传输，就可以添加任意额外的东⻄。

针对传输，我们可以进⼀步理解了 HTTP。

HTTP 是⼀个在计算机世界⾥专⻔⽤来在**两点之间传输数据**的约定和规范。

#### 3. 「超⽂本」
HTTP 传输的内容是「超⽂本」。

我们先来理解「⽂本」，在互联⽹早期的时候只是简单的字符⽂字，但现在「⽂本」的涵义已经可以扩展为图⽚、视频、压缩包等，在 HTTP 眼⾥这些都算作「⽂本」。

再来理解「超⽂本」，它就是超越了普通⽂本的⽂本，它是⽂字、图⽚、视频等的混合体，最关键有超链接，能从⼀个超⽂本跳转到另外⼀个超⽂本。

HTML 就是最常⻅的超⽂本了，它本身只是纯⽂字⽂件，但内部⽤很多标签定义了图⽚、视频等的链接，再经过浏览器的解释，呈现给我们的就是⼀个⽂字、有画⾯的⽹⻚了。

**HTTP 是⼀个在计算机世界⾥专⻔在「两点」之间「传输」⽂字、图⽚、⾳频、视频等「超⽂本」数据的「约定和规范」。**

### 2.3 HTTP 常⻅的状态码有哪些？
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201100340.png)

- 1xx 类状态码属于提示信息，是协议处理中的⼀种中间状态，实际⽤到的⽐较少。

- 2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。

「200 OK」是最常⻅的成功状态码，表示⼀切正常。如果是 **⾮ HEAD** 请求，服务器返回的响应头 都会有 body数据。

「204 No Content」也是常⻅的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。

「206 Partial Content」是应⽤于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，⽽是其中的⼀部分，也是服务器处理成功的状态。

- 3xx 类状态码表示客户端请求的资源发送了变动，需要客户端⽤新的 URL  新发送请求获取资源，也就是重定向。

「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改⽤新的 URL 再次访问。

「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要⽤另⼀个 URL 来访问。
301 和 302 都会在响应头⾥使⽤字段 **Location** ，指明后续要跳转的 URL，浏览器会⾃动重定向新的 URL。

「304 Not Modified」不具有跳转的含义，表示资源未修改， 重定向已存在的缓冲⽂件，也称缓存重定向，⽤于缓存控制。


- 4xx 类状态码表示客户端发送的报⽂有误，服务器⽆法处理，也就是错误码的含义。

「400 Bad Request」表示客户端请求的报⽂有错误，但只是个笼统的错误。

「403 Forbidden」表示服务器禁⽌访问资源，并不是客户端的请求出错。

「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以⽆法提供给客户端。

- 5xx 类状态码表示客户端请求报⽂正确，但是服务器处理时内部发⽣了错误，属于服务器端的错误码。

「500 Internal Server Error」与 400 类型，是个笼统通⽤的错误码，服务器发⽣了什么错误，我们并不知道。

「501 Not Implemented」表示客户端请求的功能还不⽀持，类似“即将开业，敬请期待”的意思。

「502 Bad Gateway」通常是服务器作为⽹关或代理时返回的错误码，表示服务器⾃身⼯作正常，访问后端服务器
发⽣了错误。

「503 Service Unavailable」表示服务器当前很忙，暂时⽆法响应服务器，类似“⽹络服务正忙，请稍后 试”的意
思。

### 2.4 http 常⻅字段有哪些？
- **Host字段** ：客户端发送请求时，⽤来指定服务器的域名。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201101323.png)

有了 Host 字段，就可以将请求发往「同⼀台」服务器上的不同⽹站。

- **Content-Length 字段** ：服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据⻓度。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201101944.png)

如上⾯则是告诉浏览器，本次服务器回应的数据⻓度是 1000 个字节，后⾯的字节就属于下⼀个回应了。

- **Connection 字段**：常⽤于客户端要求服务器使⽤ TCP 持久连接，以便其他请求复⽤。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201102142.png)

HTTP/1.1 版本的默认连接都是**持久连接**，但为了兼容⽼版本的 HTTP，需要指定 Connection ⾸部字段的值为
**keep-Alive** 。
⼀个可以复⽤的 TCP 连接就建⽴了，直到客户端或服务器主动关闭连接。但是，这不是标准字段。

- **Content-Type 字段**:⽤于服务器回应时，告诉客户端，本次数据是什么格式。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201102506.png)

上⾯的类型表明，发送的是⽹⻚，⽽且编码是UTF-8。

客户端请求的时候，可以使⽤ Accept 字段声明⾃⼰可以接受哪些数据格式。

Accept: * **/** *

上⾯代码中，客户端声明⾃⼰可以接受任何格式的数据。

- **Content-Encoding 字段** ：说明数据的压缩⽅法。表示服务器返回的数据使⽤了什么压缩格式

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201102902.png)

上⾯表示服务器返回的数据采⽤了 gzip ⽅式压缩，告知客户端需要⽤此⽅式解压。

客户端在请求时，⽤ Accept-Encoding 字段说明⾃⼰可以接受哪些压缩⽅法。

Accept-Encoding: gzip, deflate


### 2.5 说⼀下 GET 和 POST 的区别？
Get ⽅法的含义是请求从服务器获取资源，这个资源可以是静态的⽂本、⻚⾯、图⽚视频等。

⽐如，你打开我的⽂章，浏览器就会发送 GET 请求给服务器，服务器就会返回⽂章的所有⽂字及资源。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201103341.png)


⽽ POST ⽅法则是相反操作，它向 URI 指定的资源提交数据，数据就放在报⽂的 body ⾥。

⽐如，你在我⽂章底部，敲⼊了留⾔后点击「提交」（暗示你们留⾔），浏览器就会执⾏⼀次 POST 请求，把你的留⾔⽂字放进了报⽂ body ⾥，然后拼接好 POST 请求头，通过 TCP 协议发送给服务器。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201104454.png)

### 2.6 GET 和 POST ⽅法都是安全和幂等的吗？
先说明下安全和幂等的概念：
- 在 HTTP 协议⾥，所谓的「安全」是指请求⽅法不会「破坏」服务器上的资源。
- 所谓的「幂等」，意思是多次执⾏相同的操作，结果都是「相同」的。

那么很明显 GET ⽅法就是安全且幂等的，因为它是「只读」操作，⽆论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。

POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。

### 2.7  HTTP（1.1） 的优点有哪些，怎么体现的？
HTTP 最凸出的优点是「简单、灵活和易于扩展、应⽤⼴泛和跨平台」。

- 简单

HTTP 基本的报⽂格式就是 header + body ，头部信息也是 key-value 简单⽂本的形式，易于理解，降低了学习和使⽤的⻔槛。

- 灵活和易于扩展

HTTP协议⾥的各类请求⽅法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发⼈员⾃定义和扩充。

同时 HTTP 由于是⼯作在应⽤层（ OSI 第七层），则它下层可以随意变化。

HTTPS 也就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层，HTTP/3 甚⾄把 TCP 层换成了基于 UDP 的QUIC。

- 应⽤⼴泛和跨平台

互联⽹发展⾄今，HTTP 的应⽤范围⾮常的⼴泛，从台式机的浏览器到⼿机上的各种 APP，从看新闻、刷贴吧到购物、理财、吃鸡，HTTP 的应⽤⽚地开花，同时天然具有跨平台的优越性。

### 2.8  HTTP（1.1） 的缺点呢？

HTTP 协议⾥有优缺点⼀体的双刃剑，分别是「⽆状态、明⽂传输」，同时还有⼀⼤缺点「不安全」。

#### 1. ⽆状态双刃剑
⽆状态的好处，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存⽤来对外提供服务。

⽆状态的坏处，既然服务器没有记忆能⼒，它在完成有关联性的操作时会⾮常麻烦。

例如登录->添加购物⻋->下单->结算->⽀付，这系列操作都要知道⽤户的身份才⾏。但服务器不知道这些请求是有关联的，每次都要问⼀遍身份信息。

对于⽆状态的问题，解法⽅案有很多种，其中⽐较简单的⽅式⽤ Cookie 技术。

Cookie 通过在请求和响应报⽂中写⼊ Cookie 信息来控制客户端的状态。

相当于，在客户端第⼀次请求后，服务器会下发⼀个装有客户信息的「⼩贴纸」，后续客户端请求服务器的时候，带上「⼩贴纸」，服务器就能认得了了.

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201111802.png)

#### 2. 明⽂传输双刃剑
明⽂意味着在传输过程中的信息，是可⽅便阅读的，通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接⾁眼查看，为我们调试⼯作带了极⼤的便利性。

但是这正是这样，HTTP 的所有信息都暴露在了光天化⽇下，相当于信息裸奔。在传输的漫⻓的过程中，信息的内
容都毫⽆隐私可⾔，很容易就能被窃取，如果⾥⾯有你的账号密码信息，**那你号没了**。


#### 3. 不安全
HTTP ⽐较严重的缺点就是不安全：
- 通信使⽤明⽂（不加密），内容可能会被窃听。⽐如，账号信息容易泄漏，那你号没了。
- 不验证通信⽅的身份，因此有可能遭遇伪装。⽐如，访问假的淘宝、拼多多，那你钱没了。
- ⽆法证明报⽂的完整性，所以有可能已遭篡改。⽐如，⽹⻚上植⼊垃圾⼴告，视觉污染，眼没了。

HTTP 的安全问题，可以⽤ HTTPS 的⽅式解决，也就是通过引⼊ SSL/TLS 层，使得在安全上达到了极致。

### 2.9 那你再说下 HTTP/1.1 的性能如何？
HTTP 协议是基于 **TCP/IP**，并且使⽤了 **「请求 - 应答」** 的通信模式，所以性能的关键就在这两点⾥。

#### 1. ⻓连接

早期 HTTP/1.0 性能上的⼀个很⼤的问题，那就是每发起⼀个请求，都要新建⼀次 TCP 连接（三次握⼿），⽽且是串⾏请求，做了⽆谓的 TCP 连接建⽴和断开，增加了通信开销。

为了解决上述 TCP 连接问题，HTTP/1.1 提出了⻓连接的通信⽅式，也叫持久连接。这种⽅式的好处在于减少了TCP 连接的重复建⽴和断开所造成的额外开销，减轻了服务器端的负载。

持久连接的特点是，只要任意⼀端没有明确提出断开连接，则保持 TCP 连接状态。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201112821.png)

#### 2. 管道⽹络传输
HTTP/1.1 采⽤了⻓连接的⽅式，这使得管道（pipeline）⽹络传输成为了可能。

即可在同⼀个 TCP 连接⾥⾯，客户端可以发起多个请求，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以**减少整体的响应时间**。

举例来说，客户端需要请求两个资源。以前的做法是，在同⼀个TCP连接⾥⾯，先发送 A 请求，然后等待服务器做出回应，收到后再发出 B 请求。管道机制则是允许浏览器同时发出 A 请求和 B 请求。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201113357.png)

但是服务器还是按照顺序，先回应 A 请求，完成后再回应 B 请求。要是前⾯的回应特别慢，后⾯就会有许多请求排队等着。这称为「队头堵塞」。


#### 3. 队头阻塞
「请求 - 应答」的模式加剧了 HTTP 的性能问题。
因为当顺序发送的请求序列中的⼀个请求因为某种原因被阻塞时，在后⾯排队的所有请求也⼀同被阻塞了，会招致客户端⼀直请求不到数据，这也就是「队头阻塞」。好⽐上班的路上塞⻋。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201113703.png)

总之 HTTP/1.1 的性能⼀般般，后续的 HTTP/2 和 HTTP/3 就是在优化 HTTP 的性能。


### 2.10 HTTP 与 HTTPS 有哪些区别？
1. HTTP 是超⽂本传输协议，信息是明⽂传输，存在安全⻛险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在TCP 和 HTTP ⽹络层之间加⼊了 SSL/TLS 安全协议，使得报⽂能够加密传输。

2. HTTP 连接建⽴相对简单， TCP 三次握⼿之后便可进⾏ HTTP 的报⽂传输。⽽ HTTPS 在 TCP 三次握⼿之后，还需进⾏ SSL/TLS 的握⼿过程，才可进⼊加密报⽂传输。

3. HTTP 的端⼝号是 80，HTTPS 的端⼝号是 443。

4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

### 2.11 HTTPS 解决了 HTTP 的哪些问题？
HTTP 由于是明⽂传输，所以安全上存在以下三个⻛险：

- 窃听⻛险，⽐如通信链路上可以获取通信内容，⽤户号容易没。
- 篡改⻛险，⽐如强制植⼊垃圾⼴告，视觉污染，⽤户眼容易瞎。
- 冒充⻛险，⽐如冒充淘宝⽹站，⽤户钱容易没。

HTTPS 在 HTTP 与 TCP 层之间加⼊了 SSL/TLS 协议，可以很好的解决了上述的⻛险：
- 信息加密：交互信息⽆法被窃取，但你的号会因为「⾃身忘记」账号⽽没。
- 校验机制：⽆法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾⼴告。
- 身份证书：证明淘宝是真的淘宝⽹，但你的钱还是会因为「剁⼿」⽽没。


### 2.12 HTTPS 具体是如何解决上⾯的三个⻛险的？
1、**混合加密**的⽅式实现信息的机密性，解决了窃听的⻛险。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201115157.png)

HTTPS 采⽤的是对称加密和⾮对称加密结合的「混合加密」⽅式：
- 在通信建⽴前采⽤⾮对称加密的⽅式交换「会话秘钥」，后续就不再使⽤⾮对称加密。
- 在通信过程中全部使⽤对称加密的「会话秘钥」的⽅式加密明⽂数据。

采⽤「混合加密」的⽅式的原因：

- 对称加密只使⽤⼀个密钥，运算速度快，密钥必须保密，⽆法做到安全的密钥交换。
- ⾮对称加密使⽤两个密钥：公钥和私钥，公钥可以任意分发⽽私钥保密，解决了密钥交换问题但速度慢。

2、**摘要算法**的⽅式来实现完整性，它能够为数据⽣成独⼀⽆⼆的「指纹」，指纹⽤于校验数据的完整性，解决了篡改的⻛险。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201115953.png)

客户端在发送明⽂之前会通过摘要算法算出明⽂的「指纹」，发送的时候把「指纹 + 明⽂」⼀同加密成密⽂后，发送给服务器，服务器解密后，⽤相同的摘要算法算出发送过来的明⽂，通过⽐较客户端携带的「指纹」和当前算出的「指纹」做⽐较，若「指纹」相同，说明数据是完整的。

3、将服务器公钥放⼊到**数字证书**中，解决了冒充的⻛险。

客户端先向服务器端索要公钥，然后⽤公钥加密信息，服务器收到密⽂后，⽤⾃⼰的私钥解密。

这就存在些问题，如何保证公钥不被篡改和信任度？

所以这⾥就需要借助第三⽅权威机构 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201121704.png)


### 2.13 HTTPS 是如何建⽴连接的？其间交互了什么？

SSL/TLS 协议基本流程：

客户端向服务器索要并验证服务器的公钥。

双⽅协商⽣产「会话秘钥」。

双⽅采⽤「会话秘钥」进⾏加密通信。

前两步也就是 SSL/TLS 的建⽴过程，也就是握⼿阶段。

SSL/TLS 的「握⼿阶段」涉及四次通信，可⻅下图：
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201122616.png)
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201122635.png)
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201122641.png)
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201122649.png)
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201122652.png)

SSL/TLS 协议建⽴的详细流程：
#### 1. ClientHello

⾸先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。

在这⼀步，客户端主要向服务器发送以下信息：

（1）客户端⽀持的 SSL/TLS 协议版本，如 TLS 1.2 版本。

（2）客户端⽣产的随机数（ Client Random ），后⾯⽤于⽣产「会话秘钥」。

（3）客户端⽀持的密码套件列表，如 RSA 加密算法。

#### 2. SeverHello
服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello 。服务器回应的内容有如下内容：

（1）确认 SSL/ TLS 协议版本，如果浏览器不⽀持，则关闭加密通信。

（2）服务器⽣产的随机数（ Server Random ），后⾯⽤于⽣产「会话秘钥」。

（3）确认的密码套件列表，如 RSA 加密算法。

（4）服务器的数字证书。

#### 3.客户端回应
客户端收到服务器的回应之后，⾸先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。

如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使⽤它加密报⽂，向服务器发送如下信息：

（1）⼀个随机数（ pre-master key ）。该随机数会被服务器公钥加密。

（2）加密通信算法改变通知，表示随后的信息都将⽤「会话秘钥」加密通信。

（3）客户端握⼿结束通知，表示客户端的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘要，⽤来供服务端校验。

上⾯第⼀项的随机数是整个握⼿阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着就⽤双⽅协商的加密算法，各⾃⽣成本次通信的「会话秘钥」。

#### 4. 服务器的最后回应
服务器收到客户端的第三个随机数（ pre-master key ）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。然后，向客户端发⽣最后的信息：

（1）加密通信算法改变通知，表示随后的信息都将⽤「会话秘钥」加密通信。

（2）服务器握⼿结束通知，表示服务器的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘要，⽤来供客户端校验。

⾄此，整个 SSL/TLS 的握⼿阶段全部结束。接下来，客户端与服务器进⼊加密通信，就完全是使⽤普通的 HTTP协议，只不过⽤「会话秘钥」加密内容。

### 2.14 说说 HTTP/1.1 相⽐ HTTP/1.0 提⾼了什么性能？
HTTP/1.1 相⽐ HTTP/1.0 性能上的改进：
- 使⽤ TCP ⻓连接的⽅式改善了 HTTP/1.0 短连接造成的性能开销。
- ⽀持管道（pipeline）⽹络传输，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以减少整体的响应时间。

但 HTTP/1.1 还是有性能瓶颈：

- 请求 / 响应头部（Header）未经压缩就发送，⾸部信息越多延迟越⼤。只能压缩 Body 的部分；

- 发送冗⻓的⾸部。每次互相发送相同的⾸部造成的浪费较多；

- 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端⼀直请求不到数据，也就是队头阻塞；

- 没有请求优先级控制；

- 请求只能从客户端开始，服务器只能被动响应。

### 2.15 那上⾯的 HTTP/1.1 的性能瓶颈，HTTP/2 做了什么优化？
HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。

那 HTTP/2 相⽐ HTTP/1.1 性能上的改进：
#### 1. 头部压缩
HTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是⼀样的或是相似的，那么，协议会帮你消除重复的部分。

这就是所谓的 HPACK 算法：在客户端和服务器同时维护⼀张头信息表，所有字段都会存⼊这个表，⽣成⼀个索引号，以后就不发送同样字段了，只发送索引号，这样就提⾼速度了。

#### 2. ⼆进制格式
HTTP/2 不再像 HTTP/1.1 ⾥的纯⽂本形式的报⽂，⽽是全⾯采⽤了⼆进制格式，头信息和数据体都是⼆进制，并且统称为帧（frame）：头信息帧和数据帧。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201124621.png)

这样虽然对⼈不友好，但是对计算机⾮常友好，因为计算机只懂⼆进制，那么收到报⽂后，⽆需再将明⽂的报⽂转成⼆进制，⽽是直接解析⼆进制报⽂，这**增加了数据传输的效率**。

#### 3. 数据流
HTTP/2 的数据包不是按顺序发送的，同⼀个连接⾥⾯连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。

每个请求或回应的所有数据包，称为⼀个数据流（ Stream ）。每个数据流都标记着⼀个独⼀⽆⼆的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数

客户端还可以**指定数据流的优先级**。优先级⾼的请求，服务器就先响应该请求。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201125028.png)

#### 4. 多路复⽤
HTTP/2 是可以在⼀个连接中并发多个请求或回应，⽽不⽤按照顺序⼀⼀对应。

移除了 HTTP/1.1 中的串⾏请求，不需要排队等待，也就不会再出现「队头阻塞」问题，**降低了延迟，⼤幅度提⾼了连接的利⽤率**。

举例来说，在⼀个 TCP 连接⾥，服务器收到了客户端 A 和 B 的两个请求，如果发现 A 处理过程⾮常耗时，于是就回应 A 请求已经处理好的部分，接着回应 B 请求，完成后，再回应 A 请求剩下的部分。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201125349.png)

#### 5. 服务器推送
HTTP/2 还在⼀定程度上改善了传统的「请求 - 应答」⼯作模式，服务不再是被动地响应，也可以主动向客户端发送消息。

举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会⽤到的 JS、CSS ⽂件等静态资源主动发给客户端，减少延时的等待，也就是服务器推送（Server Push，也叫 Cache Push）。

### 2.16 HTTP/2 有哪些缺陷？HTTP/3 做了哪些优化？
HTTP/2 主要的问题在于，多个 HTTP 请求在复⽤⼀个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。所以⼀旦发⽣了丢包现象，就会触发 TCP 的重传机制，这样在⼀个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。

- HTTP/1.1 中的管道（ pipeline）传输中如果有⼀个请求阻塞了，那么队列后请求也统统被阻塞住了
- HTTP/2 多个请求复⽤⼀个TCP连接，⼀旦发⽣丢包，就会阻塞住所有的 HTTP 请求。

这都是基于 TCP 传输层的问题，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201130344.png)


UDP 发⽣是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的⼀个丢包全部 传问题。

⼤家都知道 UDP 是不可靠传输的，但基于 UDP 的 **QUIC** 协议 可以实现类似 TCP 的可靠性传输。
- QUIC 有⾃⼰的⼀套机制可以保证传输的可靠性的。当某个流发⽣丢包时，只会阻塞这个流，其他流不会受到影响。

- TLS3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack 。

- HTTPS 要建⽴⼀个连接，要花费 6 次交互，先是建⽴三次握⼿，然后是 TLS/1.3 的三次握⼿。QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数。

### 2.17 https和http相⽐，就是传输的内容多了对称加密，可以这么理解吗？

1. 建⽴连接时候：https ⽐ http多了 TLS 的握⼿过程；
2. 传输内容的时候：https 会把数据进⾏加密，通常是对称加密数据；

### 2.18 为啥 ssl 的握⼿是 4 次？
SSL/TLS 1.2 需要 4 握⼿，需要 2 个 RTT 的时延.

另外， SSL/TLS 1.3 优化了过程，只需要 1 个 RTT 往返时延，也就是只需要 3 次握⼿：

### 2.19 HTTP/1.1如何优化？
我想你第⼀时间想到的是，使⽤ KeepAlive 将 HTTP/1.1 从短连接改成⻓链接。

这个确实是⼀个优化的⼿段，它是从底层的传输层这⼀⽅向⼊⼿的，通过减少 TCP 连接建⽴和断开的次数，来减少了⽹络传输的延迟，从⽽提⾼ HTTP/1.1 协议的传输效率。

但其实还可以从其他⽅向来优化 HTTP/1.1 协议，⽐如有如下 3 种优化思路：
- 尽量避免发送 HTTP 请求；
- 在需要发送 HTTP 请求时，考虑如何减少请求次数；
- 减少服务器的 HTTP 响应的数据⼤⼩；

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201131938.png)


#### 1、如何避免发送 HTTP 请求？
- 对于⼀些具有重复性的 HTTP 请求，⽐如每次请求得到的数据都⼀样的，我们可以把这对「请求-响应」的数据都**缓存在本地**，那么下次就直接读取本地的数据，不必在通过⽹络获取服务器的响应了。

- 所以，避免发送 HTTP 请求的⽅法就是通过**缓存技术**，HTTP 设计者早在之前就考虑到了这点，因此 HTTP 协议的头部有不少是针对缓存的字段。


那缓存是如何做到的呢？

客户端会把第⼀次请求以及响应的数据保存在本地磁盘上，其中将请求的 URL 作为 key，⽽响应作为 value，两者形成映射关系。

这样当后续发起相同的请求时，就可以先在本地磁盘上通过 key 查到对应的 value，也就是响应，如果找到了，就直接从本地读取该响应。毋庸置疑，读取本次磁盘的速度肯定⽐⽹络请求快得多，如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201132559.png)

聪明的你可能想到了，万⼀缓存的响应不是最新的，⽽客户端并不知情，那么该怎么办呢？

放⼼，这个问题 HTTP 设计者早已考虑到。

所以，服务器在发送 HTTP 响应时，会估算⼀个过期的时间，并把这个信息放到响应头部中，这样客户端在查看响应头部的信息时，⼀旦发现缓存的响应是过期的，则就会重新发送⽹络请求。

如果客户端从第⼀次请求得到的响应头部中发现该响应过期了，客户端重新发送请求，假设服务器上的资源并没有变更，还是⽼样⼦，那么你觉得还要在服务器的响应带上这个资源吗？

很显然不带的话，可以提⾼ HTTP 协议的性能，那具体如何做到呢？

只需要客户端在重新发送请求时，在请求的 Etag 头部带上第⼀次请求的响应头部中的摘要，这个摘要是唯⼀标识响应的资源，当服务器收到请求后，会将本地资源的摘要与请求中的摘要做个⽐较。

如果不同，那么说明客户端的缓存已经没有价值，服务器在响应中带上最新的资源。

如果相同，说明客户端的缓存还是可以继续使⽤的，那么服务器仅返回不含有包体的 304 Not Modified 响应，告诉客户端仍然有效，这样就可以减少响应资源在⽹络中传输的延时，如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201133233.png)

缓存真的是性能优化的⼀把万能钥匙，⼩到 CPU Cache、Page Cache、Redis Cache，⼤到 HTTP 协议的缓存。

#### 2、如何减少 HTTP 请求次数？
- 减少重定向请求次数；
- 合并请求；
- 延迟发送请求；

##### 减少重定向请求次数
我们先来看看什么是重定向请求？

服务器上的⼀个资源可能由于迁移、维护等原因从 url1 移⾄ url2 后，⽽客户端不知情，它还是继续请求 url1，这
时服务器不能粗暴地返回错误，⽽是通过 302 响应码和 Location 头部，告诉客户端该资源已经迁移⾄ url2
了，于是客户端需要再发送 url2 请求以获得服务器的资源。

那么，如果重定向请求越多，那么客户端就要多次发起 HTTP 请求，每⼀次的 HTTP 请求都得经过⽹络，这⽆疑会
越降低⽹络性能。

另外，服务端这⼀⽅往往不只有⼀台服务器，⽐如源服务器上⼀级是代理服务器，然后代理服务器才与客户端通
信，这时客户端重定向就会导致客户端与代理服务器之间需要 2 次消息传递，如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201141937.png)

如果重定向的⼯作交由代理服务器完成，就能减少 HTTP 请求次数了:
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201143932.png)

⽽且当代理服务器知晓了重定向规则后，可以进⼀步减少消息传递次数，如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201144221.png)


除了 302 重定向响应码，还有其他⼀些重定向的响应码，你可以从下图看到：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201144524.png)

其中， 301 和 308 响应码是告诉客户端可以将重定向响应缓存到本地磁盘，之后客户端就⾃动⽤ url2 替代 url1
访问服务器的资源。

##### 合并请求
如果把多个访问⼩⽂件的请求合并成⼀个⼤的请求，虽然传输的总资源还是⼀样，但是减少请求，也就意味着**减少了重复发送的HTTP头部 。**

另外由于 HTTP/1.1 是请求响应模型，如果第⼀个发送的请求，未收到对应的响应，那么后续的请求就不会发送，
于是为了防⽌单个请求的阻塞，所以⼀般浏览器会同时发起 5-6 个请求，每⼀个请求都是不同的 TCP 连接，那么
如果合并了请求，也就会减少 **TCP 连接的数量，因⽽省去了 TCP 握⼿和慢启动过程耗费的时间**。

接下来，具体看看合并请求的⼏种⽅式。

有的⽹⻚会含有很多⼩图⽚、⼩图标，有多少个⼩图⽚，客户端就要发起多少次请求。那么对于这些⼩图⽚，我们
可以考虑使⽤ CSS Image Sprites 技术把它们合成⼀个⼤图⽚，这样浏览器就可以⽤⼀次请求获得⼀个⼤图⽚，
然后再根据 CSS 数据把⼤图⽚切割成多张⼩图⽚。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201145524.png)


这种⽅式就是通过将多个⼩图⽚合并成⼀个⼤图⽚来减少 HTTP 请求的次数，从⽽减少⽹络的开销。

除了将⼩图⽚合并成⼤图⽚的⽅式，还有服务端使⽤ webpack 等打包⼯具将 js、css 等资源合并打包成⼤⽂
件，也是能达到类似的效果。

另外，还可以将图⽚的⼆进制数据⽤ base64 编码后，以 URL 的形式潜⼊到 HTML ⽂件，跟随 HTML ⽂件⼀并
发送.
```cpp
<image
 src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPoAAAFKCAIAAAC7M9WrAAAACXBIWXMAA ...
/>
```

这样客户端收到 HTML 后，就可以直接解码出数据，然后直接显示图⽚，就不⽤再发起图⽚相关的请求，这样便减
少了请求的次数。



可以看到，**合并请求的⽅式就是合并资源，以⼀个⼤资源的请求替换多个⼩资源的请求。**

但是这样的合并请求会带来新的问题，当⼤资源中的某⼀个⼩资源发⽣变化后，客户端必须重新下载整个完整的⼤
资源⽂件，这显然带来了额外的⽹络消耗。

##### 延迟发送请求
不要⼀⼝⽓吃成⼤胖⼦，⼀般 HTML ⾥会含有很多 HTTP 的 URL，当前不需要的资源，我们没必要也获取过来，
于是可以通过「按需获取」的⽅式，来减少第⼀时间的 HTTP 请求次数。

请求⽹⻚的时候，没必要把全部资源都获取到，⽽是只获取当前⽤户所看到的⻚⾯资源，当⽤户向下滑动⻚⾯的时
候，再向服务器获取接下来的资源，这样就达到了延迟发送请求的效果。


#### 3、如何减少 HTTP 请求次数？
对于 HTTP 的请求和响应，通常 HTTP 的响应的数据⼤⼩会⽐较⼤，也就是服务器返回的资源会⽐较⼤。

于是，我们可以考虑对响应的资源进⾏**压缩**，这样就可以减少响应的数据⼤⼩，从⽽提⾼⽹络传输的效率。

压缩的⽅式⼀般分为 2 种，分别是：

- ⽆损压缩；

⽆损压缩是指资源经过压缩后，信息不被破坏，还能完全恢复到压缩前的原样，适合⽤在⽂本⽂件、程序可执⾏⽂
件、程序源代码。

⾸先，我们针对代码的语法规则进⾏压缩，因为通常代码⽂件都有很多换⾏符或者空格，这些是为了帮助程序员更
好的阅读，但是机器执⾏时并不要这些符，把这些多余的符号给去除掉。

接下来，就是⽆损压缩了，需要对原始资源建⽴统计模型，利⽤这个统计模型，将常出现的数据⽤较短的⼆进制⽐
特序列表示，将不常出现的数据⽤较⻓的⼆进制⽐特序列表示，⽣成⼆进制⽐特序列⼀般是「霍夫曼编码」算法。

gzip 就是⽐较常⻅的⽆损压缩。客户端⽀持的压缩算法，会在 HTTP 请求中通过头部中的 Accept-Encoding 字
段告诉服务器：

Accept-Encoding: gzip, deflate, br

服务器收到后，会从中选择⼀个服务器⽀持的或者合适的压缩算法，然后使⽤此压缩算法对响应资源进⾏压缩，最
后通过响应头部中的 content-encoding 字段告诉客户端该资源使⽤的压缩算法。
gzip 的压缩效率相⽐ Google 推出的 Brotli 算法还是差点意思，也就是上⽂中的 br，所以如果可以，服务器应该选
择压缩效率更⾼的 br 压缩算法。

content-encoding: gzip

gzip 的压缩效率相⽐ Google 推出的 Brotli 算法还是差点意思，也就是上⽂中的 br，所以如果可以，服务器应该选
择压缩效率更⾼的 br 压缩算法。

- 有损压缩；

与⽆损压缩相对的就是有损压缩，经过此⽅法压缩，解压的数据会与原始数据不同但是⾮常接近。


有损压缩主要将次要的数据舍弃，牺牲⼀些质 来减少数据 、提⾼压缩⽐，这种⽅法经常⽤于压缩多媒体数据，
⽐如⾳频、视频、图⽚。


可以通过 HTTP 请求头部中的 Accept 字段⾥的「 q 质 因⼦」，告诉服务器期望的资源质量。
Accept: audio/*; q=0.2, audio/basic

关于图⽚的压缩，⽬前压缩⽐较⾼的是 Google 推出的 WebP 格式，相同图⽚质 下，WebP 格式的图⽚⼤⼩都⽐ Png 格式的图⽚⼩，所以对于⼤ 图⽚的⽹站，可以考虑使⽤ WebP 格式的图⽚，这将⼤幅度提升⽹络传输的性能。


关于⾳视频的压缩，⾳视频主要是动态的，每个帧都有时序的关系，通常时间连续的帧之间的变化是很⼩的。

⽐如，⼀个在看书的视频，画⾯通常只有⼈物的⼿和书桌上的书是会有变化的，⽽其他地⽅通常都是静态的，于是
只需要在⼀个静态的关键帧，使⽤**增量数据**来表达后续的帧，这样便减少了很多数据，提⾼了⽹络传输的性能。对
于视频常⻅的编码格式有 H264、H265 等，⾳频常⻅的编码格式有 AAC、AC3。


### 总结
这次主要从 3 个⽅⾯介绍了优化 HTTP/1.1 协议的思路。

第⼀个思路是，通过缓存技术来避免发送 HTTP 请求。客户端收到第⼀个请求的响应后，可以将其缓存在本地磁
盘，下次请求的时候，如果缓存没过期，就直接读取本地缓存的响应数据。如果缓存过期，客户端发送请求的时候
带上响应数据的摘要，服务器⽐对后发现资源没有变化，就发出不带包体的 304 响应，告诉客户端缓存的响应仍然
有效。

第⼆个思路是，减少 HTTP 请求的次数，有以下的⽅法：

1. 将原本由客户端处理的 定向请求，交给代理服务器处理，这样可以减少 定向请求的次数；

2. 将多个⼩资源合并成⼀个⼤资源再传输，能够减少 HTTP 请求次数以及 头部的 复传输，再来减少 TCP 连
接数 ，进⽽省去 TCP 握⼿和慢启动的⽹络消耗；

3. 按需访问资源，只访问当前⽤户看得到/⽤得到的资源，当客户往下滑动，再访问接下来的资源，以此达到延迟请求，也就减少了同⼀时间的 HTTP 请求次数。

第三思路是，通过压缩响应资源，降低传输资源的⼤⼩，从⽽提⾼传输效率，所以应当选择更优秀的压缩算法。

### 2.20 HTTPS RSA 握⼿解析
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201152031.png)


#### TLS 握⼿过程
HTTP 由于是明⽂传输，所谓的明⽂，就是说客户端与服务端通信的信息都是⾁眼可⻅的，随意使⽤⼀个抓包⼯具都可以截获通信的内容。

所以安全上存在以下三个⻛险：
- 窃听⻛险，⽐如通信链路上可以获取通信内容，⽤户号容易没。

- 篡改⻛险，⽐如强制植⼊垃圾⼴告，视觉污染，⽤户眼容易瞎。

- 冒充⻛险，⽐如冒充淘宝⽹站，⽤户钱容易没。

HTTPS 在 HTTP 与 TCP 层之间加⼊了 TLS 协议，来解决上述的⻛险。

TLS 协议是如何解决 HTTP 的⻛险的呢？

- 信息加密： HTTP 交互信息是被加密的，第三⽅就⽆法被窃取；

- 校验机制：校验信息传输过程中是否有被第三⽅篡改过，如果被篡改过，则会有警告提示；

- 身份证书：证明淘宝是真的淘宝⽹；

可⻅，有了 TLS 协议，能保证 HTTP 通信是安全的了，那么在进⾏ HTTP 通信前，需要先进⾏ TLS 握⼿。TLS 的握⼿过程，如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201152455.png)

上图简要概述来 TLS 的握⼿过程，其中每⼀个「框」都是⼀个记录（record），记录是 TLS 收发数据的基本单位，类似于 TCP ⾥的 segment。

多个记录可以组合成⼀个 TCP 包发送，所以通常经过 **「四个消息」就可以完成TLS 握⼿，也就是需要2个RTT 的时延**，然后就可以在安全的通信环境⾥发送 HTTP 报⽂，实现 HTTPS 协议。

所以可以发现，HTTPS 是应⽤层协议，需要先完成 TCP 连接建⽴，然后⾛ TLS 握⼿过程后，才能建⽴通信安全的连接。


事实上，不同的密钥交换算法，TLS 的握⼿过程可能会有⼀些区别。

这⾥先简单介绍下密钥交换算法，因为考虑到性能的问题，所以双⽅在加密应⽤信息时使⽤的是对称加密密钥，⽽对称加密密钥是不能被泄漏的，为了保证对称加密密钥的安全性，所以使⽤⾮对称加密的⽅式来保护对称加密密钥的协商，这个⼯作就是密钥交换算法负责的。

接下来，我们就以最简单的 RSA 密钥交换算法，来看看它的 TLS 握⼿过程。

### 2.21 RSA 握⼿过程

传统的 TLS 握⼿基本都是使⽤ RSA 算法来实现密钥交换的，在将 TLS 证书部署服务端时，证书⽂件中包含⼀对公私钥，其中公钥会在 TLS 握⼿阶段传递给客户端，私钥则⼀直留在服务端，⼀定要确保私钥不能被窃取。

在 RSA 密钥协商算法中，客户端会⽣成随机密钥，并使⽤服务端的公钥加密后再传给服务端。根据⾮对称加密算法，公钥加密的消息仅能通过私钥解密，这样服务端解密后，双⽅就得到了相同的密钥，再⽤它加密应⽤消息。


⽤ Wireshark ⼯具抓了⽤ RSA 密钥交换的 TLS 握⼿过程，可以从下⾯看到，⼀共经历了四次握⼿：
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202084146.png)


对应 Wireshark 的抓包，我也画了⼀幅图，你可以从下图很清晰地看到该过程：
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202084146.png)


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202091728.png)



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202084414.png)



那么，接下来针对每⼀个 TLS 握⼿做进⼀步的介绍。

#### TLS 第⼀次握⼿
客户端⾸先会发⼀个「Client Hello」消息，字⾯意思我们也能理解到，这是跟服务器「打招呼」。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202093002.png)


消息⾥⾯有客户端使⽤的 TLS 版本号、⽀持的密码套件列表，以及⽣成的随机数（Client Random），这个**随机数**会被服务端保留，它是 **⽣成对称加密密钥的材料之⼀。**


#### TLS 第⼆次握⼿
当服务端收到客户端的「Client Hello」消息后，会确认 TLS 版本号是否⽀持，和从密码套件列表中选择⼀个密码套件，以及⽣成**随机数（Server Random）。**


接着，返回「Server Hello」消息，消息⾥⾯有服务器确认的 TLS 版本号，也给出了随机数（Server Random），然后从客户端的密码套件列表选择了⼀个合适的密码套件。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202093914.png)


可以看到，服务端选择的密码套件是 “Cipher Suite: TLS_RSA_WITH_AES_128_GCM_SHA256”。

这个密码套件看起来真让⼈头晕，好⼀⼤串，但是其实它是有固定格式和规范的。基本的形式是 **「密钥交换算法 +签名算法 + 对称加密算法 + 摘要算法」**， ⼀般 WITH 单词前⾯有两个单词，第⼀个单词是约定密钥交换的算法，第⼆个单词是约定证书的验证算法。⽐如刚才的密码套件的意思就是：

- 由于 WITH 单词只有⼀个 RSA，则说明握⼿时密钥交换算法和签名算法都是使⽤ RSA；
- 握⼿后的通信使⽤ AES 对称算法，密钥⻓度 128 位，分组模式是 GCM；
- 摘要算法 SHA384 ⽤于消息认证和产⽣随机数；


就前⾯这两个客户端和服务端相互「打招呼」的过程，客户端和服务端就已确认了 TLS 版本和使⽤的密码套件，⽽且你可能发现客户端和服务端都会各⾃⽣成⼀个随机数，并且还会把随机数传递给对⽅。

那这个随机数有啥⽤呢？其实这两个随机数是后续作为⽣成「会话密钥」的条件，所谓的会话密钥就是数据传输时，所使⽤的对称加密密钥。

然后，服务端为了证明⾃⼰的身份，会发送「Server Certificate」给客户端，这个消息⾥含有数字证书。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202094918.png)

随后，服务端发了「Server Hello Done」消息，⽬的是告诉客户端，我已经把该给你的东⻄都给你了，本次打招呼完毕。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202095144.png)


##### 客户端验证证书
在这⾥刹个⻋，客户端拿到了服务端的数字证书后，要怎么校验该数字证书是真实有效的呢？

###### 数字证书和 CA 机构
在说校验数字证书是否可信的过程前，我们先来看看数字证书是什么，⼀个数字证书通常包含了：
- 公钥；
- 持有者信息；
- 证书认证机构（CA）的信息；
- CA 对这份⽂件的数字签名及使⽤的算法；
- 证书有效期；
- 还有⼀些其他额外信息；


那数字证书的作⽤，是⽤来认证公钥持有者的身份，以防⽌第三⽅进⾏冒充。说简单些，证书就是⽤来告诉客户端，该服务端是否是合法的，因为只有证书合法，才代表服务端身份是可信的。

我们⽤证书来认证公钥持有者的身份（服务端的身份），那证书⼜是怎么来的？⼜该怎么认证证书呢？

为了让服务端的公钥被⼤家信任，服务端的证书都是由 CA （Certificate Authority，证书认证机构）签名的，CA就是⽹络世界⾥的公安局、公证中⼼，具有极⾼的可信度，所以由它来给各个公钥签名，信任的⼀⽅签发的证书，那必然证书也是被信任的。

之所以要签名，是因为签名的作⽤可以避免中间⼈在获取证书时对证书内容的篡改。

###### 数字证书签发和验证流程

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202095855.png)


CA 签发证书的过程，如上图左边部分：

- ⾸先 CA 会把持有者的公钥、⽤途、颁发者、有效时间等信息打成⼀个包，然后对这些信息进⾏ Hash 计算，得到⼀个 Hash 值；

- 然后 CA 会使⽤⾃⼰的私钥将该 Hash 值加密，⽣成 Certificate Signature，也就是 CA 对证书做了签名；

- 最后将 Certificate Signature 添加在⽂件证书上，形成数字证书；

客户端校验服务端的数字证书的过程，如上图右边部分：

- ⾸先客户端会使⽤同样的 Hash 算法获取该证书的 Hash 值 H1；

- 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使⽤ CA 的公钥解密 CertificateSignature 内容，得到⼀个 Hash 值 H2 ；

- 最后⽐较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。

###### 证书链
但事实上，证书的验证过程中还存在⼀个证书信任链的问题，因为我们向 CA 申请的证书⼀般不是根证书签发的，⽽是由中间证书签发的，⽐如百度的证书，从下图你可以看到，证书的层级有三级：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202100730.png)


对于这种三级层级关系的证书的验证过程如下：

- 客户端收到 baidu.com 的证书后，发现这个证书的签发者不是根证书，就⽆法根据本地已有的根证书中的公钥去验证 baidu.com 证书是否可信。于是，客户端根据 baidu.com 证书中的签发者，找到该证书的颁发机构是 “GlobalSign Organization Validation CA - SHA256 - G2”，然后向 CA 请求该中间证书。

- 请求到证书后发现 “GlobalSign Organization Validation CA - SHA256 - G2” 证书是由 “GlobalSign Root CA”签发的，由于 “GlobalSign Root CA” 没有再上级签发机构，说明它是根证书，也就是⾃签证书。应⽤软件会检查此证书有否已预载于根证书清单上，如果有，则可以利⽤根证书中的公钥去验证 “GlobalSignOrganization Validation CA - SHA256 - G2” 证书，如果发现验证通过，就认为该中间证书是可信的。

- “GlobalSign Organization Validation CA - SHA256 - G2” 证书被信任后，可以使⽤ “GlobalSign OrganizationValidation CA - SHA256 - G2” 证书中的公钥去验证 baidu.com 证书的可信性，如果验证通过，就可以信任baidu.com 证书。


在这四个步骤中，最开始客户端只信任根证书 GlobalSign Root CA 证书的，然后 “GlobalSign Root CA” 证书信任“GlobalSign Organization Validation CA - SHA256 - G2” 证书，⽽ “GlobalSign Organization Validation CA -SHA256 - G2” 证书⼜信任 baidu.com 证书，于是客户端也信任 baidu.com 证书。


总括来说，由于⽤户信任 GlobalSign，所以由 GlobalSign 所担保的 baidu.com 可以被信任，另外由于⽤户信任操作系统或浏览器的软件商，所以由软件商预载了根证书的 GlobalSign 都可被信任。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202101431.png)

整个证书信任链验证流程如下图所示：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202101705.png)

最后⼀个问题，为什么需要证书链这么麻烦的流程？Root CA 为什么不直接颁发证书，⽽是要搞那么多中间层级呢？

这是为了确保根证书的绝对安全性，将根证书隔离地越严格越好，不然根证书如果失守了，那么整个信任链都会有问题。


#### TLS 第三次握⼿
客户端验证完证书后，认为可信则继续往下⾛。接着，客户端就会⽣成⼀个新的随机数 (pre-master)，⽤服务器的 RSA 公钥加密该随机数，通过「Change Cipher Key Exchange」消息传给服务端。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202102139.png)


服务端收到后，⽤ RSA 私钥解密，得到客户端发来的随机数 (pre-master)。

⾄此，客户端和服务端双⽅都共享了三个随机数，分别是 **Client Random、Server Random、pre-master。**


于是，双⽅根据已经得到的三个随机数，⽣成**会话密钥**（Master Secret），它是对称密钥，⽤于对后续的 HTTP请求/响应的数据加解密。

⽣成完会话密钥后，然后客户端发⼀个「Change Cipher Spec」，告诉服务端开始使⽤加密⽅式发送消息。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202102719.png)


然后，客户端再发⼀个「Encrypted Handshake Message（Finishd）」消息，把之前所有发送的数据做个摘要，再⽤会话密钥（master secret）加密⼀下，让服务器做个验证，验证加密通信是否可⽤和之前握⼿信息是否有被中途篡改过。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202102723.png)

可以发现，「Change Cipher Spec」之前传输的 TLS 握⼿数据都是明⽂，之后都是对称密钥加密的密⽂。


#### TLS 第四次握⼿
服务器也是同样的操作，发「Change Cipher Spec」和「Encrypted Handshake Message」消息，如果双⽅都验证加密和解密没问题，那么握⼿正式完成。

最后，就⽤「会话密钥」加解密 HTTP 请求和响应了。

### 2.22  RSA 算法的缺陷
使⽤ RSA 密钥协商算法的最⼤问题是**不⽀持前向保密**。因为客户端传递随机数（⽤于⽣成对称加密密钥的条件之⼀）给服务端时使⽤的是公钥加密的，服务端收到到后，会⽤私钥解密得到随机数。所以⼀旦服务端的私钥泄漏了，过去被第三⽅截获的所有 TLS 通讯密⽂都会被破解。

为了解决这⼀问题，于是就有了 DH 密钥协商算法，这⾥简单介绍它的⼯作流程。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202102727.png)

客户端和服务端各⾃会⽣成随机数，并以此作为私钥，然后根据公开的 DH 计算公式算出各⾃的公钥，通过 TLS握⼿双⽅交换各⾃的公钥，这样双⽅都有⾃⼰的私钥和对⽅的公钥，然后双⽅根据各⾃持有的材料算出⼀个随机数，这个随机数的值双⽅都是⼀样的，这就可以作为后续对称加密时使⽤的密钥。

DH 密钥交换过程中，即使第三⽅截获了 TLS 握⼿阶段传递的公钥，在不知道的私钥的情况下，也是⽆法计算出密钥的，⽽且每⼀次对称加密密钥都是实时⽣成的，实现前向保密。

但因为 DH 算法的计算效率问题，后⾯出现了 ECDHE 密钥协商算法，我们现在⼤多数⽹站使⽤的正是 ECDHE 密钥协商算法，关于 ECDHE 握⼿的过程，将在下⼀篇揭晓，尽情期待哦。

### 2.23 HTTPS ECDHE 握⼿解析
HTTPS 常⽤的密钥交换算法有两种，分别是 RSA 和 ECDHE 算法。

其中，RSA 是⽐较传统的密钥交换算法，它不具备前向安全的性质，因此现在很少服务器使⽤的。⽽ ECDHE 算法具有前向安全，所以被⼴泛使⽤。

#### 离散对数
ECDHE 密钥协商算法是 DH 算法演进过来的，所以我们先从 DH 算法说起。

DH 算法是⾮对称加密算法， 因此它可以⽤于密钥交换，该算法的核⼼数学思想是**离散对数。**

离散对数是「离散 + 对数」的两个数学概念的组合，所以我们先来复习⼀遍对数。

要说起对数，必然要说指数，因为它们是互为反函数，指数就是幂运算，对数是指数的逆运算。

举个栗⼦，如果以 2 作为底数，那么指数和对数运算公式，如下图所示：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202113651.png)

那么对于底数为 2 的时候， 32 的对数是 5，64 的对数是 6，计算过程如下：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202113654.png)

对数运算的取值是可以连续的，⽽离散对数的取值是不能连续的，因此也以「离散」得名，

离散对数是在对数运算的基础上加了「模运算」，也就说取余数，对应编程语⾔的操作符是「%」，也可以⽤ mod表示。离散对数的概念如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202114813.png)


上图中，底数 a 和模数 p 是离散对数的公共参数，也就说是公开的，b 是真数，i 是对数。知道了对数，就可以⽤上⾯的公式计算出真数。但反过来，知道真数却很难推算出对数。

**特别是当模数 p 是⼀个很⼤的质数，即使知道底数 a 和真数 b ，在现有的计算机的计算⽔平是⼏乎⽆法算出离散对数的，这就是 DH 算法的数学基础。**

#### DH 算法
认识了离散对数，我们来看看 DH 算法是如何密钥交换的。

现假设⼩红和⼩明约定使⽤ DH 算法来交换密钥，那么基于离散对数，⼩红和⼩明需要先确定模数和底数作为算法的参数，这两个参数是公开的，⽤ P 和 G 来代称。

然后⼩红和⼩明各⾃⽣成⼀个随机整数作为私钥，双⽅的私钥要各⾃严格保管，不能泄漏，⼩红的私钥⽤ a 代称，⼩明的私钥⽤ b 代称。

现在⼩红和⼩明双⽅都有了 P 和 G 以及各⾃的私钥，于是就可以计算出公钥：

- ⼩红的公钥记作 A，A = G ^ a ( mod P )；

- ⼩明的公钥记作 B，B = G ^ b ( mod P )；

A 和 B 也是公开的，因为根据离散对数的原理，从真数（A 和 B）反向计算对数 a 和 b 是⾮常困难的，⾄少在现有计算机的计算能⼒是⽆法破解的，如果 ⼦计算机出来了，那就有可能被破解，当然如果 ⼦计算机真的出来了，那么密钥协商算法就要做⼤的升级了。


双⽅交换各⾃ DH 公钥后，⼩红⼿上共有 5 个数：P、G、a、A、B，⼩明⼿上也同样共有 5 个数：P、G、b、B、A。

然后⼩红执⾏运算： B ^ a ( mod P )，其结果为 K，因为离散对数的幂运算有交换律，所以⼩明执⾏运算： A ^ b (mod P )，得到的结果也是 K。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202120148.png)


这个 K 就是⼩红和⼩明之间⽤的对称加密密钥，可以作为会话密钥使⽤。

可以看到，整个密钥协商过程中，⼩红和⼩明公开了 4 个信息：P、G、A、B，其中 P、G 是算法的参数，A 和 B是公钥，⽽ a、b 是双⽅各⾃保管的私钥，⿊客⽆法获取这 2 个私钥，因此⿊客只能从公开的 P、G、A、B ⼊⼿，计算出离散对数（私钥）。

前⾯也多次强调， 根据离散对数的原理，如果 P 是⼀个⼤数，在现有的计算机的计算能⼒是很难破解出 私钥 a、b的，破解不出私钥，也就⽆法计算出会话密钥，因此 DH 密钥交换是安全的。


#### DHE 算法
根据私钥⽣成的⽅式，DH 算法分为两种实现：
- static DH 算法，这个是已经被废弃了；
- DHE 算法，现在常⽤的；

static DH 算法⾥有⼀⽅的私钥是静态的，也就说每次密钥协商的时候有⼀⽅的私钥都是⼀样的，⼀般是服务器⽅固定，即 a 不变，客户端的私钥则是随机⽣成的。

于是，DH 交换密钥时就只有客户端的公钥是变化，⽽服务端公钥是不变的，那么随着时间延⻓，⿊客就会截获海的密钥协商过程的数据，因为密钥协商的过程有些数据是公开的，⿊客就可以依据这些数据暴⼒破解出服务器的私钥，然后就可以计算出会话密钥了，于是之前截获的加密数据会被破解，所以 static DH 算法不具备前向安全性。

既然固定⼀⽅的私钥有被破解的⻛险，那么⼲脆就让双⽅的私钥在每次密钥交换通信时，都是随机⽣成的、临时的，这个⽅式也就是 DHE 算法，E 全称是 ephemeral（临时性的）。

所以，即使有个⽜逼的⿊客破解了某⼀次通信过程的私钥，其他通信过程的私钥仍然是安全的，因为每个通信过程的私钥都是没有任何关系的，都是独⽴的，这样就保证了「前向安全」。


#### ECDHE 算法
DHE 算法由于计算性能不佳，因为需要做⼤ 的乘法，为了提升 DHE 算法的性能，所以就出现了现在⼴泛⽤于密钥交换算法 —— ECDHE 算法。

ECDHE 算法是在 DHE 算法的基础上利⽤了 ECC 椭圆曲线特性，可以⽤更少的计算 计算出公钥，以及最终的会话密钥。


⼩红和⼩明使⽤ ECDHE 密钥交换算法的过程：

- 双⽅事先确定好使⽤哪种椭圆曲线，和曲线上的基点 G，这两个参数都是公开的；

- 双⽅各⾃随机⽣成⼀个随机数作为私钥d，并与基点 G相乘得到公钥Q（Q = dG），此时⼩红的公私钥为 Q1和 d1，⼩明的公私钥为 Q2 和 d2；

- 双⽅交换各⾃的公钥，最后⼩红计算点（x1，y1） = d1Q2，⼩明计算点（x2，y2） = d2Q1，由于椭圆曲线上是可以满⾜乘法交换和结合律，所以 d1Q2 = d1d2G = d2d1G = d2Q1 ，因此双⽅的 **x 坐标是⼀样的，所以它是共享密钥，也就是会话密钥。**

这个过程中，双⽅的私钥都是随机、临时⽣成的，都是不公开的，即使根据公开的信息（椭圆曲线、公钥、基点G）也是很难计算出椭圆曲线上的离散对数（私钥）。

#### ECDHE 握⼿过程
知道了 ECDHE 算法基本原理后，我们就结合实际的情况来看看。

我⽤ Wireshark ⼯具抓了⽤ ECDHE 密钥协商算法的 TSL 握⼿过程，可以看到是四次握⼿：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202122228.png)

细⼼的⼩伙伴应该发现了，**使⽤了 ECDHE，在 TLS 第四次握⼿前，客户端就已经发送了加密的 HTTP 数据**，⽽对于 RSA 握⼿过程，必须要完成 TLS 四次握⼿，才能传输应⽤数据。

所以，**ECDHE 相⽐ RSA 握⼿过程省去了⼀个消息往返的时间**，这个有点「抢跑」的意思，它被称为是「TLSFalse Start」，跟「TCP Fast Open」有点像，都是在还没连接完全建⽴前，就发送了应⽤数据，这样便提⾼了传输的效率。

接下来，分析每⼀个 ECDHE 握⼿过程。

##### TLS 第⼀次握⼿
客户端⾸先会发⼀个「Client Hello」消息，消息⾥⾯有客户端使⽤的 TLS 版本号、⽀持的密码套件列表，以及⽣成的随机数（Client Random）。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202123206.png)


##### TLS 第⼆次握⼿
服务端收到客户端的「打招呼」，同样也要回礼，会返回「Server Hello」消息，消息⾯有服务器确认的 TLS 版本号，也给出了⼀个随机数（Server Random），然后从客户端的密码套件列表选择了⼀个合适的密码套件。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202123356.png)

不过，这次选择的密码套件就和 RSA 不⼀样了，我们来分析⼀下这次的密码套件的意思。

「 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384」

- 密钥协商算法使⽤ ECDHE；

- 签名算法使⽤ RSA；

- 握⼿后的通信使⽤ AES 对称算法，密钥⻓度 256 位，分组模式是 GCM；

- 摘要算法使⽤ SHA384；

接着，服务端为了证明⾃⼰的身份，发送「Certificate」消息，会把证书也发给客户端。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202124132.png)

这⼀步就和 RSA 握⼿过程有很⼤到区别了，因为服务端选择了 ECDHE 密钥协商算法，所以会在发送完证书后，发送「Server Key Exchange」消息。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202124321.png)

这个过程服务器做了三件事：

- 选择了名为 named_curve 的椭圆曲线，选好了椭圆曲线相当于椭圆曲线基点 G 也定好了，这些都会公开给客户端；

- ⽣成随机数作为服务端椭圆曲线的私钥，保留到本地；

- 根据基点 G 和私钥计算出服务端的椭圆曲线公钥，这个会公开给客户端。

为了保证这个椭圆曲线的公钥不被第三⽅篡改，服务端会⽤ RSA 签名算法给服务端的椭圆曲线公钥做个签名。

随后，就是「Server Hello Done」消息，服务端跟客户端表明：“这些就是我提供的信息，打招呼完毕”。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202124907.png)


⾄此，TLS 两次握⼿就已经完成了，⽬前客户端和服务端通过明⽂共享了这⼏个信息：**Client Random、ServerRandom 、使⽤的椭圆曲线、椭圆曲线基点 G、服务端椭圆曲线的公钥**，这⼏个信息很 要，是后续⽣成会话密钥的材料。

##### TLS 第三次握⼿

客户端收到了服务端的证书后，⾃然要校验证书是否合法，如果证书合法，那么服务端到身份就是没问题的。校验证书到过程，会⾛证书链逐级验证，确认证书的真实性，再⽤证书的公钥验证签名，这样就能确认服务端的身份了，确认⽆误后，就可以继续往下⾛。

客户端会⽣成⼀个随机数作为客户端椭圆曲线的私钥，然后再根据服务端前⾯给的信息，⽣成**客户端的椭圆曲线公钥**，然后⽤「**Client Key Exchange**」消息发给服务端。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202125207.png)

⾄此，双⽅都有对⽅的椭圆曲线公钥、⾃⼰的椭圆曲线私钥、椭圆曲线基点 G。于是，双⽅都就计算出点（x，y），其中 x 坐标值双⽅都是⼀样的，前⾯说 ECDHE 算法时候，说 x 是会话密钥，但实际应⽤中，x 还不是最终的会话密钥。


还记得 TLS 握⼿阶段，客户端和服务端都会⽣成了⼀个随机数传递给对⽅吗？

**最终的会话密钥，就是⽤「客户端随机数 + 服务端随机数 + x（ECDHE 算法算出的共享密钥） 」三个材料⽣成的。**


之所以这么麻烦，是因为 TLS 设计者不信任客户端或服务器「伪随机数」的可靠性，为了保证真正的完全随机，把三个不可靠的随机数混合起来，那么「随机」的程度就⾮常⾼了，⾜够不让⿊客计算出最终的会话密钥，安全性更⾼。


算好会话密钥后，客户端会发⼀个「**Change Cipher Spec**」消息，告诉服务端后续改⽤对称算法加密通信。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202125510.png)


接着，客户端会发「**Encrypted Handshake Message**」消息，把之前发送的数据做⼀个摘要，再⽤对称密钥加密⼀下，让服务端做个验证，验证下本次⽣成的对称密钥是否可以正常使⽤。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202125737.png)


##### TLS 第四次握⼿
最后，服务端也会有⼀个同样的操作，发「**Change Cipher Spec**」和「**Encrypted Handshake Message**」消息，如果双⽅都验证加密和解密没问题，那么握⼿正式完成。于是，就可以正常收发加密的 HTTP 请求和响应了。

### 2.24 总结以下 RSA 和 ECDHE 握⼿过程的区别：

- RSA 密钥协商算法「不⽀持」前向保密，ECDHE 密钥协商算法「⽀持」前向保密；

- 使⽤了 RSA 密钥协商算法，TLS 完成四次握⼿后，才能进⾏应⽤数据传输，⽽对于 ECDHE 算法，客户端可以不⽤等服务端的最后⼀次 TLS 握⼿，就可以提前发出加密的 HTTP 数据，节省了⼀个消息的往返时间；

- 使⽤ ECDHE， 在 TLS 第 2 次握⼿中，会出现服务器端发出的「Server Key Exchange」消息，⽽ RSA 握⼿过程没有该消息；

### 2.25 HTTPS 如何优化？

由裸数据传输的 HTTP 协议转成加密数据传输的 HTTPS 协议，给应⽤数据套了个「保护伞」，提⾼安全性的同时也带来了性能消耗。

因为 HTTPS 相⽐ HTTP 协议多⼀个 TLS 协议握⼿过程，⽬的是为了通过 **⾮对称加密握⼿协商**或者**交换出对称加密密钥**，这个过程最⻓可以花费掉 2 RTT，接着后续传输的应⽤数据都得使⽤对称加密密钥来加密/解密。

为了数据的安全性，我们不得不使⽤ HTTPS 协议，⾄今⼤部分⽹址都已从 HTTP 迁移⾄ HTTPS 协议，因此针对HTTPS 的优化是⾮常重要的。

这次，就从多个⻆度来优化 HTTPS。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202162807.png)

#### 分析性能损耗

产⽣性能消耗的两个环节：

- **第⼀个环节， TLS 协议握⼿过程**；
- 第⼆个环节，握⼿后的对称加密报⽂传输。

对于第⼆环节，现在主流的对称加密算法 AES、ChaCha20 性能都是不错的，⽽且⼀些 CPU ⼚商还针对它们做了硬件级别的优化，因此这个环节的性能消耗可以说⾮常地 **⼩**。

⽽第⼀个环节，TLS 协议握⼿过程不仅增加了⽹络延时（最⻓可以花费掉 2 RTT），⽽且握⼿过程中的⼀些步骤也会产⽣性能损耗，⽐如：

- 对于 ECDHE 密钥协商算法，握⼿过程中客户端和服务端都需要临时⽣成椭圆曲线公私钥；

- 客户端验证证书时，会访问 CA 获取 CRL 或者 OCSP，⽬的是验证服务器的证书是否有被吊销；

- 双⽅计算 Pre-Master，也就是对称加密密钥；

为了⼤家更清楚这些步骤在 TLS 协议握⼿的哪⼀个阶段，我画出了这幅图：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202164038.png)


####  硬件优化
玩游戏时，如果我们怎么都战胜不了对⽅，那么有⼀个最有效、最快的⽅式来变强，那就是「充钱」，如果还是不⾏，那说明你充的钱还不够多。

但是花钱也要花对⽅向，HTTPS 协议是**计算密集型**，⽽不是 I/O 密集型，所以不能把钱花在⽹卡、硬盘等地⽅，应该花在 **CPU** 上。

⼀个好的 CPU，可以提⾼计算性能，因为 HTTPS 连接过程中就有⼤量需要计算密钥的过程，所以这样可以**加速TLS 握⼿过程**。


另外，如果可以，应该选择可以⽀持 AES-NI 特性的 CPU，因为这种款式的 CPU 能在指令级别优化了 AES 算法，这样便加速了数据的加解密传输过程。

如果你的服务器是 Linux 系统，那么你可以使⽤下⾯这⾏命令查看 CPU 是否⽀持 AES-NI 指令集：

- sort -u /proc/crypto | grep module |grep aes 

如果我们的 CPU ⽀持 AES-NI 特性，那么对于对称加密的算法应该选择 AES 算法。否则可以选择 ChaCha20 对称加密算法，因为 ChaCha20 算法的运算指令相⽐ AES 算法会对 CPU 更友好⼀点。

#### 软件优化
软件的优化⽅向可以分层两种，⼀个是**软件升级**，⼀个是**协议优化**。

先说第⼀个软件升级，软件升级就是将正在使⽤的软件升级到最新版本，因为最新版本不仅提供了最新的特性，也优化了以前软件的问题或性能。⽐如：

- 将 Linux 内核从 2.x 升级到 4.x；
- 将 OpenSSL 从 1.0.1 升级到 1.1.1；

看似简单的软件升级，对于有成百上千服务器的公司来说，软件升级也跟硬件升级同样是⼀个棘⼿的问题，因为要实⾏软件升级，会花费时间和⼈⼒，同时也存在⼀定的⻛险，也可能会影响正常的线上服务。

既然如此，我们把⽬光放到协议优化，也就是在现有的环节下，通过较⼩的改动，来进⾏优化。

#### 协议优化

协议的优化就是对「密钥交换过程」进⾏优化。

##### 密钥交换算法优化

TLS 1.2 版本如果使⽤的是 RSA 密钥交换算法，那么需要 4 次握⼿，也就是要花费 2 RTT，才可以进⾏应⽤数据的传输，⽽且 RSA 密钥交换算法不具备前向安全性。

总之使⽤ RSA 密钥交换算法的 TLS 握⼿过程，不仅慢，⽽且安全性也不⾼。

因此如果可以，尽量选⽤ **ECDHE 密钥交换算法**替换 RSA 算法，因为该算法由于⽀持「False Start」，它是“抢跑”的意思，客户端可以在 TLS 协议的第 3 次握⼿后，第 4 次握⼿前，发送加密的应⽤数据，以此将 TLS 握⼿的消息**往返由 2 RTT 减少到 1 RTT，⽽且安全性也⾼，具备前向安全性**。

ECDHE 算法是基于椭圆曲线实现的，不同的椭圆曲线性能也不同，应该尽 选择 **x25519**曲线，该曲线是⽬前最快的椭圆曲线。

⽐如在 Nginx 上，可以使⽤ ssl_ecdh_curve 指令配置想使⽤的椭圆曲线，把优先使⽤的放在前⾯：
- ssl_ecdh_curve X25519 : secp384r1


对于对称加密算法⽅⾯，如果对安全性不是特别⾼的要求，可以选⽤ AES_128_GCM，它⽐ AES_256_GCM快⼀些，因为密钥的⻓度短⼀些。


⽐如在 Nginx 上，可以使⽤ ssl_ciphers 指令配置想使⽤的⾮对称加密算法和对称加密算法，也就是密钥套件，⽽且把性能最快最安全的算法放在最前⾯：
- ssl_ciphers 'EECDH+ECDSA+AES128+SHA:RSA+AES128+SHA';


### TLS 升级

当然，如果可以，直接把 TLS 1.2 升级成 TLS 1.3，TLS 1.3 ⼤幅度简化了握⼿的步骤，完成 **TLS 握⼿只要 1RTT**，⽽且安全性更⾼。

在 TLS 1.2 的握⼿中，⼀般是需要 4 次握⼿，先要通过 Client Hello （第 1 次握⼿）和 Server Hello（第 2 次握⼿） 消息协商出后续使⽤的加密算法，再互相交换公钥（第 3 和 第 4 次握⼿），然后计算出最终的会话密钥，下图的左边部分就是 TLS 1.2 的握⼿过程：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202170443.png)


上图的右边部分就是 TLS 1.3 的握⼿过程，可以发现 TLS 1.3 **把 Hello 和公钥交换**这两个消息合并成了⼀个消息，于是这样就减少到只需 **1 RTT 就能完成 TLS 握⼿**。

怎么合并的呢？具体的做法是，客户端在 Client Hello 消息⾥带上了⽀持的椭圆曲线，以及这些椭圆曲线对应的公钥。

服务端收到后，选定⼀个椭圆曲线等参数，然后返回消息时，带上服务端这边的公钥。经过这 1 个 RTT，双⽅⼿上已经有⽣成会话密钥的材料了，于是客户端计算出会话密钥，就可以进⾏应⽤数据的加密传输了。

⽽且，TLS1.3 对密码套件进⾏“减肥”了，对于密钥交换算法，废除了不⽀持前向安全性的 RSA 和 DH 算法，**只⽀持 ECDHE 算法**。


对于对称加密和签名算法，只⽀持⽬前最安全的⼏个密码套件，⽐如 openssl 中仅⽀持下⾯ 5 种密码套件：

- TLS_AES_256_GCM_SHA384
- TLS_CHACHA20_POLY1305_SHA256
- TLS_AES_128_GCM_SHA256
- TLS_AES_128_CCM_8_SHA256
- TLS_AES_128_CCM_SHA256

之所以 TLS1.3 仅⽀持这么少的密码套件，是因为 TLS1.2 由于⽀持各种古⽼且不安全的密码套件，中间⼈可以利⽤降级攻击，伪造客户端的 Client Hello 消息，替换客户端⽀持的密码套件为⼀些不安全的密码套件，使得服务器被迫使⽤这个密码套件进⾏ HTTPS 连接，从⽽破解密⽂。

### 证书优化
为了验证的服务器的身份，服务器会在 TSL 握⼿过程中，把⾃⼰的证书发给客户端，以此证明⾃⼰身份是可信的。

对于证书的优化，可以有两个⽅向：

- ⼀个是证书传输，
- ⼀个是证书验证；

##### 证书传输优化
要让证书更便于传输，那必然是减少证书的⼤⼩，这样可以节约带宽，也能减少客户端的运算 。所以，**对于服务器的证书应该选择椭圆曲线（ECDSA）证书，⽽不是 RSA 证书，因为在相同安全强度下，ECC 密钥⻓度⽐ RSA短的多。**


##### 证书验证优化
客户端在验证证书时，是个复杂的过程，会⾛证书链逐级验证，验证的过程不仅需要「⽤ CA 公钥解密证书」以及「⽤签名算法验证证书的完整性」，⽽且为了知道证书是否被 CA 吊销，客户端有时还会再去访问 CA， 下载 CRL或者 OCSP 数据，以此确认证书的有效性。

这个访问过程是 HTTP 访问，因此⼜会产⽣⼀系列⽹络通信的开销，如 DNS 查询、建⽴连接、收发数据等。

###### CRL
CRL 称为证书吊销列表（Certificate Revocation List），这个列表是由 CA 定期更新，列表内容都是被撤销信任的证书序号，如果服务器的证书在此列表，就认为证书已经失效，不在的话，则认为证书是有效的。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202171535.png)

但是 CRL 存在两个问题：

- 第⼀个问题，由于 CRL 列表是由 CA 维护的，定期更新，如果⼀个证书刚被吊销后，客户端在更新 CRL 之前还是会信任这个证书，实时性较差；

- 第⼆个问题，随着吊销证书的增多，列表会越来越⼤，下载的速度就会越慢，下载完客户端还得遍历这么⼤的列表，那么就会导致客户端在校验证书这⼀环节的延时很⼤，进⽽拖慢了 HTTPS 连接。

###### OCSP
因此，现在基本都是使⽤ OCSP ，名为在线证书状态协议（Online Certificate Status Protocol）来查询证书的有效性，它的⼯作⽅式是向 **CA 发送查询请求，让 CA 返回证书的有效状态**。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202171919.png)


不必像 CRL ⽅式客户端需要下载⼤⼤的列表，还要从列表查询，同时因为可以实时查询每⼀张证书的有效性，解决了 CRL 的实时性问题。

OCSP 需要向 CA 查询，因此也是要发⽣⽹络请求，⽽且还得看 CA 服务器的“脸⾊”，如果⽹络状态不好，或者CA 服务器繁忙，也会导致客户端在校验证书这⼀环节的延时变⼤。

###### OCSP Stapling

于是为了解决这⼀个⽹络开销，就出现了 OCSP Stapling，其原理是：服务器向 CA 周期性地查询证书状态，获得⼀个带有时间戳和签名的响应结果并缓存它。

当有客户端发起连接请求时，服务器会把这个「响应结果」在 TLS 握⼿过程中发给客户端。由于有签名的存在，服务器⽆法篡改，因此客户端就能得知证书是否已被吊销了，这样客户端就不需要再去查询。

### 会话复⽤
TLS 握⼿的⽬的就是为了协商出会话密钥，也就是对称加密密钥，那我们如果我们把⾸次 TLS 握⼿协商的对称加密密钥缓存起来，待下次需要建⽴ HTTPS 连接时，直接「复⽤」这个密钥，不就减少 TLS 握⼿的性能损耗了吗？

这种⽅式就是**会话复⽤**（TLS session resumption），会话复⽤分两种：
- 第⼀种叫 Session ID；
- 第⼆种叫 Session Ticket；

#### Session ID
Session ID 的⼯作原理是，客户端和服务器⾸次 TLS 握⼿连接后，双⽅会在内存缓存会话密钥，并⽤唯⼀的Session ID 来标识，Session ID 和会话密钥相当于 key-value 的关系。

当客户端再次连接时，hello 消息⾥会带上 Session ID，服务器收到后就会从内存找，如果找到就直接⽤该会话密钥恢复会话状态，跳过其余的过程，只⽤⼀个消息往返就可以建⽴安全通信。当然为了安全性，内存中的会话密钥会定期失效。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202174156.png)

但是它有两个缺点：

- 服务器必须保持每⼀个客户端的会话密钥，随着客户端的增多，服务器的内存压⼒也会越⼤。

- 现在⽹站服务⼀般是由多台服务器通过负载均衡提供服务的，客户端再次连接不⼀定会命中上次访问过的服务器，于是还要⾛完整的 TLS 握⼿过程；

#### Session Ticket
为了解决 Session ID 的问题，就出现了 Session Ticket，**服务器不再缓存每个客户端的会话密钥，⽽是把缓存的⼯作交给了客户端，类似于 HTTP 的 Cookie**。

客户端与服务器⾸次建⽴连接时，服务器会加密「会话密钥」作为 Ticket 发给客户端，交给客户端缓存该 Ticket。

客户端再次连接服务器时，客户端会发送 Ticket，服务器解密后就可以获取上⼀次的会话密钥，然后验证有效期，如果没问题，就可以恢复会话了，开始加密通信。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202175657.png)

对于集群服务器的话，**要确保每台服务器加密 「会话密钥」的密钥是⼀致的**，这样客户端携带 Ticket 访问任意⼀台服务器时，都能恢复会话。

Session ID 和 Session Ticket **都不具备前向安全性**，因为⼀旦加密「会话密钥」的密钥被破解或者服务器泄漏「会话密钥」，前⾯劫持的通信密⽂都会被破解。

同时应对**重放攻击**也很困难，这⾥简单介绍下重放攻击⼯作的原理。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202180115.png)


假设 Alice 想向 Bob 证明⾃⼰的身份。 Bob 要求 Alice 的密码作为身份证明，爱丽丝应尽全⼒提供（可能是在经过如哈希函数的转换之后）。与此同时，Eve 窃听了对话并保留了密码（或哈希）。

交换结束后，Eve（冒充 Alice ）连接到 Bob。当被要求提供身份证明时，Eve 发送从 Bob 接受的最后⼀个会话中读取的 Alice 的密码（或哈希），从⽽授予 Eve 访问权限。

放攻击的危险之处在于，如果中间⼈截获了某个客户端的 Session ID 或 Session Ticket 以及 POST 报⽂，⽽⼀般 POST 请求会改变数据库的数据，中间⼈就可以利⽤此截获的报⽂，不断向服务器发送该报⽂，这样就会导致数据库的数据被中间⼈改变了，⽽客户是不知情的。


避免 放攻击的⽅式就是需要**对会话密钥设定⼀个合理的过期时间**。


#### Pre-shared Key

前⾯的 Session ID 和 Session Ticket ⽅式都需要在 1 RTT 才能恢复会话。

⽽ TLS1.3 更为⽜逼，对于 连 TLS1.3 只需要 0 RTT，原理和 Ticket 类似，只不过在重连时，客户端会把 Ticket和 HTTP 请求⼀同发送给服务端，这种⽅式叫 Pre-shared Key。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202181113.png)

同样的，Pre-shared Key 也有重放攻击的危险。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202182710.png)

如上图，假设中间⼈通过某种⽅式，截获了客户端使⽤会话重⽤技术的 POST 请求，通常 POST 请求是会改变数据库的数据，然后中间⼈就可以把截获的这个报⽂发送给服务器，服务器收到后，也认为是合法的，于是就恢复会话，致使数据库的数据⼜被更改，但是此时⽤户是不知情的。

所以，应对重放攻击可以给会话密钥设定⼀个合理的过期时间，以及只针对安全的 HTTP 请求如 GET/HEAD 使⽤会话重⽤。

### 2.26 HTTP/2 ⽜逼在哪？
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202183221.png)


#### HTTP/1.1 协议的性能问题

我们得先要了解下 HTTP/1.1 协议存在的性能问题，因为 HTTP/2 协议就是把这些性能问题逐个攻破了。

现在的站点相⽐以前变化太多了，⽐如：

- 消息的⼤⼩变⼤了，从⼏ KB ⼤⼩的消息，到⼏ MB ⼤⼩的消息；

- ⻚⾯资源变多了，从每个⻚⾯不到 10 个的资源，到每⻚超 100 多个资源；

- 内容形式变多样了，从单纯的⽂本内容，到图⽚、视频、⾳频等内容；

- 实时性要求变⾼了，对⻚⾯的实时性要求的应⽤越来越多；

这些变化带来的最⼤性能问题就是 HTTP/1.1 的⾼延迟，延迟⾼必然影响的就是⽤户体验。主要原因如下⼏个：

- **延迟难以下降**，虽然现在⽹络的「带宽」相⽐以前变多了，但是延迟降到⼀定幅度后，就很难再下降了，说⽩了就是到达了延迟的下限；

- **并发连接有限**，⾕歌浏览器最⼤并发连接数是 6 个，⽽且每⼀个连接都要经过 TCP 和 TLS 握⼿耗时，以及TCP 慢启动过程给流 带来的影响；

- **队头阻塞问题**，同⼀连接只能在完成⼀个 HTTP 事务（请求和响应）后，才能处理下⼀个事务；
HTTP 头部巨⼤且 复，由于 HTTP 协议是⽆状态的，每⼀个请求都得携带 HTTP 头部，特别是对于有携带cookie 的头部，⽽ cookie 的⼤⼩通常很⼤；

- **不⽀持服务器推送消息**，因此当客户端需要获取通知时，只能通过定时器不断地拉取消息，这⽆疑浪费⼤了带宽和服务器资源。


尽管对 HTTP/1.1 协议的优化⼿段如此之多，但是效果还是不尽⼈意，因为这些⼿段都是对 HTTP/1.1 协议的“外部”做优化，⽽⼀些关键的地⽅是没办法优化的，⽐如请求-响应模型、头部巨⼤且重复、并发连接耗时、服务器不能主动推送等，要改变这些必须重新设计 HTTP 协议，于是 HTTP/2 就出来了！



#### 兼容 HTTP/1.1

HTTP/2 出来的⽬的是为了改善 HTTP 的性能。协议升级有⼀个很重要的地⽅，就是要兼容⽼版本的协议，否则新协议推⼴起来就相当困难，所幸 HTTP/2 做到了兼容 HTTP/1.1 。

那么，HTTP/2 是怎么做的呢？

第⼀点，HTTP/2 没有在 URI ⾥引⼊新的协议名，仍然⽤「http://」表示明⽂协议，⽤「https://」表示加密协议，于是只需要浏览器和服务器在背后⾃动升级协议，这样可以让⽤户意识不到协议的升级，很好的实现了协议的平滑升级。

第⼆点，只在应⽤层做了改变，还是基于 TCP 协议传输，应⽤层⽅⾯为了保持功能上的兼容，HTTP/2 把 HTTP 分解成了「语义」和「语法」两个部分，「语义」层不做改动，与 HTTP/1.1 完全⼀致，⽐如请求⽅法、状态码、头字段等规则保留不变。

但是，HTTP/2 在「语法」层⾯做了很多改造，基本改变了 HTTP 报⽂的传输格式。

#### 头部压缩

HTTP 协议的报⽂是由「Header + Body」构成的，对于 Body 部分，HTTP/1.1 协议可以使⽤头字段 「Content-Encoding」指定 Body 的压缩⽅式，⽐如⽤ gzip 压缩，这样可以节约带宽，但报⽂中的另外⼀部分 Header，是没有针对它的优化⼿段。

HTTP/1.1 报⽂中 Header 部分存在的问题：

- 含很多固定的字段，⽐如Cookie、User Agent、Accept 等，这些字段加起来也⾼达⼏百字节甚⾄上千字节，所以有必要压缩；

- ⼤量的请求和响应的报⽂⾥有很多字段值都是重复的，这样会使得⼤量带宽被这些冗余的数据占⽤了，所以有必须要避免重复性；

- 字段是 ASCII 编码的，虽然易于⼈类观察，但效率低，所以有必要改成⼆进制编码；

HTTP/2 对 Header 部分做了⼤改造，把以上的问题都解决了。

HTTP/2 没使⽤常⻅的 gzip 压缩⽅式来压缩头部，⽽是开发了**HPACK** 算法，HPACK 算法主要包含三个组成部分：
- 静态字典；
- 动态字典；
- Huffman 编码（压缩算法）；


客户端和服务器两端都会建⽴和维护「**字典**」，⽤⻓度较⼩的索引号表示重复的字符串，再⽤ Huffman 编码压缩数据，**可达到 50%~90% 的⾼压缩率**。


#### 静态表编码
HTTP/2 为⾼频出现在头部的字符串和字段建⽴了⼀张静态表，它是写⼊到 HTTP/2 框架⾥的，不会变化的，静态表⾥共有 **61** 组，如下图：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211203180056.png)


表中的 Index 表示索引（Key）， Header Value 表示索引对应的 Value， Header Name 表示字段的名字，⽐如 Index 为 2 代表 GET，Index 为 8 代表状态码 200。

你可能注意到，表中有的 Index 没有对应的 Header Value，这是因为这些 Value 并不是固定的⽽是变化的，这些Value 都会经过 Huffman 编码后，才会发送出去。


这么说有点抽象，我们来看个具体的例⼦，下⾯这个 server 头部字段，在 HTTP/1.1 的形式如下：

- server: nghttpx\r\n

算上冒号空格和末尾的\r\n,共占用17字节，⽽使⽤了静态表和 Huffman 编码，可以将它压缩成 8 字节，压缩率⼤概 47 %。

我抓了个 HTTP/2 协议的⽹络包，你可以从下图看到，⾼亮部分就是 server 头部字段，只⽤了 8 个字节来表示server 头部数据。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211203181143.png)

根据 RFC7541 规范，如果头部字段属于静态表范围，并且 Value 是变化，那么它的 HTTP/2 头部前 2 位固定为01 ，所以整个头部格式如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211203181617.png)

HTTP/2 头部由于基于 **⼆进制编码**，就不需要冒号空格和末尾的\r\n作为分隔符，于是改⽤表示字符串⻓度（ValueLength）来分割 Index 和 Value。














































































































































































