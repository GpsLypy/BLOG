## 一、基础篇

### 1.1 TCP/IP ⽹络模型

对于同⼀台设备上的进程间通信，有很多种⽅式，⽐如**管道、消息队列、共享内存、信号**等⽅式，⽽对于不同设备上的进程间通信，就需要⽹络通信，⽽设备是多样性的，所以要兼容多种多样的设备，就协商出了⼀套通⽤的**⽹络协议**。

这个⽹络协议是分层的，每⼀层都有各⾃的作⽤和职责。

#### 应用层
最上层的，也是我们能直接接触到的就是应⽤层（Application Layer），我们电脑或⼿机使⽤的应⽤软件都是在应⽤层实现。那么，当两个不同设备的应⽤需要通信的时候，应⽤就把应⽤数据传给下⼀层，也就是传输层。
所以，应⽤层只需要专注于为⽤户提供应⽤功能，不⽤去关⼼数据是如何传输的，就类似于，我们寄快递的时候，
只需要把包裹交给快递员，由他负责运输快递，我们不需要关⼼快速是如何被运输的。
⽽且**应⽤层是⼯作在操作系统中的⽤户态，传输层及以下则⼯作在内核态**。

#### 传输层
应⽤层的数据包会传给传输层，传输层（Transport Layer）是为应⽤层提供⽹络⽀持的。

![](https://img-blog.csdnimg.cn/img_convert/6301b3b9215e239874c8dd8ca412b2f0.png)

在传输层会有两个传输协议，分别是 TCP 和 UDP。

TCP 的全称叫传输层控制协议（Transmission Control Protocol），⼤部分应⽤使⽤的正是 TCP 传输层协议，⽐
如 HTTP 应⽤层协议。TCP 相⽐ UDP 多了很多特性，⽐如流量控制、超时重传、拥塞控制等，这些都是为了保证数据包能可靠地传输给对⽅。

UDP 就相对很简单，简单到只负责发送数据包，不保证数据包是否能抵达对⽅，但它实时性相对更好，传输效率也⾼。

**当然，UDP 也可以实现可靠传输，把 TCP 的特性在应⽤层上实现就可以**，不过要实现⼀个商⽤的可靠 UDP传输协议，也不是⼀件简单的事情。应⽤需要传输的数据可能会⾮常⼤，如果直接传输就不好控制，因此**当传输层的数据包⼤⼩超过 MSS（TCP 最⼤报⽂段⻓度） ，就要将数据包分块**，这样即使中途有⼀个分块丢失或损坏了，只需要重发这⼀个分块，⽽不⽤重新发送整个数据包。在 TCP 协议中，我们把每个分块称为⼀个 TCP （TCP Segment）。


![](https://img-blog.csdnimg.cn/img_convert/55a3ce0b0fce882f32bf0f16ddfc6314.png)

当设备作为接收⽅时，传输层则要负责把数据包传给应⽤，但是⼀台设备上可能会有很多应⽤在接收或者传输数据，因此需要⽤⼀个编号将应⽤区分开来，这个编号就是端⼝。

⽐如 80 端⼝通常是 Web 服务器⽤的，22 端⼝通常是远程登录服务器⽤的。⽽对于浏览器（客户端）中的每个标签栏都是⼀个独⽴的进程，操作系统会为这些进程分配临时的端⼝号。

由于传输层的报⽂中会携带端⼝号，因此接收⽅可以识别出该报⽂是发送给哪个应⽤。


#### ⽹络层
传输层可能⼤家刚接触的时候，会认为它负责将数据从⼀个设备传输到另⼀个设备，事实上它并不负责。

实际场景中的⽹络环节是错综复杂的，中间有各种各样的线路和分叉路⼝，如果⼀个设备的数据要传输给另⼀个设备，就需要在各种各样的路径和节点进⾏选择，⽽传输层的设计理念是简单、⾼效、专注，如果传输层还负责这⼀块功能就有点违背设计原则了。

也就是说，我们不希望传输层协议处理太多的事情，只需要服务好应⽤即可，让其作为应⽤间数据传输的媒介，帮助实现应⽤到应⽤的通信，⽽实际的传输功能就交给下⼀层，也就是⽹络层（Internet Layer）。

![](https://img-blog.csdnimg.cn/img_convert/fbb69a4e9f2058ec56ee078646642bd9.png)

⽹络层最常使⽤的是 IP 协议（Internet Protocol），**IP 协议会将传输层的报⽂作为数据部分，再加上 IP 包头组装成 IP 报⽂，如果 IP 报⽂⼤⼩超过 MTU（以太⽹中⼀般为 1500 字节）就会再次进⾏分⽚，得到⼀个即将发送到⽹络的 IP 报⽂。**


![](https://img-blog.csdnimg.cn/img_convert/37283dea169f93700501ce83f9295bce.png)
⽹络层负责将数据从⼀个设备传输到另⼀个设备，世界上那么多设备，⼜该如何找到对⽅呢？因此，⽹络层需要有
区分设备的编号。

我们⼀般⽤ IP 地址给设备进⾏编号，对于 IPv4 协议， IP 地址共 32 位，分成了四段，每段是 8 位。只有⼀个单纯的 IP 地址虽然做到了区分设备，但是寻址起来就特别麻烦，全世界那么多台设备，难道⼀个⼀个去匹配？这显然不科学。

因此，需要将 IP 地址分成两种意义：

 - List item ⼀个是 **⽹络号**，负责标识该 IP 地址是属于哪个⼦⽹的；

 - List item ⼀个是 **主机号**，负责标识同⼀⼦⽹下的不同主机；

怎么分的呢？这需要配合**⼦⽹掩码**才能算出 IP 地址 的⽹络号和主机号。那么在寻址的过程中，先匹配到相同的⽹络号，才会去找对应的主机。

除了寻址能⼒， IP 协议还有另⼀个重要的能⼒就是**路由**。实际场景中，两台设备并不是⽤⼀条⽹线连接起来的，⽽是通过很多⽹关、路由器、交换机等众多⽹络设备连接起来的，那么就会形成很多条⽹络的路径，因此当数据包到达⼀个⽹络节点，就需要通过算法决定下⼀步⾛哪条路径。

所以，**IP 协议的寻址作⽤是告诉我们去往下⼀个⽬的地该朝哪个⽅向⾛，路由则是根据「下⼀个⽬的地」选择路径。寻址更像在导航，路由更像在操作⽅向盘。**


#### 数据链路层
实际场景中，⽹络并不是⼀个整体，⽐如你家和我家就不属于⼀个⽹络，所以数据不仅可以在同⼀个⽹络中设备间进⾏传输，也可以跨⽹络进⾏传输。

⼀旦数据需要跨⽹络传输，就需要有⼀个设备同时在两个⽹络当中，这个设备⼀般是路由器，路由器可以通过路由表计算出下⼀个要去的IP 地址。

那问题来了，路由器怎么知道这个 IP 地址是哪个设备的呢？

于是，就需要有⼀个专⻔的层来标识⽹络中的设备，让数据在⼀个链路中传输，这就是数据链路层（Data LinkLayer），它主要为⽹络层提供链路级别传输的服务。

![](https://img-blog.csdnimg.cn/img_convert/68736cc1fcbf2b8344e927c65515f124.png)
每⼀台设备的⽹卡都会有⼀个 MAC 地址，它就是⽤来唯⼀标识设备的。路由器计算出了下⼀个⽬的地 IP 地址，再通过 ARP 协议找到该⽬的地的 MAC 地址，这样就知道这个 IP 地址是哪个设备的了。


#### 物理层
当数据准备要从设备发送到⽹络时，需要把数据包转换成电信号，让其可以在物理介质中传输，这⼀层就是物理层（Physical Layer），它主要是为数据链路层提供⼆进制传输的服务。
![](https://img-blog.csdnimg.cn/img_convert/d38184e84df101d5c69fbb36ec9d50d7.png)

综上所述，⽹络协议通常是由上到下，分成 5 层没，分别是**应⽤层，传输层，⽹络层，数据链路层和物理层。**


## 二、HTTP 篇
![](https://img-blog.csdnimg.cn/img_convert/cb3ad09f3c639711e8579eb11d7cc660.png)

### 2.1 HTTP 是什么？描述⼀下。
HTTP 是超⽂本传输协议，也就是HyperText Transfer Protocol。
### 2.2 能否详细解释「超⽂本传输协议」？
HTTP的名字「超⽂本协议传输」，它可以拆成三个部分：

 - 超⽂本
   
 - 传输
   
 - 协议

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20211130211900.png)

#### 1. 「协议」

在⽣活中，我们也能随处可⻅「协议」，例如：

刚毕业时会签⼀个「三⽅协议」；

找房⼦时会签⼀个「租房协议」；

⽣活中的协议，本质上与计算机中的协议是相同的，协议的特点:

「**协**」字，代表的意思是必须有**两个以上的参与者**。例如三⽅协议⾥的参与者有三个：你、公司、学校三个；租房协议⾥的参与者有两个：你和房东。

「**议**」字，代表的意思是对参与者的⼀种 **⾏为约定和规范**。例如三⽅协议⾥规定试⽤期期限、毁约⾦等；租房协议⾥规定租期期限、每⽉租⾦⾦额、违约如何处理等。

针对 HTTP 协议，我们可以这么理解。

HTTP 是⼀个⽤在计算机世界⾥的协议。它使⽤计算机能够理解的语⾔确⽴了⼀种计算机之间交流通信的规范（**两个以上的参与者**），以及相关的各种控制和错误处理⽅式（**⾏为约定和规范**）。


#### 2. 「传输」
所谓的「传输」，很好理解，就是把⼀堆东⻄从 A 点搬到 B 点，或者从 B 点 搬到 A 点。
别轻视了这个简单的动作，它⾄少包含两项重要的信息。

HTTP 协议是⼀个**双向协议**。
我们在上⽹冲浪时，浏览器是请求⽅ A ，百度⽹站就是应答⽅ B。双⽅约定⽤ HTTP 协议来通信，于是浏览器把请求数据发送给⽹站，⽹站再把⼀些数据返回给浏览器，最后由浏览器渲染在屏幕，就可以看到图⽚、视频了。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201094110.png)

数据虽然是在 A 和 B 之间传输，但允许中间有**中转或接⼒**。

就好像第⼀排的同学想传递纸条给最后⼀排的同学，那么传递的过程中就需要经过好多个同学（中间⼈），这样的传输⽅式就从「A < --- > B」，变成了「A <-> N <-> M <-> B」。

⽽在 HTTP ⾥，需要中间⼈遵从 HTTP 协议，只要不打扰基本的数据传输，就可以添加任意额外的东⻄。

针对传输，我们可以进⼀步理解了 HTTP。

HTTP 是⼀个在计算机世界⾥专⻔⽤来在**两点之间传输数据**的约定和规范。

#### 3. 「超⽂本」
HTTP 传输的内容是「超⽂本」。

我们先来理解「⽂本」，在互联⽹早期的时候只是简单的字符⽂字，但现在「⽂本」的涵义已经可以扩展为图⽚、视频、压缩包等，在 HTTP 眼⾥这些都算作「⽂本」。

再来理解「超⽂本」，它就是超越了普通⽂本的⽂本，它是⽂字、图⽚、视频等的混合体，最关键有超链接，能从⼀个超⽂本跳转到另外⼀个超⽂本。

HTML 就是最常⻅的超⽂本了，它本身只是纯⽂字⽂件，但内部⽤很多标签定义了图⽚、视频等的链接，再经过浏览器的解释，呈现给我们的就是⼀个⽂字、有画⾯的⽹⻚了。

**HTTP 是⼀个在计算机世界⾥专⻔在「两点」之间「传输」⽂字、图⽚、⾳频、视频等「超⽂本」数据的「约定和规范」。**

### 2.3 HTTP 常⻅的状态码有哪些？
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201100340.png)

- 1xx 类状态码属于提示信息，是协议处理中的⼀种中间状态，实际⽤到的⽐较少。

- 2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。

「200 OK」是最常⻅的成功状态码，表示⼀切正常。如果是 **⾮ HEAD** 请求，服务器返回的响应头 都会有 body数据。

「204 No Content」也是常⻅的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。

「206 Partial Content」是应⽤于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，⽽是其中的⼀部分，也是服务器处理成功的状态。

- 3xx 类状态码表示客户端请求的资源发送了变动，需要客户端⽤新的 URL  新发送请求获取资源，也就是重定向。

「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改⽤新的 URL 再次访问。

「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要⽤另⼀个 URL 来访问。
301 和 302 都会在响应头⾥使⽤字段 **Location** ，指明后续要跳转的 URL，浏览器会⾃动重定向新的 URL。

「304 Not Modified」不具有跳转的含义，表示资源未修改， 重定向已存在的缓冲⽂件，也称缓存重定向，⽤于缓存控制。


- 4xx 类状态码表示客户端发送的报⽂有误，服务器⽆法处理，也就是错误码的含义。

「400 Bad Request」表示客户端请求的报⽂有错误，但只是个笼统的错误。

「403 Forbidden」表示服务器禁⽌访问资源，并不是客户端的请求出错。

「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以⽆法提供给客户端。

- 5xx 类状态码表示客户端请求报⽂正确，但是服务器处理时内部发⽣了错误，属于服务器端的错误码。

「500 Internal Server Error」与 400 类型，是个笼统通⽤的错误码，服务器发⽣了什么错误，我们并不知道。

「501 Not Implemented」表示客户端请求的功能还不⽀持，类似“即将开业，敬请期待”的意思。

「502 Bad Gateway」通常是服务器作为⽹关或代理时返回的错误码，表示服务器⾃身⼯作正常，访问后端服务器
发⽣了错误。

「503 Service Unavailable」表示服务器当前很忙，暂时⽆法响应服务器，类似“⽹络服务正忙，请稍后 试”的意
思。

### 2.4 http 常⻅字段有哪些？
- **Host字段** ：客户端发送请求时，⽤来指定服务器的域名。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201101323.png)

有了 Host 字段，就可以将请求发往「同⼀台」服务器上的不同⽹站。

- **Content-Length 字段** ：服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据⻓度。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201101944.png)

如上⾯则是告诉浏览器，本次服务器回应的数据⻓度是 1000 个字节，后⾯的字节就属于下⼀个回应了。

- **Connection 字段**：常⽤于客户端要求服务器使⽤ TCP 持久连接，以便其他请求复⽤。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201102142.png)

HTTP/1.1 版本的默认连接都是**持久连接**，但为了兼容⽼版本的 HTTP，需要指定 Connection ⾸部字段的值为
**keep-Alive** 。
⼀个可以复⽤的 TCP 连接就建⽴了，直到客户端或服务器主动关闭连接。但是，这不是标准字段。

- **Content-Type 字段**:⽤于服务器回应时，告诉客户端，本次数据是什么格式。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201102506.png)

上⾯的类型表明，发送的是⽹⻚，⽽且编码是UTF-8。

客户端请求的时候，可以使⽤ Accept 字段声明⾃⼰可以接受哪些数据格式。

Accept: * **/** *

上⾯代码中，客户端声明⾃⼰可以接受任何格式的数据。

- **Content-Encoding 字段** ：说明数据的压缩⽅法。表示服务器返回的数据使⽤了什么压缩格式

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201102902.png)

上⾯表示服务器返回的数据采⽤了 gzip ⽅式压缩，告知客户端需要⽤此⽅式解压。

客户端在请求时，⽤ Accept-Encoding 字段说明⾃⼰可以接受哪些压缩⽅法。

Accept-Encoding: gzip, deflate


### 2.5 说⼀下 GET 和 POST 的区别？
Get ⽅法的含义是请求从服务器获取资源，这个资源可以是静态的⽂本、⻚⾯、图⽚视频等。

⽐如，你打开我的⽂章，浏览器就会发送 GET 请求给服务器，服务器就会返回⽂章的所有⽂字及资源。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201103341.png)


⽽ POST ⽅法则是相反操作，它向 URI 指定的资源提交数据，数据就放在报⽂的 body ⾥。

⽐如，你在我⽂章底部，敲⼊了留⾔后点击「提交」（暗示你们留⾔），浏览器就会执⾏⼀次 POST 请求，把你的留⾔⽂字放进了报⽂ body ⾥，然后拼接好 POST 请求头，通过 TCP 协议发送给服务器。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201104454.png)

### 2.6 GET 和 POST ⽅法都是安全和幂等的吗？
先说明下安全和幂等的概念：
- 在 HTTP 协议⾥，所谓的「安全」是指请求⽅法不会「破坏」服务器上的资源。
- 所谓的「幂等」，意思是多次执⾏相同的操作，结果都是「相同」的。

那么很明显 GET ⽅法就是安全且幂等的，因为它是「只读」操作，⽆论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。

POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。

### 2.7  HTTP（1.1） 的优点有哪些，怎么体现的？
HTTP 最凸出的优点是「简单、灵活和易于扩展、应⽤⼴泛和跨平台」。

- 简单

HTTP 基本的报⽂格式就是 header + body ，头部信息也是 key-value 简单⽂本的形式，易于理解，降低了学习和使⽤的⻔槛。

- 灵活和易于扩展

HTTP协议⾥的各类请求⽅法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发⼈员⾃定义和扩充。

同时 HTTP 由于是⼯作在应⽤层（ OSI 第七层），则它下层可以随意变化。

HTTPS 也就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层，HTTP/3 甚⾄把 TCP 层换成了基于 UDP 的QUIC。

- 应⽤⼴泛和跨平台

互联⽹发展⾄今，HTTP 的应⽤范围⾮常的⼴泛，从台式机的浏览器到⼿机上的各种 APP，从看新闻、刷贴吧到购物、理财、吃鸡，HTTP 的应⽤⽚地开花，同时天然具有跨平台的优越性。

### 2.8  HTTP（1.1） 的缺点呢？

HTTP 协议⾥有优缺点⼀体的双刃剑，分别是「⽆状态、明⽂传输」，同时还有⼀⼤缺点「不安全」。

#### 1. ⽆状态双刃剑
⽆状态的好处，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存⽤来对外提供服务。

⽆状态的坏处，既然服务器没有记忆能⼒，它在完成有关联性的操作时会⾮常麻烦。

例如登录->添加购物⻋->下单->结算->⽀付，这系列操作都要知道⽤户的身份才⾏。但服务器不知道这些请求是有关联的，每次都要问⼀遍身份信息。

对于⽆状态的问题，解法⽅案有很多种，其中⽐较简单的⽅式⽤ Cookie 技术。

Cookie 通过在请求和响应报⽂中写⼊ Cookie 信息来控制客户端的状态。

相当于，在客户端第⼀次请求后，服务器会下发⼀个装有客户信息的「⼩贴纸」，后续客户端请求服务器的时候，带上「⼩贴纸」，服务器就能认得了了.

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201111802.png)

#### 2. 明⽂传输双刃剑
明⽂意味着在传输过程中的信息，是可⽅便阅读的，通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接⾁眼查看，为我们调试⼯作带了极⼤的便利性。

但是这正是这样，HTTP 的所有信息都暴露在了光天化⽇下，相当于信息裸奔。在传输的漫⻓的过程中，信息的内
容都毫⽆隐私可⾔，很容易就能被窃取，如果⾥⾯有你的账号密码信息，**那你号没了**。


#### 3. 不安全
HTTP ⽐较严重的缺点就是不安全：
- 通信使⽤明⽂（不加密），内容可能会被窃听。⽐如，账号信息容易泄漏，那你号没了。
- 不验证通信⽅的身份，因此有可能遭遇伪装。⽐如，访问假的淘宝、拼多多，那你钱没了。
- ⽆法证明报⽂的完整性，所以有可能已遭篡改。⽐如，⽹⻚上植⼊垃圾⼴告，视觉污染，眼没了。

HTTP 的安全问题，可以⽤ HTTPS 的⽅式解决，也就是通过引⼊ SSL/TLS 层，使得在安全上达到了极致。

### 2.9 那你再说下 HTTP/1.1 的性能如何？
HTTP 协议是基于 **TCP/IP**，并且使⽤了 **「请求 - 应答」** 的通信模式，所以性能的关键就在这两点⾥。

#### 1. ⻓连接

早期 HTTP/1.0 性能上的⼀个很⼤的问题，那就是每发起⼀个请求，都要新建⼀次 TCP 连接（三次握⼿），⽽且是串⾏请求，做了⽆谓的 TCP 连接建⽴和断开，增加了通信开销。

为了解决上述 TCP 连接问题，HTTP/1.1 提出了⻓连接的通信⽅式，也叫持久连接。这种⽅式的好处在于减少了TCP 连接的重复建⽴和断开所造成的额外开销，减轻了服务器端的负载。

持久连接的特点是，只要任意⼀端没有明确提出断开连接，则保持 TCP 连接状态。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201112821.png)

#### 2. 管道⽹络传输
HTTP/1.1 采⽤了⻓连接的⽅式，这使得管道（pipeline）⽹络传输成为了可能。

即可在同⼀个 TCP 连接⾥⾯，客户端可以发起多个请求，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以**减少整体的响应时间**。

举例来说，客户端需要请求两个资源。以前的做法是，在同⼀个TCP连接⾥⾯，先发送 A 请求，然后等待服务器做出回应，收到后再发出 B 请求。管道机制则是允许浏览器同时发出 A 请求和 B 请求。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201113357.png)

但是服务器还是按照顺序，先回应 A 请求，完成后再回应 B 请求。要是前⾯的回应特别慢，后⾯就会有许多请求排队等着。这称为「队头堵塞」。


#### 3. 队头阻塞
「请求 - 应答」的模式加剧了 HTTP 的性能问题。
因为当顺序发送的请求序列中的⼀个请求因为某种原因被阻塞时，在后⾯排队的所有请求也⼀同被阻塞了，会招致客户端⼀直请求不到数据，这也就是「队头阻塞」。好⽐上班的路上塞⻋。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201113703.png)

总之 HTTP/1.1 的性能⼀般般，后续的 HTTP/2 和 HTTP/3 就是在优化 HTTP 的性能。


### 2.10 HTTP 与 HTTPS 有哪些区别？
1. HTTP 是超⽂本传输协议，信息是明⽂传输，存在安全⻛险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在TCP 和 HTTP ⽹络层之间加⼊了 SSL/TLS 安全协议，使得报⽂能够加密传输。

2. HTTP 连接建⽴相对简单， TCP 三次握⼿之后便可进⾏ HTTP 的报⽂传输。⽽ HTTPS 在 TCP 三次握⼿之后，还需进⾏ SSL/TLS 的握⼿过程，才可进⼊加密报⽂传输。

3. HTTP 的端⼝号是 80，HTTPS 的端⼝号是 443。

4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

### 2.11 HTTPS 解决了 HTTP 的哪些问题？
HTTP 由于是明⽂传输，所以安全上存在以下三个⻛险：

- 窃听⻛险，⽐如通信链路上可以获取通信内容，⽤户号容易没。
- 篡改⻛险，⽐如强制植⼊垃圾⼴告，视觉污染，⽤户眼容易瞎。
- 冒充⻛险，⽐如冒充淘宝⽹站，⽤户钱容易没。

HTTPS 在 HTTP 与 TCP 层之间加⼊了 SSL/TLS 协议，可以很好的解决了上述的⻛险：
- 信息加密：交互信息⽆法被窃取，但你的号会因为「⾃身忘记」账号⽽没。
- 校验机制：⽆法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾⼴告。
- 身份证书：证明淘宝是真的淘宝⽹，但你的钱还是会因为「剁⼿」⽽没。


### 2.12 HTTPS 具体是如何解决上⾯的三个⻛险的？
1、**混合加密**的⽅式实现信息的机密性，解决了窃听的⻛险。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201115157.png)

HTTPS 采⽤的是对称加密和⾮对称加密结合的「混合加密」⽅式：
- 在通信建⽴前采⽤⾮对称加密的⽅式交换「会话秘钥」，后续就不再使⽤⾮对称加密。
- 在通信过程中全部使⽤对称加密的「会话秘钥」的⽅式加密明⽂数据。

采⽤「混合加密」的⽅式的原因：

- 对称加密只使⽤⼀个密钥，运算速度快，密钥必须保密，⽆法做到安全的密钥交换。
- ⾮对称加密使⽤两个密钥：公钥和私钥，公钥可以任意分发⽽私钥保密，解决了密钥交换问题但速度慢。

2、**摘要算法**的⽅式来实现完整性，它能够为数据⽣成独⼀⽆⼆的「指纹」，指纹⽤于校验数据的完整性，解决了篡改的⻛险。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201115953.png)

客户端在发送明⽂之前会通过摘要算法算出明⽂的「指纹」，发送的时候把「指纹 + 明⽂」⼀同加密成密⽂后，发送给服务器，服务器解密后，⽤相同的摘要算法算出发送过来的明⽂，通过⽐较客户端携带的「指纹」和当前算出的「指纹」做⽐较，若「指纹」相同，说明数据是完整的。

3、将服务器公钥放⼊到**数字证书**中，解决了冒充的⻛险。

客户端先向服务器端索要公钥，然后⽤公钥加密信息，服务器收到密⽂后，⽤⾃⼰的私钥解密。

这就存在些问题，如何保证公钥不被篡改和信任度？

所以这⾥就需要借助第三⽅权威机构 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201121704.png)


### 2.13 HTTPS 是如何建⽴连接的？其间交互了什么？

SSL/TLS 协议基本流程：

客户端向服务器索要并验证服务器的公钥。

双⽅协商⽣产「会话秘钥」。

双⽅采⽤「会话秘钥」进⾏加密通信。

前两步也就是 SSL/TLS 的建⽴过程，也就是握⼿阶段。

SSL/TLS 的「握⼿阶段」涉及四次通信，可⻅下图：
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201122616.png)
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201122635.png)
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201122641.png)
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201122649.png)
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201122652.png)

SSL/TLS 协议建⽴的详细流程：
#### 1. ClientHello

⾸先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。

在这⼀步，客户端主要向服务器发送以下信息：

（1）客户端⽀持的 SSL/TLS 协议版本，如 TLS 1.2 版本。

（2）客户端⽣产的随机数（ Client Random ），后⾯⽤于⽣产「会话秘钥」。

（3）客户端⽀持的密码套件列表，如 RSA 加密算法。

#### 2. SeverHello
服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello 。服务器回应的内容有如下内容：

（1）确认 SSL/ TLS 协议版本，如果浏览器不⽀持，则关闭加密通信。

（2）服务器⽣产的随机数（ Server Random ），后⾯⽤于⽣产「会话秘钥」。

（3）确认的密码套件列表，如 RSA 加密算法。

（4）服务器的数字证书。

#### 3.客户端回应
客户端收到服务器的回应之后，⾸先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。

如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使⽤它加密报⽂，向服务器发送如下信息：

（1）⼀个随机数（ pre-master key ）。该随机数会被服务器公钥加密。

（2）加密通信算法改变通知，表示随后的信息都将⽤「会话秘钥」加密通信。

（3）客户端握⼿结束通知，表示客户端的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘要，⽤来供服务端校验。

上⾯第⼀项的随机数是整个握⼿阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着就⽤双⽅协商的加密算法，各⾃⽣成本次通信的「会话秘钥」。

#### 4. 服务器的最后回应
服务器收到客户端的第三个随机数（ pre-master key ）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。然后，向客户端发⽣最后的信息：

（1）加密通信算法改变通知，表示随后的信息都将⽤「会话秘钥」加密通信。

（2）服务器握⼿结束通知，表示服务器的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘要，⽤来供客户端校验。

⾄此，整个 SSL/TLS 的握⼿阶段全部结束。接下来，客户端与服务器进⼊加密通信，就完全是使⽤普通的 HTTP协议，只不过⽤「会话秘钥」加密内容。

### 2.14 说说 HTTP/1.1 相⽐ HTTP/1.0 提⾼了什么性能？
HTTP/1.1 相⽐ HTTP/1.0 性能上的改进：
- 使⽤ TCP ⻓连接的⽅式改善了 HTTP/1.0 短连接造成的性能开销。
- ⽀持管道（pipeline）⽹络传输，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以减少整体的响应时间。

但 HTTP/1.1 还是有性能瓶颈：

- 请求 / 响应头部（Header）未经压缩就发送，⾸部信息越多延迟越⼤。只能压缩 Body 的部分；

- 发送冗⻓的⾸部。每次互相发送相同的⾸部造成的浪费较多；

- 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端⼀直请求不到数据，也就是队头阻塞；

- 没有请求优先级控制；

- 请求只能从客户端开始，服务器只能被动响应。

### 2.15 那上⾯的 HTTP/1.1 的性能瓶颈，HTTP/2 做了什么优化？
HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。

那 HTTP/2 相⽐ HTTP/1.1 性能上的改进：
#### 1. 头部压缩
HTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是⼀样的或是相似的，那么，协议会帮你消除重复的部分。

这就是所谓的 HPACK 算法：在客户端和服务器同时维护⼀张头信息表，所有字段都会存⼊这个表，⽣成⼀个索引号，以后就不发送同样字段了，只发送索引号，这样就提⾼速度了。

#### 2. ⼆进制格式
HTTP/2 不再像 HTTP/1.1 ⾥的纯⽂本形式的报⽂，⽽是全⾯采⽤了⼆进制格式，头信息和数据体都是⼆进制，并且统称为帧（frame）：头信息帧和数据帧。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201124621.png)

这样虽然对⼈不友好，但是对计算机⾮常友好，因为计算机只懂⼆进制，那么收到报⽂后，⽆需再将明⽂的报⽂转成⼆进制，⽽是直接解析⼆进制报⽂，这**增加了数据传输的效率**。

#### 3. 数据流
HTTP/2 的数据包不是按顺序发送的，同⼀个连接⾥⾯连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。

每个请求或回应的所有数据包，称为⼀个数据流（ Stream ）。每个数据流都标记着⼀个独⼀⽆⼆的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数

客户端还可以**指定数据流的优先级**。优先级⾼的请求，服务器就先响应该请求。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201125028.png)

#### 4. 多路复⽤
HTTP/2 是可以在⼀个连接中并发多个请求或回应，⽽不⽤按照顺序⼀⼀对应。

移除了 HTTP/1.1 中的串⾏请求，不需要排队等待，也就不会再出现「队头阻塞」问题，**降低了延迟，⼤幅度提⾼了连接的利⽤率**。

举例来说，在⼀个 TCP 连接⾥，服务器收到了客户端 A 和 B 的两个请求，如果发现 A 处理过程⾮常耗时，于是就回应 A 请求已经处理好的部分，接着回应 B 请求，完成后，再回应 A 请求剩下的部分。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201125349.png)

#### 5. 服务器推送
HTTP/2 还在⼀定程度上改善了传统的「请求 - 应答」⼯作模式，服务不再是被动地响应，也可以主动向客户端发送消息。

举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会⽤到的 JS、CSS ⽂件等静态资源主动发给客户端，减少延时的等待，也就是服务器推送（Server Push，也叫 Cache Push）。

### 2.16 HTTP/2 有哪些缺陷？HTTP/3 做了哪些优化？
HTTP/2 主要的问题在于，多个 HTTP 请求在复⽤⼀个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。所以⼀旦发⽣了丢包现象，就会触发 TCP 的重传机制，这样在⼀个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。

- HTTP/1.1 中的管道（ pipeline）传输中如果有⼀个请求阻塞了，那么队列后请求也统统被阻塞住了
- HTTP/2 多个请求复⽤⼀个TCP连接，⼀旦发⽣丢包，就会阻塞住所有的 HTTP 请求。

这都是基于 TCP 传输层的问题，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201130344.png)


UDP 发⽣是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的⼀个丢包全部 传问题。

⼤家都知道 UDP 是不可靠传输的，但基于 UDP 的 **QUIC** 协议 可以实现类似 TCP 的可靠性传输。
- QUIC 有⾃⼰的⼀套机制可以保证传输的可靠性的。当某个流发⽣丢包时，只会阻塞这个流，其他流不会受到影响。

- TLS3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack 。

- HTTPS 要建⽴⼀个连接，要花费 6 次交互，先是建⽴三次握⼿，然后是 TLS/1.3 的三次握⼿。QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数。

### 2.17 https和http相⽐，就是传输的内容多了对称加密，可以这么理解吗？

1. 建⽴连接时候：https ⽐ http多了 TLS 的握⼿过程；
2. 传输内容的时候：https 会把数据进⾏加密，通常是对称加密数据；

### 2.18 为啥 ssl 的握⼿是 4 次？
SSL/TLS 1.2 需要 4 握⼿，需要 2 个 RTT 的时延.

另外， SSL/TLS 1.3 优化了过程，只需要 1 个 RTT 往返时延，也就是只需要 3 次握⼿：

### 2.19 HTTP/1.1如何优化？
我想你第⼀时间想到的是，使⽤ KeepAlive 将 HTTP/1.1 从短连接改成⻓链接。

这个确实是⼀个优化的⼿段，它是从底层的传输层这⼀⽅向⼊⼿的，通过减少 TCP 连接建⽴和断开的次数，来减少了⽹络传输的延迟，从⽽提⾼ HTTP/1.1 协议的传输效率。

但其实还可以从其他⽅向来优化 HTTP/1.1 协议，⽐如有如下 3 种优化思路：
- 尽量避免发送 HTTP 请求；
- 在需要发送 HTTP 请求时，考虑如何减少请求次数；
- 减少服务器的 HTTP 响应的数据⼤⼩；

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201131938.png)


#### 1、如何避免发送 HTTP 请求？
- 对于⼀些具有重复性的 HTTP 请求，⽐如每次请求得到的数据都⼀样的，我们可以把这对「请求-响应」的数据都**缓存在本地**，那么下次就直接读取本地的数据，不必在通过⽹络获取服务器的响应了。

- 所以，避免发送 HTTP 请求的⽅法就是通过**缓存技术**，HTTP 设计者早在之前就考虑到了这点，因此 HTTP 协议的头部有不少是针对缓存的字段。


那缓存是如何做到的呢？

客户端会把第⼀次请求以及响应的数据保存在本地磁盘上，其中将请求的 URL 作为 key，⽽响应作为 value，两者形成映射关系。

这样当后续发起相同的请求时，就可以先在本地磁盘上通过 key 查到对应的 value，也就是响应，如果找到了，就直接从本地读取该响应。毋庸置疑，读取本次磁盘的速度肯定⽐⽹络请求快得多，如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201132559.png)

聪明的你可能想到了，万⼀缓存的响应不是最新的，⽽客户端并不知情，那么该怎么办呢？

放⼼，这个问题 HTTP 设计者早已考虑到。

所以，服务器在发送 HTTP 响应时，会估算⼀个过期的时间，并把这个信息放到响应头部中，这样客户端在查看响应头部的信息时，⼀旦发现缓存的响应是过期的，则就会重新发送⽹络请求。

如果客户端从第⼀次请求得到的响应头部中发现该响应过期了，客户端重新发送请求，假设服务器上的资源并没有变更，还是⽼样⼦，那么你觉得还要在服务器的响应带上这个资源吗？

很显然不带的话，可以提⾼ HTTP 协议的性能，那具体如何做到呢？

只需要客户端在重新发送请求时，在请求的 Etag 头部带上第⼀次请求的响应头部中的摘要，这个摘要是唯⼀标识响应的资源，当服务器收到请求后，会将本地资源的摘要与请求中的摘要做个⽐较。

如果不同，那么说明客户端的缓存已经没有价值，服务器在响应中带上最新的资源。

如果相同，说明客户端的缓存还是可以继续使⽤的，那么服务器仅返回不含有包体的 304 Not Modified 响应，告诉客户端仍然有效，这样就可以减少响应资源在⽹络中传输的延时，如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201133233.png)

缓存真的是性能优化的⼀把万能钥匙，⼩到 CPU Cache、Page Cache、Redis Cache，⼤到 HTTP 协议的缓存。

#### 2、如何减少 HTTP 请求次数？
- 减少重定向请求次数；
- 合并请求；
- 延迟发送请求；
