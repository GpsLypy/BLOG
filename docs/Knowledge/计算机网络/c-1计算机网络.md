## 一、基础篇

### 1.1 TCP/IP ⽹络模型

对于同⼀台设备上的进程间通信，有很多种⽅式，⽐如**管道、消息队列、共享内存、信号**等⽅式，⽽对于不同设备上的进程间通信，就需要⽹络通信，⽽设备是多样性的，所以要兼容多种多样的设备，就协商出了⼀套通⽤的**⽹络协议**。

这个⽹络协议是分层的，每⼀层都有各⾃的作⽤和职责。

#### 应用层
最上层的，也是我们能直接接触到的就是应⽤层（Application Layer），我们电脑或⼿机使⽤的应⽤软件都是在应⽤层实现。那么，当两个不同设备的应⽤需要通信的时候，应⽤就把应⽤数据传给下⼀层，也就是传输层。
所以，应⽤层只需要专注于为⽤户提供应⽤功能，不⽤去关⼼数据是如何传输的，就类似于，我们寄快递的时候，
只需要把包裹交给快递员，由他负责运输快递，我们不需要关⼼快速是如何被运输的。
⽽且**应⽤层是⼯作在操作系统中的⽤户态，传输层及以下则⼯作在内核态**。

#### 传输层
应⽤层的数据包会传给传输层，传输层（Transport Layer）是为应⽤层提供⽹络⽀持的。

![](https://img-blog.csdnimg.cn/img_convert/6301b3b9215e239874c8dd8ca412b2f0.png)

在传输层会有两个传输协议，分别是 TCP 和 UDP。

TCP 的全称叫传输层控制协议（Transmission Control Protocol），⼤部分应⽤使⽤的正是 TCP 传输层协议，⽐
如 HTTP 应⽤层协议。TCP 相⽐ UDP 多了很多特性，⽐如流量控制、超时重传、拥塞控制等，这些都是为了保证数据包能可靠地传输给对⽅。

UDP 就相对很简单，简单到只负责发送数据包，不保证数据包是否能抵达对⽅，但它实时性相对更好，传输效率也⾼。

**当然，UDP 也可以实现可靠传输，把 TCP 的特性在应⽤层上实现就可以**，不过要实现⼀个商⽤的可靠 UDP传输协议，也不是⼀件简单的事情。应⽤需要传输的数据可能会⾮常⼤，如果直接传输就不好控制，因此**当传输层的数据包⼤⼩超过 MSS（TCP 最⼤报⽂段⻓度） ，就要将数据包分块**，这样即使中途有⼀个分块丢失或损坏了，只需要重发这⼀个分块，⽽不⽤重新发送整个数据包。在 TCP 协议中，我们把每个分块称为⼀个 TCP （TCP Segment）。


![](https://img-blog.csdnimg.cn/img_convert/55a3ce0b0fce882f32bf0f16ddfc6314.png)

当设备作为接收⽅时，传输层则要负责把数据包传给应⽤，但是⼀台设备上可能会有很多应⽤在接收或者传输数据，因此需要⽤⼀个编号将应⽤区分开来，这个编号就是端⼝。

⽐如 80 端⼝通常是 Web 服务器⽤的，22 端⼝通常是远程登录服务器⽤的。⽽对于浏览器（客户端）中的每个标签栏都是⼀个独⽴的进程，操作系统会为这些进程分配临时的端⼝号。

由于传输层的报⽂中会携带端⼝号，因此接收⽅可以识别出该报⽂是发送给哪个应⽤。


#### ⽹络层
传输层可能⼤家刚接触的时候，会认为它负责将数据从⼀个设备传输到另⼀个设备，事实上它并不负责。

实际场景中的⽹络环节是错综复杂的，中间有各种各样的线路和分叉路⼝，如果⼀个设备的数据要传输给另⼀个设备，就需要在各种各样的路径和节点进⾏选择，⽽传输层的设计理念是简单、⾼效、专注，如果传输层还负责这⼀块功能就有点违背设计原则了。

也就是说，我们不希望传输层协议处理太多的事情，只需要服务好应⽤即可，让其作为应⽤间数据传输的媒介，帮助实现应⽤到应⽤的通信，⽽实际的传输功能就交给下⼀层，也就是⽹络层（Internet Layer）。

![](https://img-blog.csdnimg.cn/img_convert/fbb69a4e9f2058ec56ee078646642bd9.png)

⽹络层最常使⽤的是 IP 协议（Internet Protocol），**IP 协议会将传输层的报⽂作为数据部分，再加上 IP 包头组装成 IP 报⽂，如果 IP 报⽂⼤⼩超过 MTU（以太⽹中⼀般为 1500 字节）就会再次进⾏分⽚，得到⼀个即将发送到⽹络的 IP 报⽂。**


![](https://img-blog.csdnimg.cn/img_convert/37283dea169f93700501ce83f9295bce.png)
⽹络层负责将数据从⼀个设备传输到另⼀个设备，世界上那么多设备，⼜该如何找到对⽅呢？因此，⽹络层需要有
区分设备的编号。

我们⼀般⽤ IP 地址给设备进⾏编号，对于 IPv4 协议， IP 地址共 32 位，分成了四段，每段是 8 位。只有⼀个单纯的 IP 地址虽然做到了区分设备，但是寻址起来就特别麻烦，全世界那么多台设备，难道⼀个⼀个去匹配？这显然不科学。

因此，需要将 IP 地址分成两种意义：

 - List item ⼀个是 **⽹络号**，负责标识该 IP 地址是属于哪个⼦⽹的；

 - List item ⼀个是 **主机号**，负责标识同⼀⼦⽹下的不同主机；

怎么分的呢？这需要配合**⼦⽹掩码**才能算出 IP 地址 的⽹络号和主机号。那么在寻址的过程中，先匹配到相同的⽹络号，才会去找对应的主机。

除了寻址能⼒， IP 协议还有另⼀个重要的能⼒就是**路由**。实际场景中，两台设备并不是⽤⼀条⽹线连接起来的，⽽是通过很多⽹关、路由器、交换机等众多⽹络设备连接起来的，那么就会形成很多条⽹络的路径，因此当数据包到达⼀个⽹络节点，就需要通过算法决定下⼀步⾛哪条路径。

所以，**IP 协议的寻址作⽤是告诉我们去往下⼀个⽬的地该朝哪个⽅向⾛，路由则是根据「下⼀个⽬的地」选择路径。寻址更像在导航，路由更像在操作⽅向盘。**


#### 数据链路层
实际场景中，⽹络并不是⼀个整体，⽐如你家和我家就不属于⼀个⽹络，所以数据不仅可以在同⼀个⽹络中设备间进⾏传输，也可以跨⽹络进⾏传输。

⼀旦数据需要跨⽹络传输，就需要有⼀个设备同时在两个⽹络当中，这个设备⼀般是路由器，路由器可以通过路由表计算出下⼀个要去的IP 地址。

那问题来了，路由器怎么知道这个 IP 地址是哪个设备的呢？

于是，就需要有⼀个专⻔的层来标识⽹络中的设备，让数据在⼀个链路中传输，这就是数据链路层（Data LinkLayer），它主要为⽹络层提供链路级别传输的服务。

![](https://img-blog.csdnimg.cn/img_convert/68736cc1fcbf2b8344e927c65515f124.png)
每⼀台设备的⽹卡都会有⼀个 MAC 地址，它就是⽤来唯⼀标识设备的。路由器计算出了下⼀个⽬的地 IP 地址，再通过 ARP 协议找到该⽬的地的 MAC 地址，这样就知道这个 IP 地址是哪个设备的了。


#### 物理层
当数据准备要从设备发送到⽹络时，需要把数据包转换成电信号，让其可以在物理介质中传输，这⼀层就是物理层（Physical Layer），它主要是为数据链路层提供⼆进制传输的服务。
![](https://img-blog.csdnimg.cn/img_convert/d38184e84df101d5c69fbb36ec9d50d7.png)

综上所述，⽹络协议通常是由上到下，分成 5 层没，分别是**应⽤层，传输层，⽹络层，数据链路层和物理层。**


## 二、HTTP 篇
![](https://img-blog.csdnimg.cn/img_convert/cb3ad09f3c639711e8579eb11d7cc660.png)

### 2.1 HTTP 是什么？描述⼀下。
HTTP 是超⽂本传输协议，也就是HyperText Transfer Protocol。
### 2.2 能否详细解释「超⽂本传输协议」？
HTTP的名字「超⽂本协议传输」，它可以拆成三个部分：

 - 超⽂本
   
 - 传输
   
 - 协议

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20211130211900.png)

#### 1. 「协议」

在⽣活中，我们也能随处可⻅「协议」，例如：

刚毕业时会签⼀个「三⽅协议」；

找房⼦时会签⼀个「租房协议」；

⽣活中的协议，本质上与计算机中的协议是相同的，协议的特点:

「**协**」字，代表的意思是必须有**两个以上的参与者**。例如三⽅协议⾥的参与者有三个：你、公司、学校三个；租房协议⾥的参与者有两个：你和房东。

「**议**」字，代表的意思是对参与者的⼀种 **⾏为约定和规范**。例如三⽅协议⾥规定试⽤期期限、毁约⾦等；租房协议⾥规定租期期限、每⽉租⾦⾦额、违约如何处理等。

针对 HTTP 协议，我们可以这么理解。

HTTP 是⼀个⽤在计算机世界⾥的协议。它使⽤计算机能够理解的语⾔确⽴了⼀种计算机之间交流通信的规范（**两个以上的参与者**），以及相关的各种控制和错误处理⽅式（**⾏为约定和规范**）。


#### 2. 「传输」
所谓的「传输」，很好理解，就是把⼀堆东⻄从 A 点搬到 B 点，或者从 B 点 搬到 A 点。
别轻视了这个简单的动作，它⾄少包含两项重要的信息。

HTTP 协议是⼀个**双向协议**。
我们在上⽹冲浪时，浏览器是请求⽅ A ，百度⽹站就是应答⽅ B。双⽅约定⽤ HTTP 协议来通信，于是浏览器把请求数据发送给⽹站，⽹站再把⼀些数据返回给浏览器，最后由浏览器渲染在屏幕，就可以看到图⽚、视频了。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201094110.png)

数据虽然是在 A 和 B 之间传输，但允许中间有**中转或接⼒**。

就好像第⼀排的同学想传递纸条给最后⼀排的同学，那么传递的过程中就需要经过好多个同学（中间⼈），这样的传输⽅式就从「A < --- > B」，变成了「A <-> N <-> M <-> B」。

⽽在 HTTP ⾥，需要中间⼈遵从 HTTP 协议，只要不打扰基本的数据传输，就可以添加任意额外的东⻄。

针对传输，我们可以进⼀步理解了 HTTP。

HTTP 是⼀个在计算机世界⾥专⻔⽤来在**两点之间传输数据**的约定和规范。

#### 3. 「超⽂本」
HTTP 传输的内容是「超⽂本」。

我们先来理解「⽂本」，在互联⽹早期的时候只是简单的字符⽂字，但现在「⽂本」的涵义已经可以扩展为图⽚、视频、压缩包等，在 HTTP 眼⾥这些都算作「⽂本」。

再来理解「超⽂本」，它就是超越了普通⽂本的⽂本，它是⽂字、图⽚、视频等的混合体，最关键有超链接，能从⼀个超⽂本跳转到另外⼀个超⽂本。

HTML 就是最常⻅的超⽂本了，它本身只是纯⽂字⽂件，但内部⽤很多标签定义了图⽚、视频等的链接，再经过浏览器的解释，呈现给我们的就是⼀个⽂字、有画⾯的⽹⻚了。

**HTTP 是⼀个在计算机世界⾥专⻔在「两点」之间「传输」⽂字、图⽚、⾳频、视频等「超⽂本」数据的「约定和规范」。**

### 2.3 HTTP 常⻅的状态码有哪些？
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201100340.png)

- 1xx 类状态码属于提示信息，是协议处理中的⼀种中间状态，实际⽤到的⽐较少。

- 2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。

「200 OK」是最常⻅的成功状态码，表示⼀切正常。如果是 **⾮ HEAD** 请求，服务器返回的响应头 都会有 body数据。

「204 No Content」也是常⻅的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。

「206 Partial Content」是应⽤于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，⽽是其中的⼀部分，也是服务器处理成功的状态。

- 3xx 类状态码表示客户端请求的资源发送了变动，需要客户端⽤新的 URL  新发送请求获取资源，也就是重定向。

「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改⽤新的 URL 再次访问。

「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要⽤另⼀个 URL 来访问。
301 和 302 都会在响应头⾥使⽤字段 **Location** ，指明后续要跳转的 URL，浏览器会⾃动重定向新的 URL。

「304 Not Modified」不具有跳转的含义，表示资源未修改， 重定向已存在的缓冲⽂件，也称缓存重定向，⽤于缓存控制。


- 4xx 类状态码表示客户端发送的报⽂有误，服务器⽆法处理，也就是错误码的含义。

「400 Bad Request」表示客户端请求的报⽂有错误，但只是个笼统的错误。

「403 Forbidden」表示服务器禁⽌访问资源，并不是客户端的请求出错。

「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以⽆法提供给客户端。

- 5xx 类状态码表示客户端请求报⽂正确，但是服务器处理时内部发⽣了错误，属于服务器端的错误码。

「500 Internal Server Error」与 400 类型，是个笼统通⽤的错误码，服务器发⽣了什么错误，我们并不知道。

「501 Not Implemented」表示客户端请求的功能还不⽀持，类似“即将开业，敬请期待”的意思。

「502 Bad Gateway」通常是服务器作为⽹关或代理时返回的错误码，表示服务器⾃身⼯作正常，访问后端服务器
发⽣了错误。

「503 Service Unavailable」表示服务器当前很忙，暂时⽆法响应服务器，类似“⽹络服务正忙，请稍后 试”的意
思。

### 2.4 http 常⻅字段有哪些？
- **Host字段** ：客户端发送请求时，⽤来指定服务器的域名。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201101323.png)

有了 Host 字段，就可以将请求发往「同⼀台」服务器上的不同⽹站。

- **Content-Length 字段** ：服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据⻓度。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201101944.png)

如上⾯则是告诉浏览器，本次服务器回应的数据⻓度是 1000 个字节，后⾯的字节就属于下⼀个回应了。

- **Connection 字段**：常⽤于客户端要求服务器使⽤ TCP 持久连接，以便其他请求复⽤。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201102142.png)

HTTP/1.1 版本的默认连接都是**持久连接**，但为了兼容⽼版本的 HTTP，需要指定 Connection ⾸部字段的值为
**keep-Alive** 。
⼀个可以复⽤的 TCP 连接就建⽴了，直到客户端或服务器主动关闭连接。但是，这不是标准字段。

- **Content-Type 字段**:⽤于服务器回应时，告诉客户端，本次数据是什么格式。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201102506.png)

上⾯的类型表明，发送的是⽹⻚，⽽且编码是UTF-8。

客户端请求的时候，可以使⽤ Accept 字段声明⾃⼰可以接受哪些数据格式。

Accept: * **/** *

上⾯代码中，客户端声明⾃⼰可以接受任何格式的数据。

- **Content-Encoding 字段** ：说明数据的压缩⽅法。表示服务器返回的数据使⽤了什么压缩格式

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201102902.png)

上⾯表示服务器返回的数据采⽤了 gzip ⽅式压缩，告知客户端需要⽤此⽅式解压。

客户端在请求时，⽤ Accept-Encoding 字段说明⾃⼰可以接受哪些压缩⽅法。

Accept-Encoding: gzip, deflate


### 2.5 说⼀下 GET 和 POST 的区别？
Get ⽅法的含义是请求从服务器获取资源，这个资源可以是静态的⽂本、⻚⾯、图⽚视频等。

⽐如，你打开我的⽂章，浏览器就会发送 GET 请求给服务器，服务器就会返回⽂章的所有⽂字及资源。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201103341.png)


⽽ POST ⽅法则是相反操作，它向 URI 指定的资源提交数据，数据就放在报⽂的 body ⾥。

⽐如，你在我⽂章底部，敲⼊了留⾔后点击「提交」（暗示你们留⾔），浏览器就会执⾏⼀次 POST 请求，把你的留⾔⽂字放进了报⽂ body ⾥，然后拼接好 POST 请求头，通过 TCP 协议发送给服务器。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201104454.png)

### 2.6 GET 和 POST ⽅法都是安全和幂等的吗？
先说明下安全和幂等的概念：
- 在 HTTP 协议⾥，所谓的「安全」是指请求⽅法不会「破坏」服务器上的资源。
- 所谓的「幂等」，意思是多次执⾏相同的操作，结果都是「相同」的。

那么很明显 GET ⽅法就是安全且幂等的，因为它是「只读」操作，⽆论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。

POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。

### 2.7  HTTP（1.1） 的优点有哪些，怎么体现的？
HTTP 最凸出的优点是「简单、灵活和易于扩展、应⽤⼴泛和跨平台」。

- 简单

HTTP 基本的报⽂格式就是 header + body ，头部信息也是 key-value 简单⽂本的形式，易于理解，降低了学习和使⽤的⻔槛。

- 灵活和易于扩展

HTTP协议⾥的各类请求⽅法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发⼈员⾃定义和扩充。

同时 HTTP 由于是⼯作在应⽤层（ OSI 第七层），则它下层可以随意变化。

HTTPS 也就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层，HTTP/3 甚⾄把 TCP 层换成了基于 UDP 的QUIC。

- 应⽤⼴泛和跨平台

互联⽹发展⾄今，HTTP 的应⽤范围⾮常的⼴泛，从台式机的浏览器到⼿机上的各种 APP，从看新闻、刷贴吧到购物、理财、吃鸡，HTTP 的应⽤⽚地开花，同时天然具有跨平台的优越性。

### 2.8  HTTP（1.1） 的缺点呢？

HTTP 协议⾥有优缺点⼀体的双刃剑，分别是「⽆状态、明⽂传输」，同时还有⼀⼤缺点「不安全」。

#### 1. ⽆状态双刃剑
⽆状态的好处，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存⽤来对外提供服务。

⽆状态的坏处，既然服务器没有记忆能⼒，它在完成有关联性的操作时会⾮常麻烦。

例如登录->添加购物⻋->下单->结算->⽀付，这系列操作都要知道⽤户的身份才⾏。但服务器不知道这些请求是有关联的，每次都要问⼀遍身份信息。

对于⽆状态的问题，解法⽅案有很多种，其中⽐较简单的⽅式⽤ Cookie 技术。

Cookie 通过在请求和响应报⽂中写⼊ Cookie 信息来控制客户端的状态。

相当于，在客户端第⼀次请求后，服务器会下发⼀个装有客户信息的「⼩贴纸」，后续客户端请求服务器的时候，带上「⼩贴纸」，服务器就能认得了了.

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201111802.png)

#### 2. 明⽂传输双刃剑
明⽂意味着在传输过程中的信息，是可⽅便阅读的，通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接⾁眼查看，为我们调试⼯作带了极⼤的便利性。

但是这正是这样，HTTP 的所有信息都暴露在了光天化⽇下，相当于信息裸奔。在传输的漫⻓的过程中，信息的内
容都毫⽆隐私可⾔，很容易就能被窃取，如果⾥⾯有你的账号密码信息，**那你号没了**。


#### 3. 不安全
HTTP ⽐较严重的缺点就是不安全：
- 通信使⽤明⽂（不加密），内容可能会被窃听。⽐如，账号信息容易泄漏，那你号没了。
- 不验证通信⽅的身份，因此有可能遭遇伪装。⽐如，访问假的淘宝、拼多多，那你钱没了。
- ⽆法证明报⽂的完整性，所以有可能已遭篡改。⽐如，⽹⻚上植⼊垃圾⼴告，视觉污染，眼没了。

HTTP 的安全问题，可以⽤ HTTPS 的⽅式解决，也就是通过引⼊ SSL/TLS 层，使得在安全上达到了极致。

### 2.9 那你再说下 HTTP/1.1 的性能如何？
HTTP 协议是基于 **TCP/IP**，并且使⽤了 **「请求 - 应答」** 的通信模式，所以性能的关键就在这两点⾥。

#### 1. ⻓连接

早期 HTTP/1.0 性能上的⼀个很⼤的问题，那就是每发起⼀个请求，都要新建⼀次 TCP 连接（三次握⼿），⽽且是串⾏请求，做了⽆谓的 TCP 连接建⽴和断开，增加了通信开销。

为了解决上述 TCP 连接问题，HTTP/1.1 提出了⻓连接的通信⽅式，也叫持久连接。这种⽅式的好处在于减少了TCP 连接的重复建⽴和断开所造成的额外开销，减轻了服务器端的负载。

持久连接的特点是，只要任意⼀端没有明确提出断开连接，则保持 TCP 连接状态。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201112821.png)

#### 2. 管道⽹络传输
HTTP/1.1 采⽤了⻓连接的⽅式，这使得管道（pipeline）⽹络传输成为了可能。

即可在同⼀个 TCP 连接⾥⾯，客户端可以发起多个请求，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以**减少整体的响应时间**。

举例来说，客户端需要请求两个资源。以前的做法是，在同⼀个TCP连接⾥⾯，先发送 A 请求，然后等待服务器做出回应，收到后再发出 B 请求。管道机制则是允许浏览器同时发出 A 请求和 B 请求。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201113357.png)

但是服务器还是按照顺序，先回应 A 请求，完成后再回应 B 请求。要是前⾯的回应特别慢，后⾯就会有许多请求排队等着。这称为「队头堵塞」。


#### 3. 队头阻塞
「请求 - 应答」的模式加剧了 HTTP 的性能问题。
因为当顺序发送的请求序列中的⼀个请求因为某种原因被阻塞时，在后⾯排队的所有请求也⼀同被阻塞了，会招致客户端⼀直请求不到数据，这也就是「队头阻塞」。好⽐上班的路上塞⻋。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201113703.png)

总之 HTTP/1.1 的性能⼀般般，后续的 HTTP/2 和 HTTP/3 就是在优化 HTTP 的性能。


### 2.10 HTTP 与 HTTPS 有哪些区别？
1. HTTP 是超⽂本传输协议，信息是明⽂传输，存在安全⻛险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在TCP 和 HTTP ⽹络层之间加⼊了 SSL/TLS 安全协议，使得报⽂能够加密传输。

2. HTTP 连接建⽴相对简单， TCP 三次握⼿之后便可进⾏ HTTP 的报⽂传输。⽽ HTTPS 在 TCP 三次握⼿之后，还需进⾏ SSL/TLS 的握⼿过程，才可进⼊加密报⽂传输。

3. HTTP 的端⼝号是 80，HTTPS 的端⼝号是 443。

4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

### 2.11 HTTPS 解决了 HTTP 的哪些问题？
HTTP 由于是明⽂传输，所以安全上存在以下三个⻛险：

- 窃听⻛险，⽐如通信链路上可以获取通信内容，⽤户号容易没。
- 篡改⻛险，⽐如强制植⼊垃圾⼴告，视觉污染，⽤户眼容易瞎。
- 冒充⻛险，⽐如冒充淘宝⽹站，⽤户钱容易没。

HTTPS 在 HTTP 与 TCP 层之间加⼊了 SSL/TLS 协议，可以很好的解决了上述的⻛险：
- 信息加密：交互信息⽆法被窃取，但你的号会因为「⾃身忘记」账号⽽没。
- 校验机制：⽆法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾⼴告。
- 身份证书：证明淘宝是真的淘宝⽹，但你的钱还是会因为「剁⼿」⽽没。


### 2.12 HTTPS 具体是如何解决上⾯的三个⻛险的？
1、**混合加密**的⽅式实现信息的机密性，解决了窃听的⻛险。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201115157.png)

HTTPS 采⽤的是对称加密和⾮对称加密结合的「混合加密」⽅式：
- 在通信建⽴前采⽤⾮对称加密的⽅式交换「会话秘钥」，后续就不再使⽤⾮对称加密。
- 在通信过程中全部使⽤对称加密的「会话秘钥」的⽅式加密明⽂数据。

采⽤「混合加密」的⽅式的原因：

- 对称加密只使⽤⼀个密钥，运算速度快，密钥必须保密，⽆法做到安全的密钥交换。
- ⾮对称加密使⽤两个密钥：公钥和私钥，公钥可以任意分发⽽私钥保密，解决了密钥交换问题但速度慢。

2、**摘要算法**的⽅式来实现完整性，它能够为数据⽣成独⼀⽆⼆的「指纹」，指纹⽤于校验数据的完整性，解决了篡改的⻛险。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201115953.png)

客户端在发送明⽂之前会通过摘要算法算出明⽂的「指纹」，发送的时候把「指纹 + 明⽂」⼀同加密成密⽂后，发送给服务器，服务器解密后，⽤相同的摘要算法算出发送过来的明⽂，通过⽐较客户端携带的「指纹」和当前算出的「指纹」做⽐较，若「指纹」相同，说明数据是完整的。

3、将服务器公钥放⼊到**数字证书**中，解决了冒充的⻛险。

客户端先向服务器端索要公钥，然后⽤公钥加密信息，服务器收到密⽂后，⽤⾃⼰的私钥解密。

这就存在些问题，如何保证公钥不被篡改和信任度？

所以这⾥就需要借助第三⽅权威机构 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201121704.png)


### 2.13 HTTPS 是如何建⽴连接的？其间交互了什么？

SSL/TLS 协议基本流程：

客户端向服务器索要并验证服务器的公钥。

双⽅协商⽣产「会话秘钥」。

双⽅采⽤「会话秘钥」进⾏加密通信。

前两步也就是 SSL/TLS 的建⽴过程，也就是握⼿阶段。

SSL/TLS 的「握⼿阶段」涉及四次通信，可⻅下图：
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201122616.png)
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201122635.png)
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201122641.png)
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201122649.png)
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201122652.png)

SSL/TLS 协议建⽴的详细流程：
#### 1. ClientHello

⾸先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。

在这⼀步，客户端主要向服务器发送以下信息：

（1）客户端⽀持的 SSL/TLS 协议版本，如 TLS 1.2 版本。

（2）客户端⽣产的随机数（ Client Random ），后⾯⽤于⽣产「会话秘钥」。

（3）客户端⽀持的密码套件列表，如 RSA 加密算法。

#### 2. SeverHello
服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello 。服务器回应的内容有如下内容：

（1）确认 SSL/ TLS 协议版本，如果浏览器不⽀持，则关闭加密通信。

（2）服务器⽣产的随机数（ Server Random ），后⾯⽤于⽣产「会话秘钥」。

（3）确认的密码套件列表，如 RSA 加密算法。

（4）服务器的数字证书。

#### 3.客户端回应
客户端收到服务器的回应之后，⾸先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。

如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使⽤它加密报⽂，向服务器发送如下信息：

（1）⼀个随机数（ pre-master key ）。该随机数会被服务器公钥加密。

（2）加密通信算法改变通知，表示随后的信息都将⽤「会话秘钥」加密通信。

（3）客户端握⼿结束通知，表示客户端的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘要，⽤来供服务端校验。

上⾯第⼀项的随机数是整个握⼿阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着就⽤双⽅协商的加密算法，各⾃⽣成本次通信的「会话秘钥」。

#### 4. 服务器的最后回应
服务器收到客户端的第三个随机数（ pre-master key ）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。然后，向客户端发⽣最后的信息：

（1）加密通信算法改变通知，表示随后的信息都将⽤「会话秘钥」加密通信。

（2）服务器握⼿结束通知，表示服务器的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘要，⽤来供客户端校验。

⾄此，整个 SSL/TLS 的握⼿阶段全部结束。接下来，客户端与服务器进⼊加密通信，就完全是使⽤普通的 HTTP协议，只不过⽤「会话秘钥」加密内容。

### 2.14 说说 HTTP/1.1 相⽐ HTTP/1.0 提⾼了什么性能？
HTTP/1.1 相⽐ HTTP/1.0 性能上的改进：
- 使⽤ TCP ⻓连接的⽅式改善了 HTTP/1.0 短连接造成的性能开销。
- ⽀持管道（pipeline）⽹络传输，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以减少整体的响应时间。

但 HTTP/1.1 还是有性能瓶颈：

- 请求 / 响应头部（Header）未经压缩就发送，⾸部信息越多延迟越⼤。只能压缩 Body 的部分；

- 发送冗⻓的⾸部。每次互相发送相同的⾸部造成的浪费较多；

- 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端⼀直请求不到数据，也就是队头阻塞；

- 没有请求优先级控制；

- 请求只能从客户端开始，服务器只能被动响应。

### 2.15 那上⾯的 HTTP/1.1 的性能瓶颈，HTTP/2 做了什么优化？
HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。

那 HTTP/2 相⽐ HTTP/1.1 性能上的改进：
#### 1. 头部压缩
HTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是⼀样的或是相似的，那么，协议会帮你消除重复的部分。

这就是所谓的 HPACK 算法：在客户端和服务器同时维护⼀张头信息表，所有字段都会存⼊这个表，⽣成⼀个索引号，以后就不发送同样字段了，只发送索引号，这样就提⾼速度了。

#### 2. ⼆进制格式
HTTP/2 不再像 HTTP/1.1 ⾥的纯⽂本形式的报⽂，⽽是全⾯采⽤了⼆进制格式，头信息和数据体都是⼆进制，并且统称为帧（frame）：头信息帧和数据帧。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201124621.png)

这样虽然对⼈不友好，但是对计算机⾮常友好，因为计算机只懂⼆进制，那么收到报⽂后，⽆需再将明⽂的报⽂转成⼆进制，⽽是直接解析⼆进制报⽂，这**增加了数据传输的效率**。

#### 3. 数据流
HTTP/2 的数据包不是按顺序发送的，同⼀个连接⾥⾯连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。

每个请求或回应的所有数据包，称为⼀个数据流（ Stream ）。每个数据流都标记着⼀个独⼀⽆⼆的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数

客户端还可以**指定数据流的优先级**。优先级⾼的请求，服务器就先响应该请求。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201125028.png)

#### 4. 多路复⽤
HTTP/2 是可以在⼀个连接中并发多个请求或回应，⽽不⽤按照顺序⼀⼀对应。

移除了 HTTP/1.1 中的串⾏请求，不需要排队等待，也就不会再出现「队头阻塞」问题，**降低了延迟，⼤幅度提⾼了连接的利⽤率**。

举例来说，在⼀个 TCP 连接⾥，服务器收到了客户端 A 和 B 的两个请求，如果发现 A 处理过程⾮常耗时，于是就回应 A 请求已经处理好的部分，接着回应 B 请求，完成后，再回应 A 请求剩下的部分。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201125349.png)

#### 5. 服务器推送
HTTP/2 还在⼀定程度上改善了传统的「请求 - 应答」⼯作模式，服务不再是被动地响应，也可以主动向客户端发送消息。

举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会⽤到的 JS、CSS ⽂件等静态资源主动发给客户端，减少延时的等待，也就是服务器推送（Server Push，也叫 Cache Push）。

### 2.16 HTTP/2 有哪些缺陷？HTTP/3 做了哪些优化？
HTTP/2 主要的问题在于，多个 HTTP 请求在复⽤⼀个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。所以⼀旦发⽣了丢包现象，就会触发 TCP 的重传机制，这样在⼀个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。

- HTTP/1.1 中的管道（ pipeline）传输中如果有⼀个请求阻塞了，那么队列后请求也统统被阻塞住了
- HTTP/2 多个请求复⽤⼀个TCP连接，⼀旦发⽣丢包，就会阻塞住所有的 HTTP 请求。

这都是基于 TCP 传输层的问题，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201130344.png)


UDP 发⽣是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的⼀个丢包全部 传问题。

⼤家都知道 UDP 是不可靠传输的，但基于 UDP 的 **QUIC** 协议 可以实现类似 TCP 的可靠性传输。
- QUIC 有⾃⼰的⼀套机制可以保证传输的可靠性的。当某个流发⽣丢包时，只会阻塞这个流，其他流不会受到影响。

- TLS3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack 。

- HTTPS 要建⽴⼀个连接，要花费 6 次交互，先是建⽴三次握⼿，然后是 TLS/1.3 的三次握⼿。QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数。

### 2.17 https和http相⽐，就是传输的内容多了对称加密，可以这么理解吗？

1. 建⽴连接时候：https ⽐ http多了 TLS 的握⼿过程；
2. 传输内容的时候：https 会把数据进⾏加密，通常是对称加密数据；

### 2.18 为啥 ssl 的握⼿是 4 次？
SSL/TLS 1.2 需要 4 握⼿，需要 2 个 RTT 的时延.

另外， SSL/TLS 1.3 优化了过程，只需要 1 个 RTT 往返时延，也就是只需要 3 次握⼿：

### 2.19 HTTP/1.1如何优化？
我想你第⼀时间想到的是，使⽤ KeepAlive 将 HTTP/1.1 从短连接改成⻓链接。

这个确实是⼀个优化的⼿段，它是从底层的传输层这⼀⽅向⼊⼿的，通过减少 TCP 连接建⽴和断开的次数，来减少了⽹络传输的延迟，从⽽提⾼ HTTP/1.1 协议的传输效率。

但其实还可以从其他⽅向来优化 HTTP/1.1 协议，⽐如有如下 3 种优化思路：
- 尽量避免发送 HTTP 请求；
- 在需要发送 HTTP 请求时，考虑如何减少请求次数；
- 减少服务器的 HTTP 响应的数据⼤⼩；

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201131938.png)


#### 1、如何避免发送 HTTP 请求？
- 对于⼀些具有重复性的 HTTP 请求，⽐如每次请求得到的数据都⼀样的，我们可以把这对「请求-响应」的数据都**缓存在本地**，那么下次就直接读取本地的数据，不必在通过⽹络获取服务器的响应了。

- 所以，避免发送 HTTP 请求的⽅法就是通过**缓存技术**，HTTP 设计者早在之前就考虑到了这点，因此 HTTP 协议的头部有不少是针对缓存的字段。


那缓存是如何做到的呢？

客户端会把第⼀次请求以及响应的数据保存在本地磁盘上，其中将请求的 URL 作为 key，⽽响应作为 value，两者形成映射关系。

这样当后续发起相同的请求时，就可以先在本地磁盘上通过 key 查到对应的 value，也就是响应，如果找到了，就直接从本地读取该响应。毋庸置疑，读取本次磁盘的速度肯定⽐⽹络请求快得多，如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201132559.png)

聪明的你可能想到了，万⼀缓存的响应不是最新的，⽽客户端并不知情，那么该怎么办呢？

放⼼，这个问题 HTTP 设计者早已考虑到。

所以，服务器在发送 HTTP 响应时，会估算⼀个过期的时间，并把这个信息放到响应头部中，这样客户端在查看响应头部的信息时，⼀旦发现缓存的响应是过期的，则就会重新发送⽹络请求。

如果客户端从第⼀次请求得到的响应头部中发现该响应过期了，客户端重新发送请求，假设服务器上的资源并没有变更，还是⽼样⼦，那么你觉得还要在服务器的响应带上这个资源吗？

很显然不带的话，可以提⾼ HTTP 协议的性能，那具体如何做到呢？

只需要客户端在重新发送请求时，在请求的 Etag 头部带上第⼀次请求的响应头部中的摘要，这个摘要是唯⼀标识响应的资源，当服务器收到请求后，会将本地资源的摘要与请求中的摘要做个⽐较。

如果不同，那么说明客户端的缓存已经没有价值，服务器在响应中带上最新的资源。

如果相同，说明客户端的缓存还是可以继续使⽤的，那么服务器仅返回不含有包体的 304 Not Modified 响应，告诉客户端仍然有效，这样就可以减少响应资源在⽹络中传输的延时，如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201133233.png)

缓存真的是性能优化的⼀把万能钥匙，⼩到 CPU Cache、Page Cache、Redis Cache，⼤到 HTTP 协议的缓存。

#### 2、如何减少 HTTP 请求次数？
- 减少重定向请求次数；
- 合并请求；
- 延迟发送请求；

##### 减少重定向请求次数
我们先来看看什么是重定向请求？

服务器上的⼀个资源可能由于迁移、维护等原因从 url1 移⾄ url2 后，⽽客户端不知情，它还是继续请求 url1，这
时服务器不能粗暴地返回错误，⽽是通过 302 响应码和 Location 头部，告诉客户端该资源已经迁移⾄ url2
了，于是客户端需要再发送 url2 请求以获得服务器的资源。

那么，如果重定向请求越多，那么客户端就要多次发起 HTTP 请求，每⼀次的 HTTP 请求都得经过⽹络，这⽆疑会
越降低⽹络性能。

另外，服务端这⼀⽅往往不只有⼀台服务器，⽐如源服务器上⼀级是代理服务器，然后代理服务器才与客户端通
信，这时客户端重定向就会导致客户端与代理服务器之间需要 2 次消息传递，如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201141937.png)

如果重定向的⼯作交由代理服务器完成，就能减少 HTTP 请求次数了:
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201143932.png)

⽽且当代理服务器知晓了重定向规则后，可以进⼀步减少消息传递次数，如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201144221.png)


除了 302 重定向响应码，还有其他⼀些重定向的响应码，你可以从下图看到：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201144524.png)

其中， 301 和 308 响应码是告诉客户端可以将重定向响应缓存到本地磁盘，之后客户端就⾃动⽤ url2 替代 url1
访问服务器的资源。

##### 合并请求
如果把多个访问⼩⽂件的请求合并成⼀个⼤的请求，虽然传输的总资源还是⼀样，但是减少请求，也就意味着**减少了重复发送的HTTP头部 。**

另外由于 HTTP/1.1 是请求响应模型，如果第⼀个发送的请求，未收到对应的响应，那么后续的请求就不会发送，
于是为了防⽌单个请求的阻塞，所以⼀般浏览器会同时发起 5-6 个请求，每⼀个请求都是不同的 TCP 连接，那么
如果合并了请求，也就会减少 **TCP 连接的数量，因⽽省去了 TCP 握⼿和慢启动过程耗费的时间**。

接下来，具体看看合并请求的⼏种⽅式。

有的⽹⻚会含有很多⼩图⽚、⼩图标，有多少个⼩图⽚，客户端就要发起多少次请求。那么对于这些⼩图⽚，我们
可以考虑使⽤ CSS Image Sprites 技术把它们合成⼀个⼤图⽚，这样浏览器就可以⽤⼀次请求获得⼀个⼤图⽚，
然后再根据 CSS 数据把⼤图⽚切割成多张⼩图⽚。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201145524.png)


这种⽅式就是通过将多个⼩图⽚合并成⼀个⼤图⽚来减少 HTTP 请求的次数，从⽽减少⽹络的开销。

除了将⼩图⽚合并成⼤图⽚的⽅式，还有服务端使⽤ webpack 等打包⼯具将 js、css 等资源合并打包成⼤⽂
件，也是能达到类似的效果。

另外，还可以将图⽚的⼆进制数据⽤ base64 编码后，以 URL 的形式潜⼊到 HTML ⽂件，跟随 HTML ⽂件⼀并
发送.
```cpp
<image
 src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPoAAAFKCAIAAAC7M9WrAAAACXBIWXMAA ...
/>
```

这样客户端收到 HTML 后，就可以直接解码出数据，然后直接显示图⽚，就不⽤再发起图⽚相关的请求，这样便减
少了请求的次数。



可以看到，**合并请求的⽅式就是合并资源，以⼀个⼤资源的请求替换多个⼩资源的请求。**

但是这样的合并请求会带来新的问题，当⼤资源中的某⼀个⼩资源发⽣变化后，客户端必须重新下载整个完整的⼤
资源⽂件，这显然带来了额外的⽹络消耗。

##### 延迟发送请求
不要⼀⼝⽓吃成⼤胖⼦，⼀般 HTML ⾥会含有很多 HTTP 的 URL，当前不需要的资源，我们没必要也获取过来，
于是可以通过「按需获取」的⽅式，来减少第⼀时间的 HTTP 请求次数。

请求⽹⻚的时候，没必要把全部资源都获取到，⽽是只获取当前⽤户所看到的⻚⾯资源，当⽤户向下滑动⻚⾯的时
候，再向服务器获取接下来的资源，这样就达到了延迟发送请求的效果。


#### 3、如何减少 HTTP 请求次数？
对于 HTTP 的请求和响应，通常 HTTP 的响应的数据⼤⼩会⽐较⼤，也就是服务器返回的资源会⽐较⼤。

于是，我们可以考虑对响应的资源进⾏**压缩**，这样就可以减少响应的数据⼤⼩，从⽽提⾼⽹络传输的效率。

压缩的⽅式⼀般分为 2 种，分别是：

- ⽆损压缩；

⽆损压缩是指资源经过压缩后，信息不被破坏，还能完全恢复到压缩前的原样，适合⽤在⽂本⽂件、程序可执⾏⽂
件、程序源代码。

⾸先，我们针对代码的语法规则进⾏压缩，因为通常代码⽂件都有很多换⾏符或者空格，这些是为了帮助程序员更
好的阅读，但是机器执⾏时并不要这些符，把这些多余的符号给去除掉。

接下来，就是⽆损压缩了，需要对原始资源建⽴统计模型，利⽤这个统计模型，将常出现的数据⽤较短的⼆进制⽐
特序列表示，将不常出现的数据⽤较⻓的⼆进制⽐特序列表示，⽣成⼆进制⽐特序列⼀般是「霍夫曼编码」算法。

gzip 就是⽐较常⻅的⽆损压缩。客户端⽀持的压缩算法，会在 HTTP 请求中通过头部中的 Accept-Encoding 字
段告诉服务器：

Accept-Encoding: gzip, deflate, br

服务器收到后，会从中选择⼀个服务器⽀持的或者合适的压缩算法，然后使⽤此压缩算法对响应资源进⾏压缩，最
后通过响应头部中的 content-encoding 字段告诉客户端该资源使⽤的压缩算法。
gzip 的压缩效率相⽐ Google 推出的 Brotli 算法还是差点意思，也就是上⽂中的 br，所以如果可以，服务器应该选
择压缩效率更⾼的 br 压缩算法。

content-encoding: gzip

gzip 的压缩效率相⽐ Google 推出的 Brotli 算法还是差点意思，也就是上⽂中的 br，所以如果可以，服务器应该选
择压缩效率更⾼的 br 压缩算法。

- 有损压缩；

与⽆损压缩相对的就是有损压缩，经过此⽅法压缩，解压的数据会与原始数据不同但是⾮常接近。


有损压缩主要将次要的数据舍弃，牺牲⼀些质 来减少数据 、提⾼压缩⽐，这种⽅法经常⽤于压缩多媒体数据，
⽐如⾳频、视频、图⽚。


可以通过 HTTP 请求头部中的 Accept 字段⾥的「 q 质 因⼦」，告诉服务器期望的资源质量。
Accept: audio/*; q=0.2, audio/basic

关于图⽚的压缩，⽬前压缩⽐较⾼的是 Google 推出的 WebP 格式，相同图⽚质 下，WebP 格式的图⽚⼤⼩都⽐ Png 格式的图⽚⼩，所以对于⼤ 图⽚的⽹站，可以考虑使⽤ WebP 格式的图⽚，这将⼤幅度提升⽹络传输的性能。


关于⾳视频的压缩，⾳视频主要是动态的，每个帧都有时序的关系，通常时间连续的帧之间的变化是很⼩的。

⽐如，⼀个在看书的视频，画⾯通常只有⼈物的⼿和书桌上的书是会有变化的，⽽其他地⽅通常都是静态的，于是
只需要在⼀个静态的关键帧，使⽤**增量数据**来表达后续的帧，这样便减少了很多数据，提⾼了⽹络传输的性能。对
于视频常⻅的编码格式有 H264、H265 等，⾳频常⻅的编码格式有 AAC、AC3。


### 总结
这次主要从 3 个⽅⾯介绍了优化 HTTP/1.1 协议的思路。

第⼀个思路是，通过缓存技术来避免发送 HTTP 请求。客户端收到第⼀个请求的响应后，可以将其缓存在本地磁
盘，下次请求的时候，如果缓存没过期，就直接读取本地缓存的响应数据。如果缓存过期，客户端发送请求的时候
带上响应数据的摘要，服务器⽐对后发现资源没有变化，就发出不带包体的 304 响应，告诉客户端缓存的响应仍然
有效。

第⼆个思路是，减少 HTTP 请求的次数，有以下的⽅法：

1. 将原本由客户端处理的 定向请求，交给代理服务器处理，这样可以减少 定向请求的次数；

2. 将多个⼩资源合并成⼀个⼤资源再传输，能够减少 HTTP 请求次数以及 头部的 复传输，再来减少 TCP 连
接数 ，进⽽省去 TCP 握⼿和慢启动的⽹络消耗；

3. 按需访问资源，只访问当前⽤户看得到/⽤得到的资源，当客户往下滑动，再访问接下来的资源，以此达到延迟请求，也就减少了同⼀时间的 HTTP 请求次数。

第三思路是，通过压缩响应资源，降低传输资源的⼤⼩，从⽽提⾼传输效率，所以应当选择更优秀的压缩算法。

### 2.20 HTTPS RSA 握⼿解析
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201152031.png)


#### TLS 握⼿过程
HTTP 由于是明⽂传输，所谓的明⽂，就是说客户端与服务端通信的信息都是⾁眼可⻅的，随意使⽤⼀个抓包⼯具都可以截获通信的内容。

所以安全上存在以下三个⻛险：
- 窃听⻛险，⽐如通信链路上可以获取通信内容，⽤户号容易没。

- 篡改⻛险，⽐如强制植⼊垃圾⼴告，视觉污染，⽤户眼容易瞎。

- 冒充⻛险，⽐如冒充淘宝⽹站，⽤户钱容易没。

HTTPS 在 HTTP 与 TCP 层之间加⼊了 TLS 协议，来解决上述的⻛险。

TLS 协议是如何解决 HTTP 的⻛险的呢？

- 信息加密： HTTP 交互信息是被加密的，第三⽅就⽆法被窃取；

- 校验机制：校验信息传输过程中是否有被第三⽅篡改过，如果被篡改过，则会有警告提示；

- 身份证书：证明淘宝是真的淘宝⽹；

可⻅，有了 TLS 协议，能保证 HTTP 通信是安全的了，那么在进⾏ HTTP 通信前，需要先进⾏ TLS 握⼿。TLS 的握⼿过程，如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/微信图片_20211201152455.png)

上图简要概述来 TLS 的握⼿过程，其中每⼀个「框」都是⼀个记录（record），记录是 TLS 收发数据的基本单位，类似于 TCP ⾥的 segment。

多个记录可以组合成⼀个 TCP 包发送，所以通常经过 **「四个消息」就可以完成TLS 握⼿，也就是需要2个RTT 的时延**，然后就可以在安全的通信环境⾥发送 HTTP 报⽂，实现 HTTPS 协议。

所以可以发现，HTTPS 是应⽤层协议，需要先完成 TCP 连接建⽴，然后⾛ TLS 握⼿过程后，才能建⽴通信安全的连接。


事实上，不同的密钥交换算法，TLS 的握⼿过程可能会有⼀些区别。

这⾥先简单介绍下密钥交换算法，因为考虑到性能的问题，所以双⽅在加密应⽤信息时使⽤的是对称加密密钥，⽽对称加密密钥是不能被泄漏的，为了保证对称加密密钥的安全性，所以使⽤⾮对称加密的⽅式来保护对称加密密钥的协商，这个⼯作就是密钥交换算法负责的。

接下来，我们就以最简单的 RSA 密钥交换算法，来看看它的 TLS 握⼿过程。

### 2.21 RSA 握⼿过程

传统的 TLS 握⼿基本都是使⽤ RSA 算法来实现密钥交换的，在将 TLS 证书部署服务端时，证书⽂件中包含⼀对公私钥，其中公钥会在 TLS 握⼿阶段传递给客户端，私钥则⼀直留在服务端，⼀定要确保私钥不能被窃取。

在 RSA 密钥协商算法中，客户端会⽣成随机密钥，并使⽤服务端的公钥加密后再传给服务端。根据⾮对称加密算法，公钥加密的消息仅能通过私钥解密，这样服务端解密后，双⽅就得到了相同的密钥，再⽤它加密应⽤消息。


⽤ Wireshark ⼯具抓了⽤ RSA 密钥交换的 TLS 握⼿过程，可以从下⾯看到，⼀共经历了四次握⼿：
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202084146.png)


对应 Wireshark 的抓包，我也画了⼀幅图，你可以从下图很清晰地看到该过程：
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202084146.png)


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202091728.png)



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202084414.png)



那么，接下来针对每⼀个 TLS 握⼿做进⼀步的介绍。

#### TLS 第⼀次握⼿
客户端⾸先会发⼀个「Client Hello」消息，字⾯意思我们也能理解到，这是跟服务器「打招呼」。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202093002.png)


消息⾥⾯有客户端使⽤的 TLS 版本号、⽀持的密码套件列表，以及⽣成的随机数（Client Random），这个**随机数**会被服务端保留，它是 **⽣成对称加密密钥的材料之⼀。**


#### TLS 第⼆次握⼿
当服务端收到客户端的「Client Hello」消息后，会确认 TLS 版本号是否⽀持，和从密码套件列表中选择⼀个密码套件，以及⽣成**随机数（Server Random）。**


接着，返回「Server Hello」消息，消息⾥⾯有服务器确认的 TLS 版本号，也给出了随机数（Server Random），然后从客户端的密码套件列表选择了⼀个合适的密码套件。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202093914.png)


可以看到，服务端选择的密码套件是 “Cipher Suite: TLS_RSA_WITH_AES_128_GCM_SHA256”。

这个密码套件看起来真让⼈头晕，好⼀⼤串，但是其实它是有固定格式和规范的。基本的形式是 **「密钥交换算法 +签名算法 + 对称加密算法 + 摘要算法」**， ⼀般 WITH 单词前⾯有两个单词，第⼀个单词是约定密钥交换的算法，第⼆个单词是约定证书的验证算法。⽐如刚才的密码套件的意思就是：

- 由于 WITH 单词只有⼀个 RSA，则说明握⼿时密钥交换算法和签名算法都是使⽤ RSA；
- 握⼿后的通信使⽤ AES 对称算法，密钥⻓度 128 位，分组模式是 GCM；
- 摘要算法 SHA384 ⽤于消息认证和产⽣随机数；


就前⾯这两个客户端和服务端相互「打招呼」的过程，客户端和服务端就已确认了 TLS 版本和使⽤的密码套件，⽽且你可能发现客户端和服务端都会各⾃⽣成⼀个随机数，并且还会把随机数传递给对⽅。

那这个随机数有啥⽤呢？其实这两个随机数是后续作为⽣成「会话密钥」的条件，所谓的会话密钥就是数据传输时，所使⽤的对称加密密钥。

然后，服务端为了证明⾃⼰的身份，会发送「Server Certificate」给客户端，这个消息⾥含有数字证书。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202094918.png)

随后，服务端发了「Server Hello Done」消息，⽬的是告诉客户端，我已经把该给你的东⻄都给你了，本次打招呼完毕。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202095144.png)


##### 客户端验证证书
在这⾥刹个⻋，客户端拿到了服务端的数字证书后，要怎么校验该数字证书是真实有效的呢？

###### 数字证书和 CA 机构
在说校验数字证书是否可信的过程前，我们先来看看数字证书是什么，⼀个数字证书通常包含了：
- 公钥；
- 持有者信息；
- 证书认证机构（CA）的信息；
- CA 对这份⽂件的数字签名及使⽤的算法；
- 证书有效期；
- 还有⼀些其他额外信息；


那数字证书的作⽤，是⽤来认证公钥持有者的身份，以防⽌第三⽅进⾏冒充。说简单些，证书就是⽤来告诉客户端，该服务端是否是合法的，因为只有证书合法，才代表服务端身份是可信的。

我们⽤证书来认证公钥持有者的身份（服务端的身份），那证书⼜是怎么来的？⼜该怎么认证证书呢？

为了让服务端的公钥被⼤家信任，服务端的证书都是由 CA （Certificate Authority，证书认证机构）签名的，CA就是⽹络世界⾥的公安局、公证中⼼，具有极⾼的可信度，所以由它来给各个公钥签名，信任的⼀⽅签发的证书，那必然证书也是被信任的。

之所以要签名，是因为签名的作⽤可以避免中间⼈在获取证书时对证书内容的篡改。

###### 数字证书签发和验证流程

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202095855.png)


CA 签发证书的过程，如上图左边部分：

- ⾸先 CA 会把持有者的公钥、⽤途、颁发者、有效时间等信息打成⼀个包，然后对这些信息进⾏ Hash 计算，得到⼀个 Hash 值；

- 然后 CA 会使⽤⾃⼰的私钥将该 Hash 值加密，⽣成 Certificate Signature，也就是 CA 对证书做了签名；

- 最后将 Certificate Signature 添加在⽂件证书上，形成数字证书；

客户端校验服务端的数字证书的过程，如上图右边部分：

- ⾸先客户端会使⽤同样的 Hash 算法获取该证书的 Hash 值 H1；

- 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使⽤ CA 的公钥解密 CertificateSignature 内容，得到⼀个 Hash 值 H2 ；

- 最后⽐较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。

###### 证书链
但事实上，证书的验证过程中还存在⼀个证书信任链的问题，因为我们向 CA 申请的证书⼀般不是根证书签发的，⽽是由中间证书签发的，⽐如百度的证书，从下图你可以看到，证书的层级有三级：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202100730.png)


对于这种三级层级关系的证书的验证过程如下：

- 客户端收到 baidu.com 的证书后，发现这个证书的签发者不是根证书，就⽆法根据本地已有的根证书中的公钥去验证 baidu.com 证书是否可信。于是，客户端根据 baidu.com 证书中的签发者，找到该证书的颁发机构是 “GlobalSign Organization Validation CA - SHA256 - G2”，然后向 CA 请求该中间证书。

- 请求到证书后发现 “GlobalSign Organization Validation CA - SHA256 - G2” 证书是由 “GlobalSign Root CA”签发的，由于 “GlobalSign Root CA” 没有再上级签发机构，说明它是根证书，也就是⾃签证书。应⽤软件会检查此证书有否已预载于根证书清单上，如果有，则可以利⽤根证书中的公钥去验证 “GlobalSignOrganization Validation CA - SHA256 - G2” 证书，如果发现验证通过，就认为该中间证书是可信的。

- “GlobalSign Organization Validation CA - SHA256 - G2” 证书被信任后，可以使⽤ “GlobalSign OrganizationValidation CA - SHA256 - G2” 证书中的公钥去验证 baidu.com 证书的可信性，如果验证通过，就可以信任baidu.com 证书。


在这四个步骤中，最开始客户端只信任根证书 GlobalSign Root CA 证书的，然后 “GlobalSign Root CA” 证书信任“GlobalSign Organization Validation CA - SHA256 - G2” 证书，⽽ “GlobalSign Organization Validation CA -SHA256 - G2” 证书⼜信任 baidu.com 证书，于是客户端也信任 baidu.com 证书。


总括来说，由于⽤户信任 GlobalSign，所以由 GlobalSign 所担保的 baidu.com 可以被信任，另外由于⽤户信任操作系统或浏览器的软件商，所以由软件商预载了根证书的 GlobalSign 都可被信任。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202101431.png)

整个证书信任链验证流程如下图所示：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202101705.png)

最后⼀个问题，为什么需要证书链这么麻烦的流程？Root CA 为什么不直接颁发证书，⽽是要搞那么多中间层级呢？

这是为了确保根证书的绝对安全性，将根证书隔离地越严格越好，不然根证书如果失守了，那么整个信任链都会有问题。


#### TLS 第三次握⼿
客户端验证完证书后，认为可信则继续往下⾛。接着，客户端就会⽣成⼀个新的随机数 (pre-master)，⽤服务器的 RSA 公钥加密该随机数，通过「Change Cipher Key Exchange」消息传给服务端。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202102139.png)


服务端收到后，⽤ RSA 私钥解密，得到客户端发来的随机数 (pre-master)。

⾄此，客户端和服务端双⽅都共享了三个随机数，分别是 **Client Random、Server Random、pre-master。**


于是，双⽅根据已经得到的三个随机数，⽣成**会话密钥**（Master Secret），它是对称密钥，⽤于对后续的 HTTP请求/响应的数据加解密。

⽣成完会话密钥后，然后客户端发⼀个「Change Cipher Spec」，告诉服务端开始使⽤加密⽅式发送消息。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202102719.png)


然后，客户端再发⼀个「Encrypted Handshake Message（Finishd）」消息，把之前所有发送的数据做个摘要，再⽤会话密钥（master secret）加密⼀下，让服务器做个验证，验证加密通信是否可⽤和之前握⼿信息是否有被中途篡改过。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202102723.png)

可以发现，「Change Cipher Spec」之前传输的 TLS 握⼿数据都是明⽂，之后都是对称密钥加密的密⽂。


#### TLS 第四次握⼿
服务器也是同样的操作，发「Change Cipher Spec」和「Encrypted Handshake Message」消息，如果双⽅都验证加密和解密没问题，那么握⼿正式完成。

最后，就⽤「会话密钥」加解密 HTTP 请求和响应了。

### 2.22  RSA 算法的缺陷
使⽤ RSA 密钥协商算法的最⼤问题是**不⽀持前向保密**。因为客户端传递随机数（⽤于⽣成对称加密密钥的条件之⼀）给服务端时使⽤的是公钥加密的，服务端收到到后，会⽤私钥解密得到随机数。所以⼀旦服务端的私钥泄漏了，过去被第三⽅截获的所有 TLS 通讯密⽂都会被破解。

为了解决这⼀问题，于是就有了 DH 密钥协商算法，这⾥简单介绍它的⼯作流程。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202102727.png)

客户端和服务端各⾃会⽣成随机数，并以此作为私钥，然后根据公开的 DH 计算公式算出各⾃的公钥，通过 TLS握⼿双⽅交换各⾃的公钥，这样双⽅都有⾃⼰的私钥和对⽅的公钥，然后双⽅根据各⾃持有的材料算出⼀个随机数，这个随机数的值双⽅都是⼀样的，这就可以作为后续对称加密时使⽤的密钥。

DH 密钥交换过程中，即使第三⽅截获了 TLS 握⼿阶段传递的公钥，在不知道的私钥的情况下，也是⽆法计算出密钥的，⽽且每⼀次对称加密密钥都是实时⽣成的，实现前向保密。

但因为 DH 算法的计算效率问题，后⾯出现了 ECDHE 密钥协商算法，我们现在⼤多数⽹站使⽤的正是 ECDHE 密钥协商算法，关于 ECDHE 握⼿的过程，将在下⼀篇揭晓，尽情期待哦。

### 2.23 HTTPS ECDHE 握⼿解析
HTTPS 常⽤的密钥交换算法有两种，分别是 RSA 和 ECDHE 算法。

其中，RSA 是⽐较传统的密钥交换算法，它不具备前向安全的性质，因此现在很少服务器使⽤的。⽽ ECDHE 算法具有前向安全，所以被⼴泛使⽤。

#### 离散对数
ECDHE 密钥协商算法是 DH 算法演进过来的，所以我们先从 DH 算法说起。

DH 算法是⾮对称加密算法， 因此它可以⽤于密钥交换，该算法的核⼼数学思想是**离散对数。**

离散对数是「离散 + 对数」的两个数学概念的组合，所以我们先来复习⼀遍对数。

要说起对数，必然要说指数，因为它们是互为反函数，指数就是幂运算，对数是指数的逆运算。

举个栗⼦，如果以 2 作为底数，那么指数和对数运算公式，如下图所示：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202113651.png)

那么对于底数为 2 的时候， 32 的对数是 5，64 的对数是 6，计算过程如下：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202113654.png)

对数运算的取值是可以连续的，⽽离散对数的取值是不能连续的，因此也以「离散」得名，

离散对数是在对数运算的基础上加了「模运算」，也就说取余数，对应编程语⾔的操作符是「%」，也可以⽤ mod表示。离散对数的概念如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202114813.png)


上图中，底数 a 和模数 p 是离散对数的公共参数，也就说是公开的，b 是真数，i 是对数。知道了对数，就可以⽤上⾯的公式计算出真数。但反过来，知道真数却很难推算出对数。

**特别是当模数 p 是⼀个很⼤的质数，即使知道底数 a 和真数 b ，在现有的计算机的计算⽔平是⼏乎⽆法算出离散对数的，这就是 DH 算法的数学基础。**

#### DH 算法
认识了离散对数，我们来看看 DH 算法是如何密钥交换的。

现假设⼩红和⼩明约定使⽤ DH 算法来交换密钥，那么基于离散对数，⼩红和⼩明需要先确定模数和底数作为算法的参数，这两个参数是公开的，⽤ P 和 G 来代称。

然后⼩红和⼩明各⾃⽣成⼀个随机整数作为私钥，双⽅的私钥要各⾃严格保管，不能泄漏，⼩红的私钥⽤ a 代称，⼩明的私钥⽤ b 代称。

现在⼩红和⼩明双⽅都有了 P 和 G 以及各⾃的私钥，于是就可以计算出公钥：

- ⼩红的公钥记作 A，A = G ^ a ( mod P )；

- ⼩明的公钥记作 B，B = G ^ b ( mod P )；

A 和 B 也是公开的，因为根据离散对数的原理，从真数（A 和 B）反向计算对数 a 和 b 是⾮常困难的，⾄少在现有计算机的计算能⼒是⽆法破解的，如果 ⼦计算机出来了，那就有可能被破解，当然如果 ⼦计算机真的出来了，那么密钥协商算法就要做⼤的升级了。


双⽅交换各⾃ DH 公钥后，⼩红⼿上共有 5 个数：P、G、a、A、B，⼩明⼿上也同样共有 5 个数：P、G、b、B、A。

然后⼩红执⾏运算： B ^ a ( mod P )，其结果为 K，因为离散对数的幂运算有交换律，所以⼩明执⾏运算： A ^ b (mod P )，得到的结果也是 K。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202120148.png)


这个 K 就是⼩红和⼩明之间⽤的对称加密密钥，可以作为会话密钥使⽤。

可以看到，整个密钥协商过程中，⼩红和⼩明公开了 4 个信息：P、G、A、B，其中 P、G 是算法的参数，A 和 B是公钥，⽽ a、b 是双⽅各⾃保管的私钥，⿊客⽆法获取这 2 个私钥，因此⿊客只能从公开的 P、G、A、B ⼊⼿，计算出离散对数（私钥）。

前⾯也多次强调， 根据离散对数的原理，如果 P 是⼀个⼤数，在现有的计算机的计算能⼒是很难破解出 私钥 a、b的，破解不出私钥，也就⽆法计算出会话密钥，因此 DH 密钥交换是安全的。


#### DHE 算法
根据私钥⽣成的⽅式，DH 算法分为两种实现：
- static DH 算法，这个是已经被废弃了；
- DHE 算法，现在常⽤的；

static DH 算法⾥有⼀⽅的私钥是静态的，也就说每次密钥协商的时候有⼀⽅的私钥都是⼀样的，⼀般是服务器⽅固定，即 a 不变，客户端的私钥则是随机⽣成的。

于是，DH 交换密钥时就只有客户端的公钥是变化，⽽服务端公钥是不变的，那么随着时间延⻓，⿊客就会截获海的密钥协商过程的数据，因为密钥协商的过程有些数据是公开的，⿊客就可以依据这些数据暴⼒破解出服务器的私钥，然后就可以计算出会话密钥了，于是之前截获的加密数据会被破解，所以 static DH 算法不具备前向安全性。

既然固定⼀⽅的私钥有被破解的⻛险，那么⼲脆就让双⽅的私钥在每次密钥交换通信时，都是随机⽣成的、临时的，这个⽅式也就是 DHE 算法，E 全称是 ephemeral（临时性的）。

所以，即使有个⽜逼的⿊客破解了某⼀次通信过程的私钥，其他通信过程的私钥仍然是安全的，因为每个通信过程的私钥都是没有任何关系的，都是独⽴的，这样就保证了「前向安全」。


#### ECDHE 算法
DHE 算法由于计算性能不佳，因为需要做⼤ 的乘法，为了提升 DHE 算法的性能，所以就出现了现在⼴泛⽤于密钥交换算法 —— ECDHE 算法。

ECDHE 算法是在 DHE 算法的基础上利⽤了 ECC 椭圆曲线特性，可以⽤更少的计算 计算出公钥，以及最终的会话密钥。


⼩红和⼩明使⽤ ECDHE 密钥交换算法的过程：

- 双⽅事先确定好使⽤哪种椭圆曲线，和曲线上的基点 G，这两个参数都是公开的；

- 双⽅各⾃随机⽣成⼀个随机数作为私钥d，并与基点 G相乘得到公钥Q（Q = dG），此时⼩红的公私钥为 Q1和 d1，⼩明的公私钥为 Q2 和 d2；

- 双⽅交换各⾃的公钥，最后⼩红计算点（x1，y1） = d1Q2，⼩明计算点（x2，y2） = d2Q1，由于椭圆曲线上是可以满⾜乘法交换和结合律，所以 d1Q2 = d1d2G = d2d1G = d2Q1 ，因此双⽅的 **x 坐标是⼀样的，所以它是共享密钥，也就是会话密钥。**

这个过程中，双⽅的私钥都是随机、临时⽣成的，都是不公开的，即使根据公开的信息（椭圆曲线、公钥、基点G）也是很难计算出椭圆曲线上的离散对数（私钥）。

#### ECDHE 握⼿过程
知道了 ECDHE 算法基本原理后，我们就结合实际的情况来看看。

我⽤ Wireshark ⼯具抓了⽤ ECDHE 密钥协商算法的 TSL 握⼿过程，可以看到是四次握⼿：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202122228.png)

细⼼的⼩伙伴应该发现了，**使⽤了 ECDHE，在 TLS 第四次握⼿前，客户端就已经发送了加密的 HTTP 数据**，⽽对于 RSA 握⼿过程，必须要完成 TLS 四次握⼿，才能传输应⽤数据。

所以，**ECDHE 相⽐ RSA 握⼿过程省去了⼀个消息往返的时间**，这个有点「抢跑」的意思，它被称为是「TLSFalse Start」，跟「TCP Fast Open」有点像，都是在还没连接完全建⽴前，就发送了应⽤数据，这样便提⾼了传输的效率。

接下来，分析每⼀个 ECDHE 握⼿过程。

##### TLS 第⼀次握⼿
客户端⾸先会发⼀个「Client Hello」消息，消息⾥⾯有客户端使⽤的 TLS 版本号、⽀持的密码套件列表，以及⽣成的随机数（Client Random）。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202123206.png)


##### TLS 第⼆次握⼿
服务端收到客户端的「打招呼」，同样也要回礼，会返回「Server Hello」消息，消息⾯有服务器确认的 TLS 版本号，也给出了⼀个随机数（Server Random），然后从客户端的密码套件列表选择了⼀个合适的密码套件。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202123356.png)

不过，这次选择的密码套件就和 RSA 不⼀样了，我们来分析⼀下这次的密码套件的意思。

「 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384」

- 密钥协商算法使⽤ ECDHE；

- 签名算法使⽤ RSA；

- 握⼿后的通信使⽤ AES 对称算法，密钥⻓度 256 位，分组模式是 GCM；

- 摘要算法使⽤ SHA384；

接着，服务端为了证明⾃⼰的身份，发送「Certificate」消息，会把证书也发给客户端。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202124132.png)

这⼀步就和 RSA 握⼿过程有很⼤到区别了，因为服务端选择了 ECDHE 密钥协商算法，所以会在发送完证书后，发送「Server Key Exchange」消息。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202124321.png)

这个过程服务器做了三件事：

- 选择了名为 named_curve 的椭圆曲线，选好了椭圆曲线相当于椭圆曲线基点 G 也定好了，这些都会公开给客户端；

- ⽣成随机数作为服务端椭圆曲线的私钥，保留到本地；

- 根据基点 G 和私钥计算出服务端的椭圆曲线公钥，这个会公开给客户端。

为了保证这个椭圆曲线的公钥不被第三⽅篡改，服务端会⽤ RSA 签名算法给服务端的椭圆曲线公钥做个签名。

随后，就是「Server Hello Done」消息，服务端跟客户端表明：“这些就是我提供的信息，打招呼完毕”。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202124907.png)


⾄此，TLS 两次握⼿就已经完成了，⽬前客户端和服务端通过明⽂共享了这⼏个信息：**Client Random、ServerRandom 、使⽤的椭圆曲线、椭圆曲线基点 G、服务端椭圆曲线的公钥**，这⼏个信息很 要，是后续⽣成会话密钥的材料。

##### TLS 第三次握⼿

客户端收到了服务端的证书后，⾃然要校验证书是否合法，如果证书合法，那么服务端到身份就是没问题的。校验证书到过程，会⾛证书链逐级验证，确认证书的真实性，再⽤证书的公钥验证签名，这样就能确认服务端的身份了，确认⽆误后，就可以继续往下⾛。

客户端会⽣成⼀个随机数作为客户端椭圆曲线的私钥，然后再根据服务端前⾯给的信息，⽣成**客户端的椭圆曲线公钥**，然后⽤「**Client Key Exchange**」消息发给服务端。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202125207.png)

⾄此，双⽅都有对⽅的椭圆曲线公钥、⾃⼰的椭圆曲线私钥、椭圆曲线基点 G。于是，双⽅都就计算出点（x，y），其中 x 坐标值双⽅都是⼀样的，前⾯说 ECDHE 算法时候，说 x 是会话密钥，但实际应⽤中，x 还不是最终的会话密钥。


还记得 TLS 握⼿阶段，客户端和服务端都会⽣成了⼀个随机数传递给对⽅吗？

**最终的会话密钥，就是⽤「客户端随机数 + 服务端随机数 + x（ECDHE 算法算出的共享密钥） 」三个材料⽣成的。**


之所以这么麻烦，是因为 TLS 设计者不信任客户端或服务器「伪随机数」的可靠性，为了保证真正的完全随机，把三个不可靠的随机数混合起来，那么「随机」的程度就⾮常⾼了，⾜够不让⿊客计算出最终的会话密钥，安全性更⾼。


算好会话密钥后，客户端会发⼀个「**Change Cipher Spec**」消息，告诉服务端后续改⽤对称算法加密通信。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202125510.png)


接着，客户端会发「**Encrypted Handshake Message**」消息，把之前发送的数据做⼀个摘要，再⽤对称密钥加密⼀下，让服务端做个验证，验证下本次⽣成的对称密钥是否可以正常使⽤。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202125737.png)


##### TLS 第四次握⼿
最后，服务端也会有⼀个同样的操作，发「**Change Cipher Spec**」和「**Encrypted Handshake Message**」消息，如果双⽅都验证加密和解密没问题，那么握⼿正式完成。于是，就可以正常收发加密的 HTTP 请求和响应了。

### 2.24 总结以下 RSA 和 ECDHE 握⼿过程的区别：

- RSA 密钥协商算法「不⽀持」前向保密，ECDHE 密钥协商算法「⽀持」前向保密；

- 使⽤了 RSA 密钥协商算法，TLS 完成四次握⼿后，才能进⾏应⽤数据传输，⽽对于 ECDHE 算法，客户端可以不⽤等服务端的最后⼀次 TLS 握⼿，就可以提前发出加密的 HTTP 数据，节省了⼀个消息的往返时间；

- 使⽤ ECDHE， 在 TLS 第 2 次握⼿中，会出现服务器端发出的「Server Key Exchange」消息，⽽ RSA 握⼿过程没有该消息；

### 2.25 HTTPS 如何优化？

由裸数据传输的 HTTP 协议转成加密数据传输的 HTTPS 协议，给应⽤数据套了个「保护伞」，提⾼安全性的同时也带来了性能消耗。

因为 HTTPS 相⽐ HTTP 协议多⼀个 TLS 协议握⼿过程，⽬的是为了通过 **⾮对称加密握⼿协商**或者**交换出对称加密密钥**，这个过程最⻓可以花费掉 2 RTT，接着后续传输的应⽤数据都得使⽤对称加密密钥来加密/解密。

为了数据的安全性，我们不得不使⽤ HTTPS 协议，⾄今⼤部分⽹址都已从 HTTP 迁移⾄ HTTPS 协议，因此针对HTTPS 的优化是⾮常重要的。

这次，就从多个⻆度来优化 HTTPS。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202162807.png)

#### 分析性能损耗

产⽣性能消耗的两个环节：

- **第⼀个环节， TLS 协议握⼿过程**；
- 第⼆个环节，握⼿后的对称加密报⽂传输。

对于第⼆环节，现在主流的对称加密算法 AES、ChaCha20 性能都是不错的，⽽且⼀些 CPU ⼚商还针对它们做了硬件级别的优化，因此这个环节的性能消耗可以说⾮常地 **⼩**。

⽽第⼀个环节，TLS 协议握⼿过程不仅增加了⽹络延时（最⻓可以花费掉 2 RTT），⽽且握⼿过程中的⼀些步骤也会产⽣性能损耗，⽐如：

- 对于 ECDHE 密钥协商算法，握⼿过程中客户端和服务端都需要临时⽣成椭圆曲线公私钥；

- 客户端验证证书时，会访问 CA 获取 CRL 或者 OCSP，⽬的是验证服务器的证书是否有被吊销；

- 双⽅计算 Pre-Master，也就是对称加密密钥；

为了⼤家更清楚这些步骤在 TLS 协议握⼿的哪⼀个阶段，我画出了这幅图：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202164038.png)


####  硬件优化
玩游戏时，如果我们怎么都战胜不了对⽅，那么有⼀个最有效、最快的⽅式来变强，那就是「充钱」，如果还是不⾏，那说明你充的钱还不够多。

但是花钱也要花对⽅向，HTTPS 协议是**计算密集型**，⽽不是 I/O 密集型，所以不能把钱花在⽹卡、硬盘等地⽅，应该花在 **CPU** 上。

⼀个好的 CPU，可以提⾼计算性能，因为 HTTPS 连接过程中就有⼤量需要计算密钥的过程，所以这样可以**加速TLS 握⼿过程**。


另外，如果可以，应该选择可以⽀持 AES-NI 特性的 CPU，因为这种款式的 CPU 能在指令级别优化了 AES 算法，这样便加速了数据的加解密传输过程。

如果你的服务器是 Linux 系统，那么你可以使⽤下⾯这⾏命令查看 CPU 是否⽀持 AES-NI 指令集：

- sort -u /proc/crypto | grep module |grep aes 

如果我们的 CPU ⽀持 AES-NI 特性，那么对于对称加密的算法应该选择 AES 算法。否则可以选择 ChaCha20 对称加密算法，因为 ChaCha20 算法的运算指令相⽐ AES 算法会对 CPU 更友好⼀点。

#### 软件优化
软件的优化⽅向可以分层两种，⼀个是**软件升级**，⼀个是**协议优化**。

先说第⼀个软件升级，软件升级就是将正在使⽤的软件升级到最新版本，因为最新版本不仅提供了最新的特性，也优化了以前软件的问题或性能。⽐如：

- 将 Linux 内核从 2.x 升级到 4.x；
- 将 OpenSSL 从 1.0.1 升级到 1.1.1；

看似简单的软件升级，对于有成百上千服务器的公司来说，软件升级也跟硬件升级同样是⼀个棘⼿的问题，因为要实⾏软件升级，会花费时间和⼈⼒，同时也存在⼀定的⻛险，也可能会影响正常的线上服务。

既然如此，我们把⽬光放到协议优化，也就是在现有的环节下，通过较⼩的改动，来进⾏优化。

#### 协议优化

协议的优化就是对「密钥交换过程」进⾏优化。

##### 密钥交换算法优化

TLS 1.2 版本如果使⽤的是 RSA 密钥交换算法，那么需要 4 次握⼿，也就是要花费 2 RTT，才可以进⾏应⽤数据的传输，⽽且 RSA 密钥交换算法不具备前向安全性。

总之使⽤ RSA 密钥交换算法的 TLS 握⼿过程，不仅慢，⽽且安全性也不⾼。

因此如果可以，尽量选⽤ **ECDHE 密钥交换算法**替换 RSA 算法，因为该算法由于⽀持「False Start」，它是“抢跑”的意思，客户端可以在 TLS 协议的第 3 次握⼿后，第 4 次握⼿前，发送加密的应⽤数据，以此将 TLS 握⼿的消息**往返由 2 RTT 减少到 1 RTT，⽽且安全性也⾼，具备前向安全性**。

ECDHE 算法是基于椭圆曲线实现的，不同的椭圆曲线性能也不同，应该尽 选择 **x25519**曲线，该曲线是⽬前最快的椭圆曲线。

⽐如在 Nginx 上，可以使⽤ ssl_ecdh_curve 指令配置想使⽤的椭圆曲线，把优先使⽤的放在前⾯：
- ssl_ecdh_curve X25519 : secp384r1


对于对称加密算法⽅⾯，如果对安全性不是特别⾼的要求，可以选⽤ AES_128_GCM，它⽐ AES_256_GCM快⼀些，因为密钥的⻓度短⼀些。


⽐如在 Nginx 上，可以使⽤ ssl_ciphers 指令配置想使⽤的⾮对称加密算法和对称加密算法，也就是密钥套件，⽽且把性能最快最安全的算法放在最前⾯：
- ssl_ciphers 'EECDH+ECDSA+AES128+SHA:RSA+AES128+SHA';


### TLS 升级

当然，如果可以，直接把 TLS 1.2 升级成 TLS 1.3，TLS 1.3 ⼤幅度简化了握⼿的步骤，完成 **TLS 握⼿只要 1RTT**，⽽且安全性更⾼。

在 TLS 1.2 的握⼿中，⼀般是需要 4 次握⼿，先要通过 Client Hello （第 1 次握⼿）和 Server Hello（第 2 次握⼿） 消息协商出后续使⽤的加密算法，再互相交换公钥（第 3 和 第 4 次握⼿），然后计算出最终的会话密钥，下图的左边部分就是 TLS 1.2 的握⼿过程：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202170443.png)


上图的右边部分就是 TLS 1.3 的握⼿过程，可以发现 TLS 1.3 **把 Hello 和公钥交换**这两个消息合并成了⼀个消息，于是这样就减少到只需 **1 RTT 就能完成 TLS 握⼿**。

怎么合并的呢？具体的做法是，客户端在 Client Hello 消息⾥带上了⽀持的椭圆曲线，以及这些椭圆曲线对应的公钥。

服务端收到后，选定⼀个椭圆曲线等参数，然后返回消息时，带上服务端这边的公钥。经过这 1 个 RTT，双⽅⼿上已经有⽣成会话密钥的材料了，于是客户端计算出会话密钥，就可以进⾏应⽤数据的加密传输了。

⽽且，TLS1.3 对密码套件进⾏“减肥”了，对于密钥交换算法，废除了不⽀持前向安全性的 RSA 和 DH 算法，**只⽀持 ECDHE 算法**。


对于对称加密和签名算法，只⽀持⽬前最安全的⼏个密码套件，⽐如 openssl 中仅⽀持下⾯ 5 种密码套件：

- TLS_AES_256_GCM_SHA384
- TLS_CHACHA20_POLY1305_SHA256
- TLS_AES_128_GCM_SHA256
- TLS_AES_128_CCM_8_SHA256
- TLS_AES_128_CCM_SHA256

之所以 TLS1.3 仅⽀持这么少的密码套件，是因为 TLS1.2 由于⽀持各种古⽼且不安全的密码套件，中间⼈可以利⽤降级攻击，伪造客户端的 Client Hello 消息，替换客户端⽀持的密码套件为⼀些不安全的密码套件，使得服务器被迫使⽤这个密码套件进⾏ HTTPS 连接，从⽽破解密⽂。

### 证书优化
为了验证的服务器的身份，服务器会在 TSL 握⼿过程中，把⾃⼰的证书发给客户端，以此证明⾃⼰身份是可信的。

对于证书的优化，可以有两个⽅向：

- ⼀个是证书传输，
- ⼀个是证书验证；

##### 证书传输优化
要让证书更便于传输，那必然是减少证书的⼤⼩，这样可以节约带宽，也能减少客户端的运算 。所以，**对于服务器的证书应该选择椭圆曲线（ECDSA）证书，⽽不是 RSA 证书，因为在相同安全强度下，ECC 密钥⻓度⽐ RSA短的多。**


##### 证书验证优化
客户端在验证证书时，是个复杂的过程，会⾛证书链逐级验证，验证的过程不仅需要「⽤ CA 公钥解密证书」以及「⽤签名算法验证证书的完整性」，⽽且为了知道证书是否被 CA 吊销，客户端有时还会再去访问 CA， 下载 CRL或者 OCSP 数据，以此确认证书的有效性。

这个访问过程是 HTTP 访问，因此⼜会产⽣⼀系列⽹络通信的开销，如 DNS 查询、建⽴连接、收发数据等。

###### CRL
CRL 称为证书吊销列表（Certificate Revocation List），这个列表是由 CA 定期更新，列表内容都是被撤销信任的证书序号，如果服务器的证书在此列表，就认为证书已经失效，不在的话，则认为证书是有效的。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202171535.png)

但是 CRL 存在两个问题：

- 第⼀个问题，由于 CRL 列表是由 CA 维护的，定期更新，如果⼀个证书刚被吊销后，客户端在更新 CRL 之前还是会信任这个证书，实时性较差；

- 第⼆个问题，随着吊销证书的增多，列表会越来越⼤，下载的速度就会越慢，下载完客户端还得遍历这么⼤的列表，那么就会导致客户端在校验证书这⼀环节的延时很⼤，进⽽拖慢了 HTTPS 连接。

###### OCSP
因此，现在基本都是使⽤ OCSP ，名为在线证书状态协议（Online Certificate Status Protocol）来查询证书的有效性，它的⼯作⽅式是向 **CA 发送查询请求，让 CA 返回证书的有效状态**。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202171919.png)


不必像 CRL ⽅式客户端需要下载⼤⼤的列表，还要从列表查询，同时因为可以实时查询每⼀张证书的有效性，解决了 CRL 的实时性问题。

OCSP 需要向 CA 查询，因此也是要发⽣⽹络请求，⽽且还得看 CA 服务器的“脸⾊”，如果⽹络状态不好，或者CA 服务器繁忙，也会导致客户端在校验证书这⼀环节的延时变⼤。

###### OCSP Stapling

于是为了解决这⼀个⽹络开销，就出现了 OCSP Stapling，其原理是：服务器向 CA 周期性地查询证书状态，获得⼀个带有时间戳和签名的响应结果并缓存它。

当有客户端发起连接请求时，服务器会把这个「响应结果」在 TLS 握⼿过程中发给客户端。由于有签名的存在，服务器⽆法篡改，因此客户端就能得知证书是否已被吊销了，这样客户端就不需要再去查询。

### 会话复⽤
TLS 握⼿的⽬的就是为了协商出会话密钥，也就是对称加密密钥，那我们如果我们把⾸次 TLS 握⼿协商的对称加密密钥缓存起来，待下次需要建⽴ HTTPS 连接时，直接「复⽤」这个密钥，不就减少 TLS 握⼿的性能损耗了吗？

这种⽅式就是**会话复⽤**（TLS session resumption），会话复⽤分两种：
- 第⼀种叫 Session ID；
- 第⼆种叫 Session Ticket；

#### Session ID
Session ID 的⼯作原理是，客户端和服务器⾸次 TLS 握⼿连接后，双⽅会在内存缓存会话密钥，并⽤唯⼀的Session ID 来标识，Session ID 和会话密钥相当于 key-value 的关系。

当客户端再次连接时，hello 消息⾥会带上 Session ID，服务器收到后就会从内存找，如果找到就直接⽤该会话密钥恢复会话状态，跳过其余的过程，只⽤⼀个消息往返就可以建⽴安全通信。当然为了安全性，内存中的会话密钥会定期失效。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202174156.png)

但是它有两个缺点：

- 服务器必须保持每⼀个客户端的会话密钥，随着客户端的增多，服务器的内存压⼒也会越⼤。

- 现在⽹站服务⼀般是由多台服务器通过负载均衡提供服务的，客户端再次连接不⼀定会命中上次访问过的服务器，于是还要⾛完整的 TLS 握⼿过程；

#### Session Ticket
为了解决 Session ID 的问题，就出现了 Session Ticket，**服务器不再缓存每个客户端的会话密钥，⽽是把缓存的⼯作交给了客户端，类似于 HTTP 的 Cookie**。

客户端与服务器⾸次建⽴连接时，服务器会加密「会话密钥」作为 Ticket 发给客户端，交给客户端缓存该 Ticket。

客户端再次连接服务器时，客户端会发送 Ticket，服务器解密后就可以获取上⼀次的会话密钥，然后验证有效期，如果没问题，就可以恢复会话了，开始加密通信。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202175657.png)

对于集群服务器的话，**要确保每台服务器加密 「会话密钥」的密钥是⼀致的**，这样客户端携带 Ticket 访问任意⼀台服务器时，都能恢复会话。

Session ID 和 Session Ticket **都不具备前向安全性**，因为⼀旦加密「会话密钥」的密钥被破解或者服务器泄漏「会话密钥」，前⾯劫持的通信密⽂都会被破解。

同时应对**重放攻击**也很困难，这⾥简单介绍下重放攻击⼯作的原理。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202180115.png)


假设 Alice 想向 Bob 证明⾃⼰的身份。 Bob 要求 Alice 的密码作为身份证明，爱丽丝应尽全⼒提供（可能是在经过如哈希函数的转换之后）。与此同时，Eve 窃听了对话并保留了密码（或哈希）。

交换结束后，Eve（冒充 Alice ）连接到 Bob。当被要求提供身份证明时，Eve 发送从 Bob 接受的最后⼀个会话中读取的 Alice 的密码（或哈希），从⽽授予 Eve 访问权限。

放攻击的危险之处在于，如果中间⼈截获了某个客户端的 Session ID 或 Session Ticket 以及 POST 报⽂，⽽⼀般 POST 请求会改变数据库的数据，中间⼈就可以利⽤此截获的报⽂，不断向服务器发送该报⽂，这样就会导致数据库的数据被中间⼈改变了，⽽客户是不知情的。


避免 放攻击的⽅式就是需要**对会话密钥设定⼀个合理的过期时间**。


#### Pre-shared Key

前⾯的 Session ID 和 Session Ticket ⽅式都需要在 1 RTT 才能恢复会话。

⽽ TLS1.3 更为⽜逼，对于 连 TLS1.3 只需要 0 RTT，原理和 Ticket 类似，只不过在重连时，客户端会把 Ticket和 HTTP 请求⼀同发送给服务端，这种⽅式叫 Pre-shared Key。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202181113.png)

同样的，Pre-shared Key 也有重放攻击的危险。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202182710.png)

如上图，假设中间⼈通过某种⽅式，截获了客户端使⽤会话重⽤技术的 POST 请求，通常 POST 请求是会改变数据库的数据，然后中间⼈就可以把截获的这个报⽂发送给服务器，服务器收到后，也认为是合法的，于是就恢复会话，致使数据库的数据⼜被更改，但是此时⽤户是不知情的。

所以，应对重放攻击可以给会话密钥设定⼀个合理的过期时间，以及只针对安全的 HTTP 请求如 GET/HEAD 使⽤会话重⽤。

### 2.26 HTTP/2 ⽜逼在哪？
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211202183221.png)


#### HTTP/1.1 协议的性能问题

我们得先要了解下 HTTP/1.1 协议存在的性能问题，因为 HTTP/2 协议就是把这些性能问题逐个攻破了。

现在的站点相⽐以前变化太多了，⽐如：

- 消息的⼤⼩变⼤了，从⼏ KB ⼤⼩的消息，到⼏ MB ⼤⼩的消息；

- ⻚⾯资源变多了，从每个⻚⾯不到 10 个的资源，到每⻚超 100 多个资源；

- 内容形式变多样了，从单纯的⽂本内容，到图⽚、视频、⾳频等内容；

- 实时性要求变⾼了，对⻚⾯的实时性要求的应⽤越来越多；

这些变化带来的最⼤性能问题就是 HTTP/1.1 的⾼延迟，延迟⾼必然影响的就是⽤户体验。主要原因如下⼏个：

- **延迟难以下降**，虽然现在⽹络的「带宽」相⽐以前变多了，但是延迟降到⼀定幅度后，就很难再下降了，说⽩了就是到达了延迟的下限；

- **并发连接有限**，⾕歌浏览器最⼤并发连接数是 6 个，⽽且每⼀个连接都要经过 TCP 和 TLS 握⼿耗时，以及TCP 慢启动过程给流 带来的影响；

- **队头阻塞问题**，同⼀连接只能在完成⼀个 HTTP 事务（请求和响应）后，才能处理下⼀个事务；
HTTP 头部巨⼤且 复，由于 HTTP 协议是⽆状态的，每⼀个请求都得携带 HTTP 头部，特别是对于有携带cookie 的头部，⽽ cookie 的⼤⼩通常很⼤；

- **不⽀持服务器推送消息**，因此当客户端需要获取通知时，只能通过定时器不断地拉取消息，这⽆疑浪费⼤了带宽和服务器资源。


尽管对 HTTP/1.1 协议的优化⼿段如此之多，但是效果还是不尽⼈意，因为这些⼿段都是对 HTTP/1.1 协议的“外部”做优化，⽽⼀些关键的地⽅是没办法优化的，⽐如请求-响应模型、头部巨⼤且重复、并发连接耗时、服务器不能主动推送等，要改变这些必须重新设计 HTTP 协议，于是 HTTP/2 就出来了！



#### 兼容 HTTP/1.1

HTTP/2 出来的⽬的是为了改善 HTTP 的性能。协议升级有⼀个很重要的地⽅，就是要兼容⽼版本的协议，否则新协议推⼴起来就相当困难，所幸 HTTP/2 做到了兼容 HTTP/1.1 。

那么，HTTP/2 是怎么做的呢？

第⼀点，HTTP/2 没有在 URI ⾥引⼊新的协议名，仍然⽤「http://」表示明⽂协议，⽤「https://」表示加密协议，于是只需要浏览器和服务器在背后⾃动升级协议，这样可以让⽤户意识不到协议的升级，很好的实现了协议的平滑升级。

第⼆点，只在应⽤层做了改变，还是基于 TCP 协议传输，应⽤层⽅⾯为了保持功能上的兼容，HTTP/2 把 HTTP 分解成了「语义」和「语法」两个部分，「语义」层不做改动，与 HTTP/1.1 完全⼀致，⽐如请求⽅法、状态码、头字段等规则保留不变。

但是，HTTP/2 在「语法」层⾯做了很多改造，基本改变了 HTTP 报⽂的传输格式。

#### 头部压缩

HTTP 协议的报⽂是由「Header + Body」构成的，对于 Body 部分，HTTP/1.1 协议可以使⽤头字段 「Content-Encoding」指定 Body 的压缩⽅式，⽐如⽤ gzip 压缩，这样可以节约带宽，但报⽂中的另外⼀部分 Header，是没有针对它的优化⼿段。

HTTP/1.1 报⽂中 Header 部分存在的问题：

- 含很多固定的字段，⽐如Cookie、User Agent、Accept 等，这些字段加起来也⾼达⼏百字节甚⾄上千字节，所以有必要压缩；

- ⼤量的请求和响应的报⽂⾥有很多字段值都是重复的，这样会使得⼤量带宽被这些冗余的数据占⽤了，所以有必须要避免重复性；

- 字段是 ASCII 编码的，虽然易于⼈类观察，但效率低，所以有必要改成⼆进制编码；

HTTP/2 对 Header 部分做了⼤改造，把以上的问题都解决了。

HTTP/2 没使⽤常⻅的 gzip 压缩⽅式来压缩头部，⽽是开发了**HPACK** 算法，HPACK 算法主要包含三个组成部分：
- 静态字典；
- 动态字典；
- Huffman 编码（压缩算法）；


客户端和服务器两端都会建⽴和维护「**字典**」，⽤⻓度较⼩的索引号表示重复的字符串，再⽤ Huffman 编码压缩数据，**可达到 50%~90% 的⾼压缩率**。


##### 静态表编码
HTTP/2 为⾼频出现在头部的字符串和字段建⽴了⼀张静态表，它是写⼊到 HTTP/2 框架⾥的，不会变化的，静态表⾥共有 **61** 组，如下图：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211203180056.png)


表中的 Index 表示索引（Key）， Header Value 表示索引对应的 Value， Header Name 表示字段的名字，⽐如 Index 为 2 代表 GET，Index 为 8 代表状态码 200。

你可能注意到，表中有的 Index 没有对应的 Header Value，这是因为这些 Value 并不是固定的⽽是变化的，这些Value 都会经过 Huffman 编码后，才会发送出去。


这么说有点抽象，我们来看个具体的例⼦，下⾯这个 server 头部字段，在 HTTP/1.1 的形式如下：

- server: nghttpx\r\n

算上冒号空格和末尾的\r\n,共占用17字节，⽽使⽤了静态表和 Huffman 编码，可以将它压缩成 8 字节，压缩率⼤概 47 %。

我抓了个 HTTP/2 协议的⽹络包，你可以从下图看到，⾼亮部分就是 server 头部字段，只⽤了 8 个字节来表示server 头部数据。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211203181143.png)

根据 RFC7541 规范，如果头部字段属于静态表范围，并且 Value 是变化，那么它的 HTTP/2 头部前 2 位固定为01 ，所以整个头部格式如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211203181617.png)

HTTP/2 头部由于基于 **⼆进制编码**，就不需要冒号空格和末尾的\r\n作为分隔符，于是改⽤表示字符串⻓度（ValueLength）来分割 Index 和 Value。

接下来，根据这个头部格式来分析上⾯抓包的 server 头部的⼆进制数据。

⾸先，从静态表中能查到 **server** 头部字段的 Index 为 **54**，⼆进制为 **110110**，再加上固定 **01**，头部格式第 1 个字节就是 01110110 ，这正是上⾯抓包标注的红⾊部分的⼆进制数据。


然后，第⼆个字节的⾸个⽐特位表示 Value 是否经过 Huffman 编码，剩余的 7 位表示 Value 的⻓度，⽐如这次例⼦的第⼆个字节为 10000110 ，⾸位⽐特位为 1 就代表 Value 字符串是经过 Huffman 编码的，经过 Huffman 编码的 Value ⻓度为 6。


最后，字符串 **nghttpx** 经过 Huffman 编码后压缩成了 6 个字节，Huffman 编码的原理是将⾼频出现的信息⽤「较短」的编码表示，从⽽缩减字符串⻓度。


于是，在统计⼤ 的 HTTP 头部后，HTTP/2 根据出现频率将 ASCII 码编码为了 Huffman 编码表，可以在RFC7541 ⽂档找到这张静态 Huffman 表，我就不把表的全部内容列出来了，我只列出字符串 nghttpx 中每个字符对应的 Huffman 编码，如下图：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211206094308.png)


通过查表后，字符串 nghttpx 的 Huffman 编码在下图看到，共 6 个字节，每⼀个字符的 Huffman 编码，我⽤相同的颜⾊将他们对应起来了，最后的 7 位是补位的。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211206094508.png)


最终， server 头部的⼆进制数据对应的静态头部格式如下：
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211206094828.png)

##### 动态表编码

静态表只包含了 61 种⾼频出现在头部的字符串，不在静态表范围内的头部字符串就要⾃⾏构建动态表，它的Index 从 **62** 起步，会在编码解码的时候随时更新。

⽐如，第⼀次发送时头部中的「 **user-agent** 」字段数据有上百个字节，经过Huffman 编码发送出去后，客户端和服务器双⽅都会更新⾃⼰的动态表，添加⼀个新的 Index 号62。**那么在下⼀次发送的时候，就不⽤重复发这个字段的数据了，只⽤发 1 个字节的Index 号就好了，因为双⽅都可以根据⾃⼰的动态表获取到字段的数据。**

所以，使得动态表⽣效有⼀个前提：***必须同⼀个连接上，重复传输完全相同的 HTTP 头部**。如果消息字段在 1 个连接上只发送了 1 次，或者重复传输时，字段总是略有变化，动态表就⽆法被充分利⽤了。

因此，随着在同⼀ HTTP/2 连接上发送的报⽂越来越多，客户端和服务器双⽅的「字典」积累的越来越多，理论上最终每个头部字段都会变成 1 个字节的 Index，这样便避免了⼤量的冗余数据的传输，⼤⼤节约了带宽。


理想很美好，现实很⻣感。动态表越⼤，占⽤的内存也就越⼤，如果占⽤了太多内存，是会影响服务器性能的，因此 Web 服务器都会提供类似 **http2_max_requests** 的配置，⽤于限制⼀个连接上能够传输的请求数量，避免动态表⽆限增⼤，请求数量到达上限后，就会关闭 HTTP/2 连接来释放内存。

综上，HTTP/2 头部的编码通过「静态表、动态表、Huffman 编码」共同完成的。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211206100643.png)


#### ⼆进制帧

HTTP/2 厉害的地⽅在于将 HTTP/1 的⽂本格式改成⼆进制格式传输数据，极⼤提⾼了 HTTP 传输效率，⽽且⼆进制数据使⽤位运算能⾼效解析。

你可以从下图看到，HTTP/1.1 的响应 和 HTTP/2 的区别：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211206100928.png)


HTTP/2 把响应报⽂划分成了两个帧（Frame），图中的 HEADERS（⾸部）和 DATA（消息负载） 是帧的类型，也就是说⼀条 HTTP 响应，划分成了两个帧来传输，并且采⽤⼆进制来编码。

HTTP/2 ⼆进制帧的结构如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211206101323.png)

帧头（Fream Header）很⼩，只有 9 个字节，帧开头的前 3 个字节表示帧数据（Fream Playload）的⻓度。


帧⻓度后⾯的⼀个字节是表示**帧的类型**，HTTP/2 总共定义了 10 种类型的帧，⼀般分为**数据帧**和**控制帧**两类，如下表格：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211206101923.jpg)


帧类型后⾯的⼀个字节是**标志位**，可以保存 8 个标志位，⽤于携带简单的控制信息，⽐如：

- END_HEADERS 表示头数据结束标志，相当于 HTTP/1 ⾥头后的空⾏（“\r\n”）;
- END_STREAM 表示单⽅向数据发送结束，后续不会再有数据帧;
- PRIORITY 表示流的优先级;

帧头的最后 4 个字节是**流标识符**（Stream ID），但最⾼位被保留不⽤，只有 31 位可以使⽤，因此流标识符的最⼤值是 2^31，⼤约是 21 亿，它的作⽤是⽤来标识该 Fream 属于哪个 Stream，接收⽅可以根据这个信息从乱序的帧⾥找到相同 Stream ID 的帧，从⽽有序组装信息。

最后⾯就是**帧数据**了，它存放的是通过 **HPACK算法**压缩过的 HTTP 头部和包体。

### 并发传输
知道了 HTTP/2 的帧结构后，我们再来看看它是如何实现并发传输的。

我们都知道 HTTP/1.1 的实现是基于请求-响应模型的。同⼀个连接中，HTTP 完成⼀个事务（请求与响应），才能处理下⼀个事务，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是⽆法发送的，也造成了**队头阻塞**的问题。

⽽ HTTP/2 就很⽜逼了，通过 Stream 这个设计，**多个Stream 复⽤⼀条 TCP 连接，达到并发的效果**，解决了HTTP/1.1 队头阻塞的问题，提⾼了 HTTP 传输的吞吐 。

为了理解 HTTP/2 的并发是怎样实现的，我们先来理解 HTTP/2 中的 Stream、Message、Frame 这 3 个概念。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211206104222.png)



你可以从上图中看到：
- 1 个 TCP 连接包含⼀个或者多个 Stream，Stream 是 HTTP/2 并发的关键技术；
- Stream ⾥可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成；
- Message ⾥包含⼀条或者多个 Frame，Frame 是 HTTP/2 最⼩单位，以⼆进制压缩格式存放 HTTP/1 中的内容（头部和包体）；

因此，我们可以得出 2 个结论：HTTP 消息可以由多个 Frame 构成，以及 1 个 Frame 可以由多个 TCP 报⽂构成。

在 HTTP/2 连接上，**不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ）**，因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息，⽽**同⼀ Stream 内部的帧必须是严格有序的**。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211206111044.png)



客户端和服务器双⽅都可以建⽴ Stream， Stream ID 也是有区别的，客户端建⽴的 Stream 必须是奇数号，⽽服务器建⽴的 Stream 必须是偶数号。


同⼀个连接中的 Stream ID 是不能复⽤的，只能顺序递增，所以当 Stream ID 耗尽时，需要发⼀个控制帧GOAWAY ，⽤来关闭 TCP 连接。

在 Nginx 中，可以通过 http2_max_concurrent_streams 配置来设置 Stream 的上限，默认是 128 个。


HTTP/2 通过 Stream 实现的并发，⽐ HTTP/1.1 通过 TCP 连接实现并发要⽜逼的多，因为当 HTTP/2 实现 100 个并发 Stream 时，只需要建⽴⼀次 TCP 连接，⽽ HTTP/1.1 需要建⽴ 100 个 TCP 连接，每个 TCP 连接都要经过TCP 握⼿、慢启动以及 TLS 握⼿过程，这些都是很耗时的。

HTTP/2 还可以对每个 Stream 设置不同优先级，帧头中的「标志位」可以设置优先级，⽐如客户端访问HTML/CSS 和图⽚资源时，希望服务器先传递 HTML/CSS，再传图⽚，那么就可以通过设置 Stream 的优先级来实现，以此提⾼⽤户体验。


### 服务器主动推送资源
HTTP/1.1 不⽀持服务器主动推送资源给客户端，都是由客户端向服务器发起请求后，才能获取到服务器响应的资源。

⽐如，客户端通过 HTTP/1.1 请求从服务器那获取到了 HTML ⽂件，⽽ HTML 可能还需要依赖 CSS 来渲染⻚⾯，这时客户端还要再发起获取 CSS ⽂件的请求，需要两次消息往返，如下图左边部分：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211206114207.png)


如上图右边部分，在 HTTP/2 中，客户端在访问 HTML 时，服务器可以直接主动推送 CSS ⽂件，减少了消息传递的次数。

在 Nginx 中，如果你希望客户端访问 /test.html 时，服务器直接推送 /test.css，那么可以这么配置：

location /test.html {

 http2_push /test.css;

}


那 HTTP/2 的推送是怎么实现的？

客户端发起的请求，必须使⽤的是奇数号 Stream，服务器主动的推送，使⽤的是偶数号 Stream。服务器在推送资源时，会通过 **PUSH_PROMISE** 帧传输 HTTP 头部，并通过帧中的 **Promised Stream ID** 字段告知客户端，接下来会在哪个偶数号 Stream 中发送包体。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211206114514.png)


如上图，在 Stream 1 中通知客户端 CSS 资源即将到来，然后在 Stream 2 中发送 CSS 资源，注意 Stream 1 和 2是可以并发的。


### 总结
HTTP/2 协议其实还有很多内容，⽐如流控制、流状态、依赖关系等等。

这次主要介绍了关于 HTTP/2 是如何提示性能的⼏个⽅向，它相⽐ HTTP/1 ⼤⼤提⾼了传输效率、吞吐能⼒。

第⼀点，对于常⻅的 HTTP 头部通过静态表和 Huffman 编码的⽅式，将体积压缩了近⼀半，⽽且针对后续的请求头部，还可以建⽴动态表，将体积压缩近 90%，⼤⼤提⾼了编码效率，同时节约了带宽资源。

不过，动态表并⾮可以⽆限增⼤， 因为动态表是会占⽤内存的，动态表越⼤，内存也越⼤，容易影响服务器总体的并发能⼒，因此服务器需要限制 HTTP/2 连接时⻓或者请求次数。

第⼆点，HTTP/2 实现了 Stream 并发，多个 Stream 只需复⽤ 1 个 TCP 连接，节约了 TCP 和 TLS 握⼿时间，以及减少了 TCP 慢启动阶段对流量的影响。不同的 Stream ID 才可以并发，即时乱序发送帧也没问题，但是同⼀个Stream ⾥的帧必须严格有序。

另外，可以根据资源的渲染顺序来设置 Stream 的优先级，从⽽提⾼⽤户体验。

第三点，服务器⽀持主动推送资源，⼤⼤提升了消息的传输性能，服务器推送资源时，会先发送 PUSH_PROMISE帧，告诉客户端接下来在哪个 Stream 发送资源，然后⽤偶数号 Stream 发送资源给客户端。

HTTP/2 通过 Stream 的并发能⼒，解决了 HTTP/1 队头阻塞的问题，看似很完美了，但是 HTTP/2 还是存在“队头阻塞”的问题，只不过问题不是在 HTTP 这⼀层⾯，⽽是在 TCP 这⼀层。

HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区⾥的数据返回给 HTTP 应⽤，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区⾥，只有等到这 1 个字节数据到达时，HTTP/2 应⽤层才能从内核中拿到数据，这就是HTTP/2 队头阻塞问题。

有没有什么解决⽅案呢？既然是 TCP 协议⾃身的问题，那⼲脆放弃 TCP 协议，转⽽使⽤ UDP 协议作为传输层协议，这个⼤胆的决定， HTTP/3 协议做了！



### 2.27 HTTP/3 强势来袭
HTTP/3 现在还没正式推出，不过⾃ 2017 年起， HTTP/3 已经更新到 34 个草案了，基本的特性已经确定下来了，对于包格式可能后续会有变化。

所以，这次 HTTP/3 介绍不会涉及到包格式，只说它的特性。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211206115937.png)


#### 美中不⾜的 HTTP/2
HTTP/2 通过头部压缩、⼆进制编码、多路复⽤、服务器推送等新特性⼤幅度提升了 HTTP/1.1 的性能，⽽美中不⾜的是 HTTP/2 协议是基于 TCP 实现的，于是存在的缺陷有三个。
- 队头阻塞；
- TCP 与 TLS 的握⼿时延迟；
- ⽹络迁移需要 新连接；



##### 队头阻塞
HTTP/2 多个请求是跑在⼀个 TCP 连接中的，那么当 TCP 丢包时，整个 TCP 都要等待 传，那么就会阻塞该TCP 连接中的所有请求。

因为 TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且有序的，如果序列号较低的 TCP 段在⽹络传输中丢失了，即使序列号较⾼的 TCP 段已经被接收了，应⽤层也⽆法从内核中读取到这部分数据，从 HTTP 视⻆看，就是请求被阻塞了。

举个例⼦，如下图：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片2021120755.png)

图中发送⽅发送了很多个 packet，每个 packet 都有⾃⼰的序号，你可以认为是 TCP 的序列号，其中 packet 3 在⽹络中丢失了，即使 packet 4-6 被接收⽅收到后，由于内核中的 TCP 数据不是连续的，于是接收⽅的应⽤层就⽆法从内核中读取到，只有等到 packet 3  传后，接收⽅的应⽤层才可以从内核中读取到数据，这就是 HTTP/2 的队头阻塞问题，是在 TCP 层⾯发⽣的。


#### TCP 与 TLS 的握⼿时延迟
发起 HTTP 请求时，需要经过 TCP 三次握⼿和 TLS 四次握⼿（TLS 1.2）的过程，因此共需要 3 个 RTT 的时延才能发出请求数据。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片2021121435.png)

另外， TCP 由于具有「拥塞控制」的特性，所以刚建⽴连接的 TCP 会有个「慢启动」的过程，它会对 TCP 连接产⽣"减速"效果。


#### ⽹络迁移需要重新连接
⼀个 TCP 连接是由四元组（源 IP 地址，源端⼝，⽬标 IP 地址，⽬标端⼝）确定的，这意味着如果 IP 地址或者端⼝变动了，就会导致需要 TCP 与 TLS  新握⼿，这不利于移动设备切换⽹络的场景，⽐如 4G ⽹络环境切换成WIFI。

这些问题都是 TCP 协议固有的问题，⽆论应⽤层的 HTTP/2 在怎么设计都⽆法逃脱。要解决这个问题，就必须把**传输层协议替换成 UDP**，这个⼤胆的决定，HTTP/3 做了！

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211206122011.png)

#### QUIC 协议的特点
我们深知，UDP 是⼀个简单、不可靠的传输协议，⽽且是 UDP 包之间是⽆序的，也没有依赖关系。

⽽且，UDP 是不需要连接的，也就不需要握⼿和挥⼿的过程，所以天然的就⽐ TCP 快。

当然，HTTP/3 不仅仅只是简单将传输协议替换成了 UDP，还基于 UDP 协议在「应⽤层」实现了 QUIC 协议，它具有类似 TCP 的连接管理、拥塞窗⼝、流量控制的⽹络特性，相当于将不可靠传输的 UDP 协议变成“可靠”的了，所以不⽤担⼼数据包丢失的问题。

QUIC 协议的优点有很多，这⾥举例⼏个，⽐如：

- ⽆队头阻塞；
- 更快的连接建⽴；
- 连接迁移；

##### ⽆队头阻塞
QUIC 协议也有类似 HTTP/2 Stream 与多路复⽤的概念，也是可以在同⼀条连接上并发传输多个 Stream，Stream可以认为就是⼀条 HTTP 请求。

由于 QUIC 使⽤的传输协议是 UDP，UDP 不关⼼数据包的顺序，如果数据包丢失，UDP 也不关⼼。

不过 QUIC 协议会保证数据包的可靠性，每个数据包都有⼀个序号唯⼀标识。当某个流中的⼀个数据包丢失了，即使该流的其他数据包到达了，数据也⽆法被 HTTP/3 读取，直到 QUIC 重传丢失的报⽂，数据才会交给 HTTP/3。


⽽其他流的数据报⽂只要被完整接收，HTTP/3 就可以读取到数据。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。


所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独⽴的，某个流发⽣丢包了，只会影响该流，其他流不受影响。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211206150612.png)


##### 更快的连接建⽴
对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在⼀起，需要分批次来握⼿，先 TCP 握⼿，再 TLS 握⼿。

HTTP/3 在传输数据前虽然需要 QUIC 协议握⼿，这个握⼿过程只需要 1 RTT，握⼿的⽬的是为确认双⽅的「连接ID」，连接迁移就是基于连接 ID 实现的。


但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，⽽是QUIC 内部包含了 TLS，它在⾃⼰的帧会携带 TLS ⾥的“记录”，再加上 QUIC 使⽤的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建⽴连接与密钥协商，甚⾄在第⼆次连接的时候，应⽤数据包可以和 QUIC 握⼿信息（连接信息 + TLS 信息）⼀起发送，达到 0-RTT 的效果。

但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，⽽是QUIC 内部包含了 TLS，它在⾃⼰的帧会携带 TLS ⾥的“记录”，再加上 QUIC 使⽤的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建⽴连接与密钥协商，甚⾄在第⼆次连接的时候，应⽤数据包可以和 QUIC 握⼿信息（连接信息 + TLS 信息）⼀起发送，达到 0-RTT 的效果。

如下图右边部分，HTTP/3 当会话恢复时，有效负载数据与第⼀个数据包⼀起发送，可以做到 0-RTT：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211206153445.png)


##### 连接迁移
在前⾯我们提到，基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端⼝、⽬的 IP、⽬的端⼝）确定⼀条 TCP 连接，那么当移动设备的⽹络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后 新建⽴连接，⽽建⽴连接的过程包含 TCP 三次握⼿和 TLS 四次握⼿的时延，以及 TCP 慢启动的减速过程，给⽤户的感觉就是⽹络突然卡顿了⼀下，因此连接的迁移成本是很⾼的。

⽽ QUIC 协议没有⽤四元组的⽅式来“绑定”连接，⽽是通过**连接ID**来标记通信的两个端点，客户端和服务器可以各⾃选择⼀组 ID 来标记⾃⼰，因此即使移动设备的⽹络变化后，导致 IP 地址变化了，只要仍保有上下⽂信息（⽐如连接 ID、TLS 密钥等），就可以“⽆缝”地复⽤原连接，消除 连的成本，没有丝毫卡顿感，达到了连接迁移的功能。


#### HTTP/3 协议
了解完 QUIC 协议的特点后，我们再来看看 HTTP/3 协议在 HTTP 这⼀层做了什么变化。

HTTP/3 同 HTTP/2 ⼀样采⽤⼆进制帧的结构，不同的地⽅在于 HTTP/2 的⼆进制帧⾥需要定义 Stream，⽽HTTP/3 ⾃身不需要再定义 Stream，直接使⽤ QUIC ⾥的 Stream，于是 HTTP/3 的帧的结构也变简单了。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211206155001.png)


从上图可以看到，HTTP/3 帧头只有两个字段：类型和⻓度。

根据帧类型的不同，⼤体上分为数据帧和控制帧两⼤类，HEADERS 帧（HTTP 头部）和 DATA 帧（HTTP 包体）属于数据帧。

HTTP/3 在头部压缩算法这⼀⽅便也做了升级，升级成了 QPACK。与 HTTP/2 中的 HPACK 编码⽅式相似，HTTP/3 中的 QPACK 也采⽤了静态表、动态表及 Huffman 编码。


对于静态表的变化，HTTP/2 中的 HPACK 的静态表只有 61 项，⽽ HTTP/3 中的 QPACK 的静态表扩⼤到 91 项。

HTTP/2 和 HTTP/3 的 Huffman 编码并没有多⼤不同，但是动态表编解码⽅式不同。

所谓的动态表，在⾸次请求-响应后，双⽅会将未包含在静态表中的 Header 项更新各⾃的动态表，接着后续传输时仅⽤ 1 个数字表示，然后对⽅可以根据这 1 个数字从动态表查到对应的数据，就不必每次都传输⻓⻓的数据，⼤⼤
提升了编码效率。

可以看到，动态表是具有时序性的，如果⾸次出现的请求发⽣了丢包，后续的收到请求，对⽅就⽆法解码出HPACK 头部，因为对⽅还没建⽴好动态表，因此后续的请求解码会阻塞到⾸次请求中丢失的数据包重传过来。


HTTP/3 的 QPACK 解决了这⼀问题，那它是如何解决的呢？

QUIC 会有两个特殊的单向流，所谓的单项流只有⼀端可以发送消息，双向则指两端都可以发送消息，传输 HTTP消息时⽤的是双向流，这两个单向流的⽤法：

- ⼀个叫 QPACK Encoder Stream， ⽤于将⼀个字典（key-value）传递给对⽅，⽐如⾯对不属于静态表的HTTP 请求头部，客户端可以通过这个 Stream 发送字典；

- ⼀个叫 QPACK Decoder Stream，⽤于响应对⽅，告诉它刚发的字典已经更新到⾃⼰的本地动态表了，后续就可以使⽤这个字典来编码了。


这两个特殊的单向流是⽤来**同步双⽅的动态表**，编码⽅收到解码⽅更新确认的通知后，才使⽤动态表编码 HTTP 头部。



### 总结
HTTP/2 虽然具有多个流并发传输的能⼒，但是传输层是 TCP 协议，于是存在以下缺陷：
- 队头阻塞，HTTP/2 多个请求跑在⼀个 TCP 连接中，如果序列号较低的 TCP 段在⽹络传输中丢失了，即使序列号较⾼的 TCP 段已经被接收了，应⽤层也⽆法从内核中读取到这部分数据，从 HTTP 视⻆看，就是多个请求被阻塞了；

- TCP 和 TLS 握⼿时延，TCL 三次握⼿和 TLS 四次握⼿，共有 3-RTT 的时延；

- 连接迁移需要重新连接，移动设备从 4G ⽹络环境切换到 WIFI 时，由于 TCP 是基于四元组来确认⼀条 TCP连接的，那么⽹络环境变化后，就会导致 IP 地址或端⼝变化，于是 TCP 只能断开连接，然后再 新建⽴连接，切换⽹络环境的成本⾼；

HTTP/3 就将传输层从 TCP 替换成了 UDP，并在 UDP 协议上开发了 QUIC 协议，来保证数据的可靠传输。

QUIC 协议的特点：

- ⽆队头阻塞，QUIC 连接上的多个 Stream 之间并没有依赖，都是独⽴的，也不会有底层协议限制，某个流发⽣丢包了，只会影响该流，其他流不受影响；

- 建⽴连接速度快，因为 QUIC 内部包含 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建⽴连接与 TLS 密钥协商，甚⾄在第⼆次连接的时候，应⽤数据包可以和 QUIC 握⼿信息（连接信息 + TLS 信息）⼀起发送，达到 0-RTT 的效果。

- 连接迁移，QUIC 协议没有⽤四元组的⽅式来“绑定”连接，⽽是通过「连接 ID 」来标记通信的两个端点，客户端和服务器可以各⾃选择⼀组 ID 来标记⾃⼰，因此即使移动设备的⽹络变化后，导致 IP 地址变化了，只要仍保有上下⽂信息（⽐如连接 ID、TLS 密钥等），就可以“⽆缝”地复⽤原连接，消除 连的成本；

另外 HTTP/3 的 QPACK 通过两个特殊的单向流来同步双⽅的动态表，解决了 HTTP/2 的 HPACK 队头阻塞问题。

期待，HTTP/3 正式推出的那⼀天！



# TCP篇
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211206161018.png)

### 3.1 TCP 头格式

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211206161759.png)

**序列号**：在建⽴连接时由计算机⽣成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送⼀次数据，就「累加」⼀次该「数据字节数」的⼤⼩。**⽤来解决⽹络包乱序问题**。


**确认应答号**：指下⼀次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。**⽤来解决不丢包的问题**。


**控制位**：
- ACK：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建⽴连接时的 SYN 包之外该位必
须设置为 1 。

- RST：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。

- SYN：该位为 1 时，表示希望建⽴连接，并在其「序列号」的字段进⾏序列号初始值的设定。

- FIN：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双⽅的
主机之间就可以相互交换 FIN 位为 1 的 TCP 段。



### 3.2 为什么需要 TCP 协议？ TCP ⼯作在哪⼀层？
IP 层是「不可靠」的，它不保证⽹络包的交付、不保证⽹络包的按序交付、也不保证⽹络包中的数据的完整性。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211207193322.png)


如果需要保障⽹络数据包的可靠性，那么就需要由上层（传输层）的 TCP 协议来负责。

因为 TCP 是⼀个⼯作在**传输层**的可靠数据传输的服务，它能确保接收端接收的⽹络包是 **⽆损坏、⽆间隔、⾮冗余和按序的**。

### 3.3 什么是TCP
TCP 是 **⾯向连接的**、**可靠的**、**基于字节流**的传输层通信协议。

- ⾯向连接：⼀定是「⼀对⼀」才能连接，不能像 UDP 协议可以⼀个主机同时向多个主机发送消息，也就是⼀对多是⽆法做到的；

- 可靠的：⽆论的⽹络链路中出现了怎样的链路变化，TCP 都可以保证⼀个报⽂⼀定能够到达接收端；


- 字节流：消息是「**没有边界**」的，所以⽆论我们消息有多⼤都可以进⾏传输。并且消息是「有序的」，当「前⼀个」消息没有收到的时候，即使它先收到了后⾯的字节，那么也不能扔给应⽤层去处理，同时对「 
复」的报⽂会⾃动丢弃。


### 3.4 什么是 TCP 连接？
简单来说就是，⽤于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket、序列号和窗⼝⼤⼩称为连接。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211207201818.png)



所以我们可以知道，建⽴⼀个 TCP 连接是需要客户端与服务器端达成上述三个信息的共识。

- Socket：由 IP 地址和端⼝号组成
- 序列号：⽤来解决乱序问题等
- 窗⼝⼤⼩：⽤来做流量控制


### 3.5 如何唯⼀确定⼀个 TCP 连接呢？
TCP 四元组可以唯⼀的确定⼀个连接，四元组包括如下：
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211207203647.png)

源地址和⽬的地址的字段（32位）是在 IP 头部中，作⽤是通过 IP 协议发送报⽂给对⽅主机。

源端⼝和⽬的端⼝的字段（16位）是在 TCP 头部中，作⽤是告诉 TCP 协议应该把报⽂发给哪个进程。


### 3.6 有⼀个 IP 的服务器监听了⼀个端⼝，它的 TCP 的最⼤连接数是多少？
服务器通常固定在某个本地端⼝上监听，等待客户端的连接请求。

因此，客户端 IP 和 端⼝是可变的，其理论值计算公式如下:
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211207205930.png)


对 IPv4，客户端的 IP 数最多为 2 的 32 次⽅，客户端的端⼝数最多为 2 的 16 次⽅，也就是服务端单机最⼤ TCP 连接数，约为 2 的 48 次⽅。


当然，服务端最⼤并发 TCP 连接数远不能达到理论上限。

- ⾸先主要是⽂件描述符限制，Socket 都是⽂件，所以⾸先要通过 ulimit 配置⽂件描述符的数⽬；
- 另⼀个是内存限制，每个 TCP 连接都要占⽤⼀定内存，操作系统的内存是有限的。

### 3.7 UDP 和 TCP 有什么区别呢？分别的应⽤场景是？
UDP 不提供复杂的控制机制，利⽤ IP 提供⾯向「⽆连接」的通信服务。

UDP 协议真的⾮常简单，头部只有 8 个字节（ 64 位），UDP 的头部格式如下：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211207212144.png)

- ⽬标和源端⼝：主要是告诉 UDP 协议应该把报⽂发给哪个进程。
- 包⻓度：该字段保存了 UDP ⾸部的⻓度跟数据的⻓度之和。
- 校验和：校验和是为了提供可靠的 UDP ⾸部和数据⽽设计。


#### TCP 和 UDP 区别：
##### 1. 连接
- TCP 是⾯向连接的传输层协议，传输数据前先要建⽴连接。
- UDP 是不需要连接，即刻传输数据。


##### 2. 服务对象
- TCP 是⼀对⼀的两点服务，即⼀条连接只有两个端点。
- UDP ⽀持⼀对⼀、⼀对多、多对多的交互通信


##### 3. 可靠性
- TCP 是可靠交付数据的，数据可以⽆差错、不丢失、不重复、按序到达。
- UDP 是尽最⼤努⼒交付，不保证可靠交付数据。


##### 4. 拥塞控制、流量控制
- TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。
- UDP 则没有，即使⽹络⾮常拥堵了，也不会影响 UDP 的发送速率。

##### 5. ⾸部开销
- TCP ⾸部⻓度较⻓，会有⼀定的开销，⾸部在没有使⽤「选项」字段时是 20 个字节，如果使⽤了「选项」字段则会变⻓的。
- UDP ⾸部只有 8 个字节，并且是固定不变的，开销较⼩。




##### 6. 传输⽅式
- TCP 是流式传输，没有边界，但保证顺序和可靠。
- UDP 是⼀个包⼀个包的发送，是有边界的，但可能会丢包和乱序。



##### 7. 分⽚不同
- TCP 的数据⼤⼩如果⼤于 MSS ⼤⼩，则会在传输层进⾏分⽚，⽬标主机收到后，也同样在传输层组装 TCP
数据包，如果中途丢失了⼀个分⽚，只需要传输丢失的这个分⽚。

- UDP 的数据⼤⼩如果⼤于 MTU ⼤⼩，则会在 IP 层进⾏分⽚，⽬标主机收到后，在 IP 层组装完数据，接着再传给传输层，但是如果中途丢了⼀个分⽚，在实现可靠传输的 UDP 时则就需要重传所有的数据包，这样传输效率⾮常差，所以通常 UDP 的报⽂应该⼩于 MTU。

### TCP 和 UDP 应⽤场景：
由于 TCP 是⾯向连接，能保证数据的可靠性交付，因此经常⽤于：

- FTP ⽂件传输
- HTTP / HTTPS

由于 UDP ⾯向⽆连接，它可以随时发送数据，再加上UDP本身的处理既简单⼜⾼效，因此经常⽤于：

- 包总量较少的通信，如 DNS 、 SNMP 等
- 视频、⾳频等多媒体通信
- ⼴播通信


### 3.8 为什么 UDP 头部没有「⾸部⻓度」字段，⽽ TCP 头部有「⾸部⻓度」字段呢？

原因是 TCP 有可变⻓的「选项」字段，⽽ UDP 头部⻓度则是不会变化的，⽆需多⼀个字段去记录 UDP 的⾸部⻓度。


###  3.9 为什么 UDP 头部有「包⻓度」字段，⽽ TCP 头部则没有「包⻓度」字段呢？
先说说 TCP 是如何计算负载数据⻓度：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211207220844.png)

其中 IP 总⻓度 和 IP ⾸部⻓度，在 IP ⾸部格式是已知的。TCP ⾸部⻓度，则是在 TCP ⾸部格式已知的，所以就可以求得 TCP 数据的⻓度。


⼤家这时就奇怪了问：“ UDP 也是基于 IP 层的呀，那 UDP 的数据⻓度也可以通过这个公式计算呀？ 为何还要有「包⻓度」呢？”

这么⼀问，确实感觉 UDP 「包⻓度」是冗余的。

因为为了⽹络设备硬件设计和处理⽅便，⾸部⻓度需要是 4 字节的整数倍。


### 3.10 TCP 三次握⼿过程和状态变迁

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211207223731.png)


-  ⼀开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端⼝，处于 LISTEN 状态

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211207224157.png)


- 客户端会随机初始化序号（ **client_isn** ），将此序号置于 TCP ⾸部的「序号」字段中，同时把 **SYN** 标志位置为 **1** ，表示 **SYN** 报⽂。接着把第⼀个 SYN 报⽂发送给服务端，表示向服务端发起连接，该报⽂不包含应⽤层数据，之后客户端处于 **SYN-SENT** 状态。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211208100858.png)

- 服务端收到客户端的 SYN 报⽂后，⾸先服务端也随机初始化⾃⼰的序号（ server_isn ），将此序号填⼊TCP ⾸部的「序号」字段中,其次把  client_isn + 1 填⼊TCP ⾸部的「确认应答号」字段中。
接着把 SYN和 ACK 标志位置为 1 。最后把该报⽂发给客户端，该报⽂也不包含应⽤层数据，之后服务端处于 SYN-RCVD 状态。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211208102524.png)


- 客户端收到服务端报⽂后，还要向服务端回应最后⼀个应答报⽂，⾸先该应答报⽂ TCP ⾸部 ACK 标志位
置为 1 ，其次「确认应答号」字段填⼊ server_isn + 1 ，最后把报⽂发送给服务端，这次报⽂可以携带客户到服务器的数据，之后客户端处于 ESTABLISHED 状态。


- 服务器收到客户端的应答报⽂后，也进⼊ ESTABLISHED 状态。

从上⾯的过程可以发现**第三次握⼿是可以携带数据的，前两次握⼿是不可以携带数据的**，这也是⾯试常问的题。

⼀旦完成三次握⼿，双⽅都处于 ESTABLISHED 状态，此时连接就已建⽴完成，客户端和服务端就可以相互发送数据了。



### 3.11 如何在 Linux 系统中查看 TCP 状态？
TCP 的连接状态查看，在 Linux 可以通过 netstat -napt 命令查看。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211208104358.png)


### 3.11 为什么是三次握⼿？不是两次、四次？
在前⾯我们知道了什么是 TCP 连接：

- ⽤于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket、序列号和窗⼝⼤⼩称为连接。


所以，重要的是为什么三次握⼿才可以初始化Socket、序列号和窗⼝⼤⼩并建⽴ TCP 连接。

接下来以三个⽅⾯分析三次握⼿的原因：

- 三次握⼿才可以阻⽌重复历史连接的初始化（主要原因）
- 三次握⼿才可以同步双⽅的初始序列号
- 三次握⼿才可以避免资源浪费

#### 原因⼀：避免历史连接

三次握⼿的⾸要原因是为了防⽌旧的重复连接初始化造成混乱。

⽹络环境是错综复杂的，往往并不是如我们期望的⼀样，先发送的数据包，就先到达⽬标主机，反⽽它很骚，可能会由于⽹络拥堵等乱七⼋糟的原因，会使得旧的数据包，先到达⽬标主机，那么这种情况下 TCP 三次握⼿是如何避免的呢？

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211208111957.png)


客户端连续发送多次 SYN 建⽴连接的报⽂，在⽹络拥堵情况下：

- ⼀个「旧 SYN 报⽂」⽐「最新的 SYN 」 报⽂早到达了服务端；
- 那么此时服务端就会回⼀个 SYN + ACK 报⽂给客户端；
- 客户端收到后可以根据⾃身的上下⽂，判断这是⼀个历史连接（序列号过期或超时），那么客户端就会发送RST 报⽂给服务端，表示中⽌这⼀次连接。

如果是两次握⼿连接，就不能判断当前连接是否是历史连接，三次握⼿则可以在客户端（发送⽅）准备发送第三次报⽂时，客户端因有⾜够的上下⽂来判断当前连接是否是历史连接：

- 如果是历史连接（序列号过期或超时），则第三次握⼿发送的报⽂是 RST 报⽂，以此中⽌历史连接；

- 如果不是历史连接，则第三次发送的报⽂是 ACK 报⽂，通信双⽅就会成功建⽴连接；

所以，TCP 使⽤三次握⼿建⽴连接的最主要原因是**防⽌历史连接初始化了连接**。


#### 原因⼆：同步双⽅初始序列号
TCP 协议的通信双⽅， 都必须维护⼀个「序列号」， 序列号是可靠传输的⼀个关键因素，它的作⽤：
- 接收⽅可以去除重复的数据；
- 接收⽅可以根据数据包的序列号按序接收；
- 可以标识发送出去的数据包中， 哪些是已经被对⽅收到的；

可⻅，序列号在 TCP 连接中占据着⾮常重要的作⽤，所以当客户端发送携带「初始序列号」的 SYN 报⽂的时候，需要服务端回⼀个 ACK 应答报⽂，表示客户端的 SYN 报⽂已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，这样⼀来⼀回，才能确保双⽅的初始序列号能被可靠的同步。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211208124703.png)


四次握⼿其实也能够可靠的同步双⽅的初始化序号，但由于第⼆步和第三步可以优化成⼀步，所以就成了「三次握⼿」。

⽽两次握⼿只保证了⼀⽅的初始序列号能被对⽅成功接收，没办法保证双⽅的初始序列号都能被确认接收。


#### 原因三：避免资源浪费
如果只有「两次握⼿」，当客户端的 SYN 请求连接在⽹络中阻塞，客户端没有接收到 ACK 报⽂，就会重新发送 SYN ，由于没有第三次握⼿，服务器不清楚客户端是否收到了⾃⼰发送的建⽴连接的 ACK 确认信号，所以每收到⼀个 SYN 就只能先主动建⽴⼀个连接，这会造成什么情况呢？

如果客户端的 SYN 阻塞了， 重复发送多次 SYN 报⽂，那么服务器在收到请求后就会建⽴多个冗余的⽆效链
接，造成不必要的资源浪费。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211208125601.png)

即两次握⼿会造成消息滞留情况下，服务器重复接受⽆⽤的连接请求 SYN 报⽂，⽽造成重复分配资源。


### 3.12 为什么是三次握⼿？不是两次、四次？
TCP 建⽴连接时，通过三次握⼿能**防⽌历史连接的建⽴**，能**减少双⽅不必要的资源开销**，能**帮助双⽅同步初始化序列号**。序列号能够保证数据包不重复、不丢弃和按序传输。

不使⽤「两次握⼿」和「四次握⼿」的原因：

- 「两次握⼿」：⽆法防⽌历史连接的建⽴，会造成双⽅资源的浪费，也⽆法可靠的同步双⽅序列号；
- 「四次握⼿」：三次握⼿就已经理论上最少可靠连接建⽴，所以不需要使⽤更多的通信次数。


### 3.13 为什么客户端和服务端的初始序列号 ISN 是不相同的？

如果⼀个已经失效的连接被重⽤了，但是该旧连接的历史报⽂还残留在⽹络中，如果序列号相同，那么就⽆法分辨出该报⽂是不是历史报⽂，如果历史报⽂被新的连接接收了，则会产⽣数据错乱。

所以，每次建⽴连接前重新初始化⼀个序列号主要是为了通信双⽅能够根据序号将不属于本连接的报⽂段丢弃。

另⼀⽅⾯是为了安全性，防⽌⿊客伪造的相同序列号的 TCP 报⽂被对⽅接收。


### 3.14 初始序列号 ISN 是如何随机产⽣的？
起始 ISN 是基于时钟的，每 4 毫秒 + 1，转⼀圈要 4.55 个⼩时。

RFC1948 中提出了⼀个较好的初始化序列号 ISN 随机⽣成算法。


- ISN = M + F (localhost, localport, remotehost, remoteport)

M 是⼀个计时器，这个计时器每隔 4 毫秒加 1。

F 是⼀个 Hash 算法，根据源 IP、⽬的 IP、源端⼝、⽬的端⼝⽣成⼀个随机数值。要保证 Hash 算法不能
被外部轻易推算得出，⽤ MD5 算法是⼀个⽐较好的选择。

### 3.15 既然 IP 层会分⽚，为什么 TCP 层还需要 MSS 呢？
我们先来认识下 MTU 和 MSS
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211208192751.png)

- MTU ：⼀个⽹络包的最⼤⻓度，以太⽹中⼀般为 1500 字节；
- MSS ：除去 IP 和 TCP 头部之后，⼀个⽹络包所能容纳的 TCP 数据的最⼤⻓度；

如果在 TCP 的整个报⽂（头部 + 数据）交给 IP 层进⾏分⽚，会有什么异常呢？

当 IP 层有⼀个超过 MTU ⼤⼩的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进⾏分⽚，把数据分⽚成若⼲⽚，保证每⼀个分⽚都⼩于 MTU。把⼀份 IP 数据报进⾏分⽚以后，由⽬标主机的 IP 层来进⾏ 重新组装后，再交给上⼀层 TCP 传输层。

这看起来井然有序，但这存在隐患的，那么当如果⼀个 IP 分⽚丢失，整个 IP 报⽂的所有分⽚都得重传。

因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。

当接收⽅发现 TCP 报⽂（头部 + 数据）的某⼀⽚丢失后，则不会响应 ACK 给对⽅，那么发送⽅的 TCP 在超时后，就会重发「整个 TCP 报⽂（头部 + 数据）」。

因此，可以得知由 IP 层进⾏分⽚传输，是⾮常没有效率的。


所以，为了达到最佳的传输效能 TCP 协议在建⽴连接的时候通常要协商双⽅的 MSS 值，当 TCP 层发现数据超过MSS 时，则就先会进⾏分⽚，当然由它形成的 IP 包的⻓度也就不会⼤于 MTU ，⾃然也就不⽤ IP 分⽚了。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211208221659.png)


经过 TCP 层分⽚后，如果⼀个 TCP 分⽚丢失后，**进⾏重发时也是以 MSS 为单位**，⽽不⽤重传所有的分⽚，⼤⼤增加了重传的效率。



### 3.16 什么是 SYN 攻击？如何避免 SYN 攻击？

#### SYN 攻击
我们都知道 TCP 连接建⽴是需要三次握⼿，假设攻击者短时间伪造不同 IP 地址的 SYN 报⽂，服务端每接收到⼀个 SYN 报⽂，就进⼊ SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报⽂，⽆法得到未知 IP 主机的ACK 应答，久⽽久之就会占满服务端的 SYN 接收队列（未连接队列），使得服务器不能为正常⽤户服务。



#### 避免 SYN 攻击⽅式⼀
其中⼀种解决⽅式是通过修改 Linux 内核参数，控制队列⼤⼩和当队列满时应做什么处理。

- 当⽹卡接收数据包的速度⼤于内核处理的速度时，会有⼀个队列保存这些数据包。控制该队列的最⼤值如下参数：
net.core.netdev_max_backlog

- SYN_RCVD 状态连接的最⼤个数：
net.ipv4.tcp_max_syn_backlog

- 超出处理能力时，对新的 SYN 直接回复 RST，丢弃连接：
net.ipv4.tcp_abort_on_overflow




#### 避免 SYN 攻击⽅式二
我们先来看下 Linux 内核的 SYN （未完成连接建⽴）队列与 Accpet （已完成连接建⽴）队列是如何⼯作的？

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209122108.png)


##### 正常流程：
- 当服务端接收到客户端的 SYN 报⽂时，会将其加⼊到内核的「 SYN 队列」；
- 接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报⽂；
- 服务端接收到 ACK 报⽂后，从「 SYN 队列」移除放⼊到「 Accept 队列」；
- 应⽤通过调⽤ accpet() socket 接⼝，从「 Accept 队列」取出连接。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209122448.png)


##### 应⽤程序过慢：
- 如果应⽤程序过慢时，就会导致「 Accept 队列」被占满。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209122909.png)


##### 受到 SYN 攻击：
- 如果不断受到 SYN 攻击，就会导致「 SYN 队列」被占满。

tcp_syncookies 的⽅式可以应对 SYN 攻击的⽅法：
net.ipv4.tcp_syncookies = 1

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209123310.png)

- 当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进⼊「 SYN 队列」；

- 计算出⼀个 cookie 值，再以 SYN + ACK 中的「序列号」返回客户端，

- 服务端接收到客户端的应答报⽂时，服务器会检查这个 ACK 包的合法性。如果合法，直接放⼊到「 Accept队列」。


- 最后应⽤通过调⽤ accpet() socket 接⼝，从「 Accept 队列」取出的连接。


### 3.17 TCP 四次挥⼿过程和状态变迁

双⽅都可以主动断开连接，断开连接后主机中的「资源」将被释放。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209125340.png)


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209125507.png)

这⾥⼀点需要注意是：主动关闭连接的，才有 TIME_WAIT 状态。



### 3.18 为什么挥⼿需要四次？

- 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。

- 服务器收到客户端的 FIN 报⽂时，先回⼀个 ACK 应答报⽂，⽽服务端可能还有数据需要处理和发送，等
服务端不再发送数据时，才发送 FIN 报⽂给客户端来表示同意现在关闭连接。

从上⾯过程可知，**服务端通常需要等待完成数据的发送和处理**，所以服务端的 ACK 和 FIN ⼀般都会分开发送，从⽽⽐三次握⼿导致多了⼀次。


### 3.19 为什么 TIME_WAIT 等待的时间是 2MSL？

MSL 是 Maximum Segment Lifetime，**报⽂最⼤⽣存时间**，它是任何报⽂在⽹络上存在的最⻓时间，超过这个时间报⽂将被丢弃。

因为 TCP 报⽂基于是 IP 协议的，⽽ IP 头中有⼀个 **TTL** 字段，是 IP 数据报可以经过的最⼤路
由数，每经过⼀个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报⽂通知源主机。

MSL 与 TTL 的区别： MSL 的单位是时间，⽽ TTL 是经过路由跳数。所以 MSL 应该要⼤于等于 TTL 消耗为 0 的时间，以确保报⽂已被⾃然消亡。

TIME_WAIT 等待 2 倍的 MSL，⽐较合理的解释是： ⽹络中可能存在来⾃发送⽅的数据包，当这些发送⽅的数据包被接收⽅处理后⼜会向对⽅发送响应，所以 **⼀去⼀回需要等待 2 倍的时间**。


⽐如如果被动关闭⽅没有收到断开连接的最后的 ACK 报⽂，就会触发超时 发 Fin 报⽂，另⼀⽅接收到 FIN 后，会重发 ACK 给被动关闭⽅， ⼀来⼀去正好 2 个 MSL。

2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK没有传输到服务端，客户端⼜接收到了服务端重发的 FIN 报⽂，那么 2MSL 时间将重新计时。

在 Linux 系统⾥ 2MSL 默认是 60 秒，那么⼀个 MSL 也就是 30 秒。Linux 系统停留在 TIME_WAIT 的时
间为固定的 60 秒。


其定义在 Linux 内核代码⾥的名称为 TCP_TIMEWAIT_LEN：

- #define TCP_TIMEWAIT_LEN (60*HZ) /* how long to wait to destroy TIME-WAIT state, about 60 seconds */

如果要修改 TIME_WAIT 的时间⻓度，只能修改 Linux 内核代码⾥ TCP_TIMEWAIT_LEN 的值，并 新编译 Linux内核。



### 3.20 为什么需要 TIME_WAIT 状态？
主动发起关闭连接的⼀⽅，才会有 TIME-WAIT 状态。

需要 TIME-WAIT 状态，主要是两个原因：
- 防⽌具有相同「四元组」的「旧」数据包被收到；
- 保证「被动关闭连接」的⼀⽅能被正确的关闭，即保证最后的 ACK 能让被动关闭⽅接收，从⽽帮助其正常关闭；

#### 原因⼀：防⽌旧连接的数据包
假设 TIME-WAIT 没有等待时间或时间过短，被延迟的数据包抵达后会发⽣什么呢？

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209133055.png)

- 如上图⻩⾊框框服务端在关闭连接之前发送的 SEQ = 301 报⽂，被⽹络延迟了。

- 这时有相同端⼝的 TCP 连接被复⽤后，被延迟的 SEQ = 301 抵达了客户端，那么客户端是有可能正常接收这个过期的报⽂，这就会产⽣数据错乱等严 的问题。


所以，TCP 就设计出了这么⼀个机制，经过 2MSL 这个时间，⾜以让两个⽅向上的数据包都被丢弃，使得原来连接的数据包在⽹络中都⾃然消失，再出现的数据包⼀定都是新建⽴连接所产⽣的。

#### 原因⼆：保证连接正确关闭
TIME-WAIT 作⽤是等待⾜够的时间以**确保最后的 ACK 能让被动关闭⽅接收，从⽽帮助其正常关闭**。

假设 TIME-WAIT 没有等待时间或时间过短，断开连接会造成什么问题呢？

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209134441.png)

- 如上图红⾊框框客户端四次挥⼿的最后⼀个 ACK 报⽂如果在⽹络中被丢失了，此时如果客户端 TIME-
WAIT 过短或没有，则就直接进⼊了 CLOSED 状态了，那么服务端则会⼀直处在 LASE_ACK 状态。

- 当客户端发起建⽴连接的 SYN 请求报⽂后，服务端会发送 RST 报⽂给客户端，连接建⽴的过程就会被
终⽌。

如果 TIME-WAIT 等待⾜够⻓的情况就会遇到两种情况：
- 服务端正常收到四次挥⼿的最后⼀个 ACK 报⽂，则服务端正常关闭连接。

- 服务端没有收到四次挥⼿的最后⼀个 ACK 报⽂时，则会 发 FIN 关闭连接报⽂并等待新的 ACK 报
⽂。

所以客户端在 TIME-WAIT 状态等待 2MSL 时间后，就可以保证双⽅的连接都可以正常的关闭。


### 3.21 TIME_WAIT 过多有什么危害？

如果服务器有处于 TIME-WAIT 状态的 TCP，则说明是由服务器⽅主动发起的断开请求。

过多的 TIME-WAIT 状态主要的危害有两种：

- 第⼀是内存资源占⽤；
- 第⼆是对端⼝资源的占⽤，⼀个 TCP 连接⾄少消耗⼀个本地端⼝；

第⼆个危害是会造成严 的后果的，要知道，端⼝资源也是有限的，⼀般可以开启的端⼝为 32768～61000 ，也可以通过如下参数设置指定net.ipv4.ip_local_port_range

**如果发起连接⼀⽅的 TIME_WAIT 状态过多，占满了所有端⼝资源，则会导致⽆法创建新连接。**


客户端受端⼝资源限制：
- 客户端TIME_WAIT过多，就会导致端⼝资源被占⽤，因为端⼝就65536个，被占满就会导致⽆法创建新的连
接。

服务端受系统资源限制：
- 由于⼀个四元组表示 TCP 连接，理论上服务端可以建⽴很多连接，服务端确实只监听⼀个端⼝ 但是会把连接扔给处理线程，所以理论上监听的端⼝可以继续监听。但是线程池处理不了那么多⼀直不断的连接了。所以当服务端出现⼤  TIME_WAIT 时，系统资源被占满时，会导致处理不过来新的连接。

### 3.22 如何优化 TIME_WAIT？
这⾥给出优化 TIME-WAIT 的⼏个⽅式，都是有利有弊：

- 方式一 ：打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项；

如下的 Linux 内核参数开启后，则可以**复⽤处于 TIME_WAIT 的 socket 为新的连接所⽤**。

有⼀点需要注意的是，**tcp_tw_reuse 功能只能⽤客户端（连接发起⽅），因为开启了该功能，在调⽤ connect()函数时，内核会随机找⼀个 time_wait 状态超过 1 秒的连接给新的连接复⽤。**

net.ipv4.tcp_tw_reuse = 1


使⽤这个选项，还有⼀个前提，需要打开对 TCP 时间戳的⽀持，即

net.ipv4.tcp_timestamps=1（默认即为 1）


这个时间戳的字段是在 TCP 头部的「选项」⾥，⽤于记录 TCP 发送⽅的当前时间戳和从对端接收到的最新时间戳。

由于引⼊了时间戳，我们在前⾯提到的 2MSL 问题就不复存在了，因为重复的数据包会因为时间戳过期被⾃然丢弃。

- 方式二：net.ipv4.tcp_max_tw_buckets

这个值默认为 18000，当系统中处于 TIME_WAIT 的连接⼀旦超过这个值时，系统就会将后⾯的 TIME_WAIT 连接状态重置。

这个⽅法过于暴⼒，⽽且治标不治本，带来的问题远⽐解决的问题多，不推荐使⽤。



- 方式三：程序中使⽤ SO_LINGER ，应⽤强制使⽤ RST 关闭。

我们可以通过设置 socket 选项，来设置调⽤ close 关闭连接⾏为。

```cpp
struct linger so_linger;
so_linger.l_onoff = 1;
so_linger.l_linger = 0;
setsockopt(s, SOL_SOCKET, SO_LINGER, &so_linger,sizeof(so_linger));
```
如果 l_onoff 为⾮ 0， 且 l_linger 值为 0，那么调⽤ close 后，会⽴该发送⼀个 RST 标志给对端，该 TCP 连接将跳过四次挥⼿，也就跳过了 TIME_WAIT 状态，直接关闭。

但这为跨越 TIME_WAIT 状态提供了⼀个可能，不过是⼀个⾮常危险的⾏为，不值得提倡。



### 3.23 如果已经建⽴了连接，但是客户端突然出现故障了怎么办？

TCP 有⼀个机制是**保活机制**。这个机制的原理是这样的：

定义⼀个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作⽤，每隔⼀个时间间隔，发送⼀个探测报⽂，该探测报⽂包含的数据⾮常少，如果连续⼏个探测报⽂都没有得到响应，则认为当前的TCP 连接已经死亡，系统内核将错误信息通知给上层应⽤程序。

在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：
```cpp
net.ipv4.tcp_keepalive_time=7200
net.ipv4.tcp_keepalive_intvl=75 
net.ipv4.tcp_keepalive_probes=9
```
- tcp_keepalive_time=7200：表示保活时间是 7200 秒（2⼩时），也就 2 ⼩时内如果没有任何连接相关的活动，则会启动保活机制.

- tcp_keepalive_intvl=75：表示每次检测间隔 75 秒；

- tcp_keepalive_probes=9：表示检测 9 次⽆响应，认为对⽅是不可达的，从⽽中断本次的连接。


也就是说在 Linux 系统中，最少需要经过 2 ⼩时 11 分 15 秒才可以发现⼀个「死亡」连接。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209152415.png)

这个时间是有点⻓的，我们也可以根据实际的需求，对以上的保活相关的参数进⾏设置。

如果开启了 TCP 保活，需要考虑以下⼏种情况：

第⼀种，对端程序是正常⼯作的。当 TCP 保活的探测报⽂发送给对端, 对端会正常响应，这样 TCP 保活时间会被重置，等待下⼀个 TCP 保活时间的到来。


第⼆种，对端程序崩溃并重启。当 TCP 保活的探测报⽂发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，会产⽣⼀个 RST 报⽂，这样很快就会发现 TCP 连接已经被重置。

第三种，是对端程序崩溃，或对端由于其他原因导致报⽂不可达。当 TCP 保活的探测报⽂发送给对端后，⽯沉⼤海，没有响应，连续⼏次，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。


### 3.24 针对TCP应该如何Socket编程？

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209152928.png)


- 服务端和客户端初始化 socket ，得到⽂件描述符；

- 服务端调⽤ bind ，将绑定在 IP 地址和端⼝;

- 服务端调⽤ listen ，进⾏监听；

- 服务端调⽤ accept ，等待客户端连接；

- 客户端调⽤ connect ，向服务器端的地址和端⼝发起连接请求；

- 服务端 accept 返回⽤于传输的 socket 的⽂件描述符；

- 客户端调⽤ write 写⼊数据；服务端调⽤ read 读取数据；

- 客户端断开连接时，会调⽤ close ，那么服务端 read 读取数据的时候，就会读取到了 EOF ，待处理完
数据后，服务端调⽤ close ，表示连接关闭。


这⾥需要注意的是，服务端调⽤ accept 时，连接成功了会返回⼀个已完成连接的 socket，后续⽤来传输数据。

所以，监听的 socket 和真正⽤来传送数据的 socket，是「两个」 socket，⼀个叫作监听 socket，⼀个叫作已完成连接 socket。


成功连接建⽴之后，双⽅开始通过 read 和 write 函数来读写数据，就像往⼀个⽂件流⾥⾯写东⻄⼀样。

### 3.25 listen 时候参数 backlog 的意义？
Linux内核中会维护两个队列：

- 未完成连接队列（SYN 队列）：接收到⼀个 SYN 建⽴连接请求，处于 SYN_RCVD 状态；
- 已完成连接队列（Accpet 队列）：已完成 TCP 三次握⼿过程，处于 ESTABLISHED 状态；

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209155408.png)


```cpp
int listen (int socketfd, int backlog)
```

- 参数⼀ socketfd 为 socketfd ⽂件描述符
- 参数⼆ backlog，这参数在历史版本有⼀定的变化


在早期 Linux 内核 backlog 是 SYN 队列⼤⼩，也就是未完成的队列⼤⼩。


在 Linux 内核 2.2 之后，backlog 变成 accept 队列，也就是已完成连接建⽴的队列⻓度，所以现在通常认为**backlog 是 accept 队列。**

**但是上限值是内核参数 somaxconn 的⼤⼩，也就说 accpet 队列⻓度 = min(backlog, somaxconn)。**


### 3.26 accept 发⽣在三次握⼿的哪⼀步？

我们先看看客户端连接服务端时，发送了什么？
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209160100.png)

- 客户端的协议栈向服务器端发送了 SYN 包，并告诉服务器端当前发送序列号 client_isn，客户端进⼊
SYN_SENT 状态；


- 服务器端的协议栈收到这个包之后，和客户端进⾏ ACK 应答，应答的值为 client_isn+1，表示对 SYN 包client_isn 的确认，同时服务器也发送⼀个 SYN 包，告诉客户端当前我的发送序列号为 server_isn，服务器端进⼊ SYN_RCVD 状态；


- 客户端协议栈收到 ACK 之后，使得应⽤程序从 connect 调⽤返回，表示客户端到服务器端的单向连接建⽴成功，客户端的状态为 ESTABLISHED，同时客户端协议栈也会对服务器端的 SYN 包进⾏应答，应答数据为
server_isn+1；


- 应答包到达服务器端后，服务器端协议栈使得 accept 阻塞调⽤返回，这个时候服务器端到客户端的单向连接也建⽴成功，服务器端也进⼊ ESTABLISHED 状态。


**从上⾯的描述过程，我们可以得知客户端 connect 成功返回是在第⼆次握⼿，服务端 accept 成功返回是在三次握⼿成功之后。**



### 3.27 客户端调⽤ close 了，连接是断开的流程是什么？
我们看看客户端主动调⽤了 close ，会发⽣什么？

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209162019.png)


- 客户端调⽤ close ，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报⽂，进⼊ FIN_WAIT_1状态；

- 服务端接收到了 FIN 报⽂，TCP 协议栈会为 FIN 包插⼊⼀个⽂件结束符 EOF 到接收缓冲区中，应⽤程序可以通过 read 调⽤来感知这个 FIN 包。这个 EOF 会被放在已排队等候的其他已接收的数据之后，这就
意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再⽆额外数据到达。此时，服务端进⼊
CLOSE_WAIT 状态；

- 接着，当处理完数据后，⾃然就会读到 EOF ，于是也调⽤ close 关闭它的套接字，这会使得客户端会发
出⼀个 FIN 包，之后处于 LAST_ACK 状态；

- 客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进⼊ TIME_WAIT 状态；

- 服务端收到 ACK 确认包后，就进⼊了最后的 CLOSE 状态；

- 客户端经过 2MSL 时间之后，也进⼊ CLOSE 状态；

### 3.28 为了⽅便调试服务器程序，⼀般会在服务端设置 SO_REUSEADDR 选项，这样服务器程序在启后，可以⽴刻使⽤。这⾥设置SO_REUSEADDR 是不是就等价于对这个 socket 设置了内核中的net.ipv4.tcp_tw_reuse=1 这个选项？”

这两个东⻄没有关系的哦。

- 1. tcp_tw_reuse 是内核选项，主要⽤在连接的发起⽅（客户端）。TIME_WAIT 状态的连接创建时间超过 1 秒后，新的连接才可以被复⽤，注意，这⾥是「连接的发起⽅」；


- 2. SO_REUSEADDR 是⽤户态的选项，⽤于「连接的服务⽅」，⽤来告诉操作系统内核，如果端⼝已被占⽤，但是 TCP 连接状态位于 TIME_WAIT ，可以重⽤端⼝。如果端⼝忙，⽽ TCP 处于其他状态， 重⽤会有
“Address already in use” 的错误信息。


tcp_tw_reuse 是为了缩短 time_wait 的时间，避免出现⼤量的 time_wait 连接⽽占⽤系统资源，解决的是 accept后的问题。


SO_REUSEADDR 是为了解决 time_wait 状态带来的端⼝占⽤问题，以及⽀持同⼀个 port 对应多个 ip，解决的是bind 时的问题。


### 3.29 如果客户端第四次挥⼿ack丢失，服务端超时重发的fin报⽂也丢失，客户端timewait时间超过了2msl，这个时候会发⽣什么？认为连接已经关闭吗？”

当客户端 timewait 时间超过了 2MSL，则客户端就直接进⼊关闭状态。

服务端超时重发 fin 报⽂的次数如果超过 tcp_orphan_retries ⼤⼩后，服务端也会关闭 TCP 连接。


### 3.30  ⽂章在解释IP分⽚和TCP MSS分⽚时说，如果⽤IP分⽚会有两个问题：（1）IP按MTU分⽚，如果某⼀⽚丢失则需要所有分⽚都重传；（2）IP没有重传机制，所以需要等TCP发送⽅超时才能重传；问题⼀：MSS跟IP的MTU分⽚相⽐，只是多了⼀步协商MSS值的过程，⽽IP的MTU可以看作是默认协商好就是1500字节，所以为什么协商后的MSS可以做到丢失后只发丢失的这⼀⽚来提⾼效率，⽽默认协商好1500字节的IP分⽚就需要所有⽚都重传呢？问题⼆：TCP MSS分⽚如果丢失了⼀⽚，是不是也需要发送⽅等待超时再重传？如果不是，MSS的协商如何能在超时前就直到丢了分⽚从⽽提⾼效率的呢？

问题⼀：

如果⼀个⼤的 TCP 报⽂是被 MTU 分⽚，那么只有「第⼀个分⽚」才具有 TCP 头部，后⾯的分⽚则没有
TCP 头部，接收⽅ IP 层只有重组了这些分⽚，才会认为是⼀个 TCP 报⽂，那么丢失了其中⼀个分⽚，接收
⽅ IP 层就不会把 TCP 报⽂丢给 TCP 层，那么就会等待对⽅超时重传这⼀整个 TCP 报⽂。

如果⼀个⼤的 TCP 报⽂被 MSS 分⽚，那么所有「分⽚都具有 TCP 头部」，因为每个 MSS 分⽚的是具有
TCP 头部的TCP报⽂，那么其中⼀个 MSS 分⽚丢失，就只需要重传这⼀个分⽚就可以。

问题⼆：

TCP MSS分⽚如果丢失了⼀⽚，发送⽅没收到对⽅ACK应答，也是会触发超时重传的，因为TCP层是会保证
数据的可靠交付。




### 3.31 如果是服务提供⽅发起的 close ，然后引起过多的 time_wait 状态的 tcp 链接，time_wait 会影响服务端的端⼝吗？

不会。如果发起连接⼀⽅（客户端）的 TIME_WAIT 状态过多，占满了所有端⼝资源，则会导致⽆法创建新连接

客户端受端⼝资源限制：

- 客户端TIME_WAIT过多，就会导致端⼝资源被占⽤，因为端⼝就65536个，被占满就会导致⽆法创建新连
接。

服务端受系统资源限制：

- 由于⼀个 TCP 四元组表示 TCP 连接，理论上服务端可以建⽴很多连接，服务端只监听⼀个端⼝，但是会把连接扔给处理线程，所以理论上监听的端⼝可以继续监听。但是线程池处理不了那么多⼀直不断的连接了。所以当服务端出现⼤量 TIMEWAIT 时，系统资源容易被耗尽。




![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209182013.png)


### 3.32 重传机制

TCP 实现可靠传输的⽅式之⼀，是通过序列号与确认应答。


在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回⼀个**确认应答消息，表示已收到消息。**

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209204507.png)

但在错综复杂的⽹络，并不⼀定能如上图那么顺利能正常的数据传输，万⼀数据在传输过程中丢失了呢？

所以 TCP 针对数据包丢失的情况，会⽤**重传机制**解决。

接下来说说常⻅的重传机制：

- 超时重传
- 快速重传
- SACK
- D-SACK

#### 超时重传

重传机制的其中⼀个⽅式，就是在发送数据时，设定⼀个定时器，当超过指定的时间后，没有收到对⽅的 ACK确认应答报⽂，就会重发该数据，也就是我们常说的超时重传。

TCP 会在以下两种情况发⽣超时重传：

- 数据包丢失
- 确认应答丢失

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209212628.png)

>超时时间应该设置为多少呢？</font>。

我们先来了解⼀下什么是 RTT （Round-Trip Time 往返时延），从下图我们就可以知道：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209213710.png)

RTT 就是**数据从⽹络⼀端传送到另⼀端所需的时间，也就是包的往返时间。**

超时重传时间是以 RTO （Retransmission Timeout 超时重传时间）表示。

假设在重传的情况下，超时时间 RTO 「较⻓或较短」时，会发⽣什么事情呢？

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209214106.png)

上图中有两种超时时间不同的情况：

- 当超时时间 RTO 较⼤时，重发就慢，丢了⽼半天才重发，没有效率，性能差；
- 当超时时间 RTO 较⼩时，会导致可能并没有丢就重发，于是重发的就快，会增加⽹络拥塞，导致更多的超
时，更多的超时导致更多的重发。


精确的测量超时时间 RTO 的值是⾮常重要的，这可让我们的重传机制更⾼效。
根据上述的两种情况，我们可以得知，超时重传时间 RTO 的值应该略⼤于报⽂往返 RTT 的值。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209214832.png)

⾄此，可能⼤家觉得超时重传时间 RTO 的值计算，也不是很复杂嘛。


好像就是在发送端发包时记下 t0 ，然后接收端再把这个 ack 回来时再记⼀个 t1 ，于是 RTT = t1 – t0 。没那么简单，这只是⼀个采样，不能代表普遍情况。

实际上「报⽂往返 RTT 的值」是经常变化的，因为我们的⽹络也是时常变化的。也就因为「报⽂往返 RTT 的值」是经常波动变化的，所以「超时重传时间 RTO 的值」应该是⼀个动态变化的值。

我们来看看 Linux 是如何计算 RTO 的呢？

估计往返时间，通常需要采样以下两个：

- 需要 TCP 通过采样 RTT 的时间，然后进⾏加权平均，算出⼀个平滑 RTT 的值，⽽且这个值还是要不断变化的，因为⽹络状况不断地变化。

- 除了采样 RTT，还要采样 RTT 的波动范围，这样就避免如果 RTT 有⼀个⼤的波动的话，很难被发现的情况。


RFC6289 建议使⽤以下的公式计算 RTO：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209220900.png)


其中 SRTT 是计算平滑的RTT ， DevRTR 是计算平滑的RTT 与 最新 RTT 的差距。

在 Linux 下，α = 0.125，β = 0.25， μ = 1，∂ = 4。别问怎么来的，问就是⼤量实验中调出来的。

如果超时重发的数据，再次超时的时候，⼜需要重传的时候，TCP 的策略是超时间隔加倍。

也就是每当遇到⼀次超时重传的时候，都会将下⼀次超时时间间隔设为先前值的两倍。两次超时，就说明⽹络环境差，不宜频繁反复发送。

超时触发重传存在的问题是，超时周期可能相对较⻓。那是不是可以有更快的⽅式呢？

于是就可以⽤「快速重传」机制来解决超时重发的时间等待。



#### 快速重传
TCP 还有另外⼀种快速重传（Fast Retransmit）机制，它不以时间为驱动，⽽是以数据驱动重传。

快速重传机制，是如何⼯作的呢？其实很简单，⼀图胜千⾔。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209222157.png)


在上图，发送⽅发出了 1，2，3，4，5 份数据：


- 第⼀份 Seq1 先送到了，于是就 Ack 回 2；

- 结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2；

- 后⾯的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到；

- 发送端收到了三个 Ack = 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。

- 最后，收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。


所以，快速重传的⼯作⽅式是当收到三个相同的 ACK 报⽂时，会在定时器过期之前，重传丢失的报⽂段。

快速重传机制只解决了⼀个问题，就是超时时间的问题，但是它依然⾯临着另外⼀个问题。就是重传的时候，是重传之前的⼀个，还是重传所有的问题。


⽐如对于上⾯的例⼦，是重传 Seq2 呢？还是重传 Seq2、Seq3、Seq4、Seq5 呢？因为发送端并不清楚这连续的三个 Ack 2 是谁传回来的。


根据 TCP 不同的实现，以上两种情况都是有可能的。可⻅，这是⼀把双刃剑。


为了解决不知道该重传哪些 TCP 报⽂，于是就有 SACK ⽅法。



#### SACK ⽅法

还有⼀种实现重传机制的⽅式叫： SACK （ Selective Acknowledgment 选择性确认）。


这种⽅式需要在 TCP 头部「选项」字段⾥加⼀个 **SACK** 的东⻄，它可以**将缓存的地图**发送给发送⽅，这样发送⽅就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据。

如下图，发送⽅收到了三次同样的 ACK 确认报⽂，于是就会触发快速重发机制，通过 SACK 信息发现只有
200~299 这段数据丢失，则重发时，就只选择了这个 TCP 段进⾏重发。





![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209223723.png)


如果要⽀持 SACK ，必须双⽅都要⽀持。在 Linux 下，可以通过 net.ipv4.tcp_sack 参数打开这个功能（Linux2.4 后默认打开）。

#### Duplicate SACK
Duplicate SACK ⼜称 D-SACK ，其主要使⽤了 SACK 来告诉「发送⽅」有哪些数据被重复接收了。

下⾯举例两个栗⼦，来说明 D-SACK 的作⽤。
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209224547.png)


- 「接收⽅」发给「发送⽅」的两个 ACK 确认应答都丢失了，所以发送⽅超时后，重传第⼀个数据包（3000 ~3499）

- 于是「接收⽅」发现数据是重复收到的，于是回了⼀个 SACK = 3000~3500，告诉「发送⽅」 3000~3500
的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个
SACK 就代表着 D-SACK 。


- 这样「发送⽅」就知道了，数据没有丢，是「接收⽅」的 ACK 确认报⽂丢了。

栗⼦⼆号：⽹络延时

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211209224744.png)


- 数据包（1000~1499） 被⽹络延迟了，导致「发送⽅」没有收到 Ack 1500 的确认报⽂。


- ⽽后⾯报⽂到达的三个相同的 ACK 确认报⽂，就触发了快速 传机制，但是在 传后，被延迟的数据包
（1000~1499）⼜到了「接收⽅」；


- 所以「接收⽅」回了⼀个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表
示收到了重复的包。


- 这样发送⽅就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，⽽是因为⽹络延迟了。


可⻅， D-SACK 有这么⼏个好处：

1. 可以让「发送⽅」知道，是发出去的包丢了，还是接收⽅回应的 ACK 包丢了;
2. 可以知道是不是「发送⽅」的数据包被⽹络延迟了;
3. 可以知道⽹络中是不是把「发送⽅」的数据包给复制了;

在 Linux 下可以通过 net.ipv4.tcp_dsack 参数开启/关闭这个功能（Linux 2.4 后默认打开）。


### 3.33 滑动窗⼝

我们都知道 TCP 是每发送⼀个数据，都要进⾏⼀次确认应答。当上⼀个数据包收到了应答了， 再发送下⼀个。但这种⽅式的缺点是效率⽐较低。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211210172757.png)

所以，这样的传输⽅式有⼀个缺点：**数据包的往返时间越⻓，通信的效率就越低。**

为解决这个问题，TCP 引⼊了**窗⼝**这个概念。即使在往返时间较⻓的情况下，它也不会降低⽹络通信的效率。


那么有了窗⼝，就可以指定窗⼝⼤⼩，窗⼝⼤⼩就是指 **⽆需等待确认应答，⽽可以继续发送数据的最⼤值**

窗⼝的实现实际上是操作系统开辟的⼀个缓存空间，发送⽅主机在等待确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。

假设窗⼝⼤⼩为 3 个 TCP 段，那么发送⽅就可以「连续发送」 3 个 TCP 段，并且中途若有 ACK 丢失，可以通过「下⼀个确认应答进⾏确认」。如下图：



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211210174319.png)


图中的 ACK 600 确认应答报⽂丢失，也没关系，因为可以通过下⼀个确认应答进⾏确认，只要发送⽅收到了 ACK 700 确认应答，就意味着 700 之前的所有数据「接收⽅」都收到了。这个模式就叫**累计确认**或者**累计应答**。

### 3.34 窗⼝⼤⼩由哪⼀⽅决定？
TCP 头⾥有⼀个字段叫 Window ，也就是窗⼝⼤⼩。

这个字段是接收端告诉发送端⾃⼰还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能⼒来发送数据，⽽不会导致接收端处理不过来。

所以，通常窗⼝的⼤⼩是由**接收⽅的窗⼝⼤⼩**来决定的。

发送⽅发送的数据⼤⼩不能超过接收⽅的窗⼝⼤⼩，否则接收⽅就⽆法正常接收到数据。

### 3.35 发送⽅的滑动窗⼝

我们先来看看发送⽅的窗⼝，下图就是发送⽅缓存的数据，根据处理的情况分成四个部分，其中深蓝⾊⽅框是发送窗⼝，紫⾊⽅框是可⽤窗⼝：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211210180650.png)

- #1 是已发送并收到 ACK确认的数据：1~31 字节

- #2 是已发送但未收到 ACK确认的数据：32~45 字节

- #3 是未发送但总⼤⼩在接收⽅处理范围内（接收⽅还有空间）：46~51字节

- #4 是未发送但总⼤⼩超过接收⽅处理范围（接收⽅没有空间）：52字节以后


在下图，当发送⽅把数据「全部」都⼀下发送出去后，可⽤窗⼝的⼤⼩就为 0 了，表明可⽤窗⼝耗尽，在没收到ACK 确认之前是⽆法继续发送数据了。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211210182122.png)


在下图，当收到之前发送的数据 32~36 字节的 ACK 确认应答后，如果发送窗⼝的⼤⼩没有变化，则**滑动窗⼝往右边移动 5 个字节，因为有 5 个字节的数据被应答确认**，接下来 52~56 字节⼜变成了可⽤窗⼝，那么后续也就可以发送 52~56 这 5 个字节的数据了。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211210182949.png)


### 3.36 程序是如何表示发送⽅的四个部分的呢？

TCP 滑动窗⼝⽅案使⽤三个指针来跟踪在四个传输类别中的每⼀个类别中的字节。其中两个指针是绝对指针（指特定的序列号），⼀个是相对指针（需要做偏移）。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211210183536.png)


- SND.WND ：表示发送窗⼝的⼤⼩（⼤⼩是由接收⽅指定的）；

- SND.UNA ：是⼀个绝对指针，它指向的是已发送但未收到确认的第⼀个字节的序列号，也就是 #2 的第⼀
个字节。


- SND.NXT ：也是⼀个绝对指针，它指向未发送但可发送范围的第⼀个字节的序列号，也就是 #3 的第⼀个
字节。


- 指向 #4 的第⼀个字节是个相对指针，它需要 SND.UNA 指针加上 SND.WND ⼤⼩的偏移 ，就可以指向
#4 的第⼀个字节了。


那么可⽤窗⼝⼤⼩的计算就可以是：


可⽤窗⼝⼤ = SND.WND -（SND.NXT - SND.UNA）

### 3.37 接收⽅的滑动窗⼝

接下来我们看看接收⽅的窗⼝，接收窗⼝相对简单⼀些，根据处理的情况划分成三个部分：

- #1 + #2 是已成功接收并确认的数据（等待应⽤进程读取）；

- #3 是未收到数据但可以接收的数据；

- #4 未收到数据并不可以接收的数据；

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211210183536.png)


其中三个接收部分，使⽤两个指针进⾏划分:
- RCV.WND ：表示接收窗⼝的⼤⼩，它会通告给发送⽅。
- RCV.NXT ：是⼀个指针，它指向期望从发送⽅发送来的下⼀个数据字节的序列号，也就是 #3 的第⼀个字
节。

- 指向 #4 的第⼀个字节是个相对指针，它需要 RCV.NXT 指针加上 RCV.WND ⼤⼩的偏移 ，就可以指向
#4 的第⼀个字节了。


### 3.38 接收窗⼝和发送窗⼝的⼤⼩是相等的吗？
并不是完全相等，接收窗⼝的⼤⼩是**约等于**发送窗⼝的⼤⼩的。

因为滑动窗⼝并不是⼀成不变的。⽐如，当接收⽅的应⽤进程读取数据的速度⾮常快的话，这样的话接收窗⼝可以、很快的就空缺出来。那么新的接收窗⼝⼤⼩，是通过 TCP 报⽂中的 Windows 字段来告诉发送⽅。那么这个传输过程是存在时延的，所以接收窗⼝和发送窗⼝是约等于的关系。


### 3.39 流量控制
发送⽅不能⽆脑的发数据给接收⽅，要考虑接收⽅处理能⼒。

如果⼀直⽆脑的发数据给对⽅，但对⽅处理不过来，那么就会导致触发重发机制，从⽽导致⽹络流量的⽆端的浪费。


为了解决这种现象发⽣，**TCP 提供⼀种机制可以让「发送⽅」根据「接收⽅」的实际接收能⼒控制发送的数据量，这就是所谓的流量控制。**

下⾯举个栗⼦，为了简单起⻅，假设以下场景：

- 客户端是接收⽅，服务端是发送⽅

- 假设接收窗⼝和发送窗⼝相同，都为 200

- 假设两个设备在整个传输过程中都保持相同的窗⼝⼤⼩，不受外界影响


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211210191027.png)



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211210191143.png)


- 1、客户端向服务端发送请求数据报⽂。这⾥要说明下，本次例⼦是把服务端作为发送⽅，所以没有画出服务端的接收窗⼝。

- 2、服务端收到请求报⽂后，发送确认报⽂和 80 字节的数据，于是可⽤窗⼝ Usable 减少为 120 字节，同时SND.NXT 指针也向右偏移 80 字节后，指向 321，这意味着下次发送数据的时候，序列号是 321。

- 3、客户端收到 80 字节数据后，于是接收窗⼝往右移动 80 字节， RCV.NXT 也就指向 321，这意味着客户端期望的下⼀个报⽂的序列号是 321，接着发送确认报⽂给服务端。

- 4、服务端再次发送了 120 字节数据，于是可⽤窗⼝耗尽为 0，服务端⽆法再继续发送数据。

- 5、客户端收到 120 字节的数据后，于是接收窗⼝往右移动 120 字节， RCV.NXT 也就指向 441，接着发送确认报⽂给服务端。


- 6、服务端收到对 80 字节数据的确认报⽂后， SND.UNA 指针往右偏移后指向 321，于是可⽤窗⼝ Usable增⼤到 80。


- 7 、服务端收到对 120 字节数据的确认报⽂后， SND.UNA 指针往右偏移后指向 441，于是可⽤窗⼝ Usable增⼤到 200。

- 8、 服务端可以继续发送了，于是发送了 160 字节的数据后， SND.NXT 指向 601，于是可⽤窗⼝
Usable 减少到 40。

- 9、客户端收到 160 字节后，接收窗⼝往右移动了 160 字节， RCV.NXT 也就是指向了 601，接着发送确认报⽂给服务端。


- 10、服务端收到对 160 字节数据的确认报⽂后，发送窗⼝往右移动了 160 字节，于是 SND.UNA 指针偏移了160 后指向 601，可⽤窗⼝ Usable 也就增⼤⾄了 200。



#### 操作系统缓冲区与滑动窗⼝的关系
前⾯的流量控制例⼦，我们假定了发送窗⼝和接收窗⼝是不变的，但是实际上，发送窗⼝和接收窗⼝中所存放的字节数，都是放在操作系统内存缓冲区中的，⽽操作系统的缓冲区，会被操作系统调整。

当应⽤进程没办法及时读取缓冲区的内容时，也会对我们的缓冲区造成影响。

那操作系统的缓冲区，是如何影响发送窗⼝和接收窗⼝的呢？

我们先来看看第⼀个例⼦。

当应⽤程序没有及时读取缓存时，发送窗⼝和接收窗⼝的变化。

考虑以下场景：

- 客户端作为发送⽅，服务端作为接收⽅，发送窗⼝和接收窗⼝初始⼤⼩为 360 ；

- 服务端⾮常的繁忙，当收到客户端的数据时，应⽤层不能及时读取数据。



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211210192922.png)


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211210192925.png)


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211210192928.png)



根据上图的流量控制，说明下每个过程：

1. 客户端发送 140 字节数据后，可⽤窗⼝变为 220 （360 - 140）。

2. 服务端收到 140 字节数据，但是服务端⾮常繁忙，应⽤进程只读取了 40 个字节，还有 100 字节占⽤着缓冲区，于是接收窗⼝收缩到了 260 （360 - 100），最后发送确认信息时，将窗⼝⼤⼩通告给客户端。

3. 客户端收到确认和窗⼝通告报⽂后，发送窗⼝减少为 260。

4. 客户端发送 180 字节数据，此时可⽤窗⼝减少到 80。

5. 服务端收到 180 字节数据，但是应⽤程序没有读取任何数据，这 180 字节直接就留在了缓冲区，于是接收窗⼝收缩到了 80 （260 - 180），并在发送确认信息时，通过窗⼝⼤⼩给客户端。

6. 客户端收到确认和窗⼝通告报⽂后，发送窗⼝减少为 80。

7. 客户端发送 80 字节数据后，可⽤窗⼝耗尽。

8. 服务端收到 80 字节数据，但是应⽤程序依然没有读取任何数据，这 80 字节留在了缓冲区，于是接收窗⼝收缩到了 0，并在发送确认信息时，通过窗⼝⼤⼩给客户端。

9. 客户端收到确认和窗⼝通告报⽂后，发送窗⼝减少为 0。


可⻅最后窗⼝都收缩为 0 了，也就是发⽣了窗⼝关闭。当发送⽅可⽤窗⼝变为 0 时，发送⽅实际上会定时发送窗⼝探测报⽂，以便知道接收⽅的窗⼝是否发⽣了改变，这个内容后⾯会说，这⾥先简单提⼀下。


**我们先来看看第⼆个例⼦。**

当服务端系统资源⾮常紧张的时候，操作系统可能会直接减少接收缓冲区⼤⼩，这时应⽤程序⼜⽆法及时读取缓存数据，那么这时候就有严重的事情发⽣了，会出现数据包丢失的现象。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211210194530.png)


说明下每个过程：

1. 客户端发送 140 字节的数据，于是可⽤窗⼝减少到了 220。

2. 服务端因为现在⾮常的繁忙，操作系统于是就把接收缓存减少了 120 字节，当收到 140 字节数据后，⼜因为应⽤程序没有读取任何数据，所以 140 字节留在了缓冲区中，于是接收窗⼝⼤⼩从 360 收缩成了 100，最后发送确认信息时，通告窗⼝⼤⼩给对⽅。

3. 此时客户端因为还没有收到服务端的通告窗⼝报⽂，所以不知道此时接收窗⼝收缩成了 100，客户端只会看⾃⼰的可⽤窗⼝还有 220，所以客户端就发送了 180 字节数据，于是可⽤窗⼝减少到 40。

4. 服务端收到了 180 字节数据时，发现数据⼤⼩超过了接收窗⼝的⼤⼩，于是就把数据包丢失了。

5. 客户端收到第 2 步时，服务端发送的确认报⽂和通告窗⼝报⽂，尝试减少发送窗⼝到 100，把窗⼝的右端向左收缩了 80，此时可⽤窗⼝的⼤⼩就会出现诡异的负值。

所以，如果发⽣了先减少缓存，再收缩窗⼝，就会出现丢包的现象。

**为了防⽌这种情况发⽣，TCP 规定是不允许同时减少缓存⼜收缩窗⼝的，⽽是采⽤先收缩窗⼝，过段时间再减少缓存，这样就可以避免了丢包情况。**



#### 窗⼝关闭

在前⾯我们都看到了，TCP 通过让接收⽅指明希望从发送⽅接收的数据⼤⼩（窗⼝⼤⼩）来进⾏流量控制。

如果窗⼝⼤⼩为 0 时，就会阻⽌发送⽅给接收⽅传递数据，直到窗⼝变为d⾮ 0 为⽌，这就是窗⼝关闭。


### 3.40 窗⼝关闭潜在的危险

接收⽅向发送⽅通告窗⼝⼤⼩时，是通过 ACK 报⽂来通告的。

那么，当发⽣窗⼝关闭时，接收⽅处理完数据后，会向发送⽅通告⼀个窗⼝⾮ 0 的 ACK 报⽂，如果这个通告窗⼝的 ACK 报⽂在⽹络中丢失了，那麻烦就⼤了。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211210201109.png)


这会导致发送⽅⼀直等待接收⽅的⾮ 0 窗⼝通知，接收⽅也⼀直等待发送⽅的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象。


### 3.41 TCP 是如何解决窗⼝关闭时，潜在的死锁现象呢？

为了解决这个问题，TCP 为每个连接设有⼀个持续定时器，只要 TCP 连接⼀⽅收到对⽅的零窗⼝通知，就启动持续计时器。

如果持续计时器超时，就会发送窗⼝探测 ( Windowprobe ) 报⽂，⽽对⽅在确认这个探测报⽂时，给出⾃⼰现在的接收窗⼝⼤⼩。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211210202534.png)


- 如果接收窗⼝仍然为 0，那么收到这个报⽂的⼀⽅就会重新启动持续计时器；

- 如果接收窗⼝不是 0，那么死锁的局⾯就可以被打破了。


窗⼝探测的次数⼀般为 3 次，每次⼤约 30-60 秒（不同的实现可能会不⼀样）。如果 3 次过后接收窗⼝还是 0 的话，有的 TCP 实现就会发 RST 报⽂来中断连接。


#### 糊涂窗⼝综合症

如果接收⽅太忙了，来不及取⾛接收窗⼝⾥的数据，那么就会导致发送⽅的发送窗⼝越来越⼩。

到最后，如果接收⽅腾出⼏个字节并告诉发送⽅现在有⼏个字节的窗⼝，⽽发送⽅会义⽆反顾地发送这⼏个字节，这就是糊涂窗⼝综合症。


要知道，我们的 TCP + IP 头有 40 个字节，为了传输那⼏个字节的数据，要搭上这么⼤的开销，这太不经济了。

就好像⼀个可以承载 50 ⼈的⼤巴⻋，每次来了⼀两个⼈，就直接发⻋。除⾮家⾥有矿的⼤巴司机，才敢这样玩，不然迟早破产。要解决这个问题也不难，⼤巴司机等乘客数 超过了 25 个，才认定可以发⻋。

现举个糊涂窗⼝综合症的栗⼦，考虑以下场景：
接收⽅的窗⼝⼤⼩是 360 字节，但接收⽅由于某些原因陷⼊困境，假设接收⽅的应⽤层读取的能⼒如下：

- 接收⽅每接收 3 个字节，应⽤程序就只能从缓冲区中读取 1 个字节的数据；

- 在下⼀个发送⽅的 TCP 段到达之前，应⽤程序还从缓冲区中读取了 40 个额外的字节；


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211210204725.png)


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211210204802.png)

每个过程的窗⼝⼤⼩的变化，在图中都描述的很清楚了，可以发现窗⼝不断减少了，并且发送的数据都是⽐较⼩的了。

所以，糊涂窗⼝综合症的现象是可以发⽣在发送⽅和接收⽅：

- 接收⽅可以通告⼀个⼩的窗⼝
- ⽽发送⽅可以发送⼩数据

于是，要解决糊涂窗⼝综合症，就解决上⾯两个问题就可以了

- 接收⽅不通告⼩窗⼝给发送⽅
- 让发送⽅避免发送⼩数据




### 3.42 怎么让接收⽅不通告⼩窗⼝呢？

接收⽅通常的策略如下:


当「窗⼝⼤⼩」⼩于 min( MSS，缓存空间/2 ) ，也就是⼩于 MSS 与 1/2 缓存⼤⼩中的最⼩值时，就会向发送⽅通告窗⼝为 0 ，也就阻⽌了发送⽅再发数据过来。

等到接收⽅处理了⼀些数据后，窗⼝⼤⼩ >= MSS，或者接收⽅缓存空间有⼀半可以使⽤，就可以把窗⼝打开让发送⽅发送数据过来。


### 3.43 怎么让发送⽅避免发送⼩数据呢？
发送⽅通常的策略:
使⽤ Nagle 算法，该算法的思路是延时处理，它满⾜以下两个条件中的⼀条才可以发送数据：

- 要等到窗⼝⼤⼩ >= MSS 或是 数据⼤⼩ >= MSS
- 收到之前发送数据的 ack 回包


只要没满⾜上⾯条件中的⼀条，发送⽅⼀直在囤积数据，直到满⾜上⾯的发送条件。



另外，Nagle 算法默认是打开的，如果对于⼀些需要⼩数据包交互的场景的程序，⽐如，telnet 或 ssh 这样的交互性⽐较强的程序，则需要关闭 Nagle 算法。


可以在 Socket 设置 TCP_NODELAY 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应⽤⾃⼰的特点来关闭）


```cpp
setsockopt(sock_fd, IPPROTO_TCP, TCP_NODELAY, (char *)&value, sizeof(int));
```


### 3.44 为什么要有拥塞控制呀，不是有流量控制了吗？

流量控制是避免「发送⽅」的数据填满「接收⽅」的缓存，但是并不知道⽹络的中发⽣了什么。


⼀般来说，计算机⽹络都处在⼀个共享的环境。因此也有可能会因为其他主机之间的通信使得⽹络拥堵。


在⽹络出现拥堵时，如果继续发送⼤量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是⼀重传就会导致⽹络的负担更重，于是会导致更⼤的延迟以及更多的丢包，这个情况就会进⼊恶性循环被不断地放⼤....


所以，TCP 不能忽略⽹络上发⽣的事，它被设计成⼀个⽆私的协议，当⽹络发送拥塞时，TCP 会⾃我牺牲，降低发送的数据量。


于是，就有了**拥塞控制**，控制的⽬的就是**避免「发送⽅」的数据填满整个⽹络。**

为了在「发送⽅」调节所要发送数据的量，定义了⼀个叫做「拥塞窗⼝」的概念。



### 3.45 什么是拥塞窗⼝？和发送窗⼝有什么关系呢？
**拥塞窗⼝ cwnd**是发送⽅维护的⼀个的状态变量，它会**根据⽹络的拥塞程度动态变化**的。

我们在前⾯提到过发送窗⼝ swnd 和接收窗⼝ rwnd 是约等于的关系，那么由于加⼊了拥塞窗⼝的概念后，此时**发送窗⼝的值是swnd = min(cwnd, rwnd)，也就是拥塞窗⼝和接收窗⼝中的最⼩值。**


拥塞窗⼝ cwnd 变化的规则：

- 只要⽹络中没有出现拥塞， cwnd 就会增⼤；

- 但⽹络中出现了拥塞， cwnd 就减少；


### 3.46 那么怎么知道当前⽹络是否出现了拥塞呢？

其实只要「发送⽅」没有在规定时间内接收到 ACK 应答报⽂，也就是发⽣了超时重传，就会认为⽹络出现了拥塞。



### 3.47 拥塞控制有哪些控制算法？

- 慢启动
- 拥塞避免
- 拥塞发⽣
- 快速恢复


#### 慢启动
TCP 在刚建⽴连接完成后，⾸先是有个慢启动的过程，这个慢启动的意思就是⼀点⼀点的提⾼发送数据包的数量，如果⼀上来就发⼤量的数据，这不是给⽹络添堵吗？


慢启动的算法记住⼀个规则就⾏：**当发送⽅每收到⼀个 ACK，拥塞窗⼝ cwnd 的⼤⼩就会加 1。**


这⾥假定拥塞窗⼝ cwnd 和发送窗⼝ swnd 相等，下⾯举个栗⼦：

- 连接建⽴完成后，⼀开始初始化 cwnd = 1 ，表示可以传⼀个 MSS ⼤⼩的数据。


- 当收到⼀个 ACK 确认应答后，cwnd 增加 1，于是⼀次能够发送 2 个


- 当收到 2 个的 ACK 确认应答后， cwnd 增加 2，于是就可以⽐之前多发2 个，所以这⼀次能够发送 4 个

- 当这 4 个的 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以⽐之前多发4 个，所以这⼀次能够发送 8 个。



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211105107.png)

可以看出慢启动算法，发包的个数是指数性的增⻓。

那慢启动涨到什么时候是个头呢？
有⼀个叫慢启动⻔限ssthresh （slow start threshold）状态变量

- 当 cwnd < ssthresh 时，使⽤慢启动算法。
- 当 cwnd >= ssthresh 时，就会使⽤「拥塞避免算法」。



#### 拥塞避免算法

前⾯说道，当拥塞窗⼝ cwnd 「超过」慢启动⻔限 ssthresh 就会进⼊拥塞避免算法。

一般来说 ssthresh 的⼤⼩是 65535 字节。

那么进⼊拥塞避免算法后，它的规则是：每当收到⼀个 ACK 时，cwnd 增加 1/cwnd。


接上前⾯的慢启动的栗⼦，现假定 ssthresh 为 8 ：


当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd ⼀共增加 1，于是这⼀次能够发送 9个 MSS ⼤⼩的数据，变成了线性增⻓。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211110414.png)


所以，我们可以发现，拥塞避免算法就是将原本慢启动算法的指数增⻓变成了线性增⻓，还是增⻓阶段，但是增⻓速度缓慢了⼀些。


就这么⼀直增⻓着后，⽹络就会慢慢进⼊了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进⾏重传。


当触发了重传机制，也就进⼊了「拥塞发⽣算法」。


#### 拥塞发⽣
当⽹络出现拥塞，也就是会发⽣数据包重传，重传机制主要有两种：

- 超时重传
- 快速重传

这两种使⽤的拥塞发生算法是不同的，接下来分别来说说。


##### 发⽣超时重传的拥塞发⽣算法
这个时候，ssthresh 和 cwnd 的值会发⽣变化：

- ssthresh 设为 cwnd/2 ，
- cwnd 重置为 1


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211112212.png)


接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是⼀旦「超时重传」，⻢上回到解放前。但是这种⽅式太激进了，反应也很强烈，会造成⽹络卡顿。


就好像本来在秋名⼭⾼速漂移着，突然来个紧急刹⻋，轮胎受得了吗。。。


##### 发⽣快速重传的拥塞发⽣算法

还有更好的⽅式，前⾯我们讲过「快速重传算法」。当接收⽅发现丢了⼀个中间包的时候，发送三次前⼀个包的ACK，于是发送端就会快速地重传，不必等待超时再重传。

TCP 认为这种情况不严重，因为⼤部分没丢，只丢了⼀⼩部分，则 ssthresh 和 cwnd 变化如下：

- cwnd = cwnd/2 ，也就是设置为原来的⼀半;
- ssthresh = cwnd ;
- 进⼊快速恢复算法



#### 快速恢复
快速重传和快速恢复算法⼀般同时使⽤，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明⽹络也不那么糟糕，所以没有必要像 RTO 超时那么强烈。

正如前⾯所说，进⼊快速恢复之前， cwnd 和 ssthresh 已被更新了：

- cwnd = cwnd/2 ，也就是设置为原来的⼀半;
- ssthresh = cwnd ;


然后，进⼊快速恢复算法如下：

- 拥塞窗⼝ cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）；

- 重传丢失的数据包；

- 如果再收到重复的 ACK，那么 cwnd 增加 1；

- 如果收到新数据的 ACK 后，把 cwnd 设置为第⼀步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进⼊拥塞避免状态；


也就是没有像「超时重传」⼀夜回到解放前，⽽是还在⽐较⾼的值，后续呈线性增⻓。


#### 拥塞算法示意图

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211114510.png)



### 3.48 TCP 实战抓包分析

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211115516.png)


⽹络世界中的数据包交互我们⾁眼是看不⻅的，它们就好像隐形了⼀样，我们对着课本学习计算机⽹络的时候就会觉得⾮常的抽象，加⼤了学习的难度。

tcpdump 和 Wireshark，这两⼤利器把我们“看不⻅”的数据包，呈现在我们眼前，⼀⽬了然。


### 3.49 tcpdump 和 Wireshark 有什么区别？

tcpdump 和 Wireshark 就是最常⽤的⽹络抓包和分析⼯具，更是分析⽹络性能必不可少的利器。


- tcpdump 仅⽀持命令⾏格式使⽤，常⽤在 Linux 服务器中抓取和分析⽹络包。

- Wireshark 除了可以抓包外，还提供了可视化分析⽹络包的图形⻚⾯。



所以，这两者实际上是搭配使⽤的，先⽤ tcpdump 命令在 Linux 服务器上抓包，接着把抓包的⽂件拖出到
Windows 电脑后，⽤ Wireshark 可视化分析



当然，如果你是在 Windows 上抓包，只需要⽤ Wireshark ⼯具就可以。



### 3.50 tcpdump 在 Linux 下如何抓包？
tcpdump 提供了⼤量的选项以及各式各样的过滤表达式，来帮助你抓取指定的数据包，不过不要担⼼，只需要掌握⼀些常⽤选项和过滤表达式，就可以满⾜⼤部分场景的需要了。

假设我们要抓取下⾯的 ping 的数据包：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211121630.png)

要抓取上⾯的 ping 命令数据包，⾸先我们要知道 ping 的数据包是 icmp 协议，接着在使⽤ tcpdump 抓包的时候，就可以指定只抓 icmp 协议的数据包：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211121848.png)


那么当 tcpdump 抓取到 icmp 数据包后， 输出格式如下：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211123657.png)


从 tcpdump 抓取的 icmp 数据包，我们很清楚的看到 icmp echo 的交互过程了，⾸先发送⽅发起了 ICMP echo request 请求报⽂，接收⽅收到后回了⼀个 ICMP echo reply 响应报⽂，之后 seq 是递增的。


我在这⾥也帮你整理了⼀些最常⻅的⽤法，并且绘制成了表格，你可以参考使⽤。

⾸先，先来看看常⽤的选项类，在上⾯的 ping 例⼦中，我们⽤过 -i 选项指定⽹⼝，⽤过 -nn 选项不对 IP 地址和端⼝名称解析。其他常⽤的选项，如下表格：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211144611.png)


接下来，我们再来看看常⽤的过滤表⽤法，在上⾯的 ping 例⼦中，我们⽤过的是 icmp and host
183.232.231.174 ，表示抓取 icmp 协议的数据包，以及源地址或⽬标地址为 183.232.231.174 的包。其他常⽤的过滤选项，我也整理成了下⾯这个表格。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211145011.png)


tcpdump 虽然功能强⼤，但是输出的格式并不直观。

所以，在⼯作中 tcpdump 只是⽤来抓取数据包，不⽤来分析数据包，⽽是把 tcpdump 抓取的数据包保存成 pcap后缀的⽂件，接着⽤ Wireshark ⼯具进⾏数据包分析。



### 3.51 Wireshark ⼯具如何分析数据包？
Wireshark 除了可以抓包外，还提供了可视化分析⽹络包的图形⻚⾯，同时，还内置了⼀系列的汇总分析⼯具。

⽐如，拿上⾯的 ping 例⼦来说，我们可以使⽤下⾯的命令，把抓取的数据包保存到 ping.pcap ⽂件


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211145807.png)

接着把 ping.pcap ⽂件拖到电脑，再⽤ Wireshark 打开它。打开后，你就可以看到下⾯这个界⾯：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211145947.png)

是吧？在 Wireshark 的⻚⾯⾥，可以更加直观的分析数据包，不仅展示各个⽹络包的头部信息，还会⽤不同的颜⾊来区分不同的协议，由于这次抓包只有 ICMP 协议，所以只有紫⾊的条⽬。


接着，在⽹络包列表中选择某⼀个⽹络包后，在其下⾯的⽹络包详情中，可以更清楚的看到，这个⽹络包在协议栈各层的详细信息。⽐如，以编号 1 的⽹络包为例⼦：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211150257.jpg)


- 可以在数据链路层，看到 MAC 包头信息，如源 MAC 地址和⽬标 MAC 地址等字段

- 可以在 IP 层，看到 IP 包头信息，如源 IP 地址和⽬标 IP 地址、TTL、IP 包⻓度、协议等 IP 协议各个字段的数值和含义；

- 可以在 ICMP 层，看到 ICMP 包头信息，⽐如 Type、Code 等 ICMP 协议各个字段的数值和含义；

Wireshark ⽤了分层的⽅式，展示了各个层的包头信息，把“不可⻅”的数据包，清清楚楚的展示了给我们，还有理由学不好计算机⽹络吗？是不是相⻅恨晚？


从 ping 的例⼦中，我们可以看到⽹络分层就像有序的分⼯，每⼀层都有⾃⼰的责任范围和信息，上层协议完成⼯作后就交给下⼀层，最终形成⼀个完整的⽹络包。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211150459.png)




### 3.51 解密 TCP 三次握⼿和四次挥⼿

本次例⼦，我们将要访问的 http://192.168.3.200 服务端。在终端⼀⽤ tcpdump 命令抓取数据包：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211151249.png)




接着，在终端⼆执⾏下⾯的 curl 命令：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211151344.png)


最后，回到终端⼀，按下 Ctrl+C 停⽌ tcpdump，并把得到的 http.pcap 取出到电脑。


使⽤ Wireshark 打开 http.pcap 后，你就可以在 Wireshark 中，看到如下的界⾯：、

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211152736.jpg)

我们都知道 HTTP 是基于 TCP 协议进⾏传输的，那么：


- 最开始的 3 个包就是 TCP 三次握⼿建⽴连接的包

- 中间是 HTTP 请求和响应的包

- ⽽最后的 3 个包则是 TCP 断开连接的挥⼿包



Wireshark 可以⽤时序图的⽅式显示数据包交互的过程，从菜单栏中，点击 统计 (Statistics) -> 流 图 (FlowGraph)，然后，在弹出的界⾯中的「流 类型」选择 「TCP Flows」，你可以更清晰的看到，整个过程中 TCP 流的执⾏过程：



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211153933.png)



### 3.52 为什么三次握⼿连接过程的 Seq 是 0 ？

实际上是因为 Wireshark ⼯具帮我们做了优化，它默认显示的是序列号 seq 是相对值，⽽不是真实值。

如果你想看到实际的序列号的值，可以右键菜单， 然后找到「协议⾸选项」，接着找到「Relative Seq」后，把它给取消，操作如下


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211154134.jpg)


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211154251.png)



可⻅，客户端和服务端的序列号实际上是不同的，序列号是⼀个随机值。

这其实跟我们书上看到的 TCP 三次握⼿和四次挥⼿很类似，作为对⽐，你通常看到的 TCP 三次握⼿和四次挥⼿的流程，基本是这样的：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211155850.png)

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211155905.png)



### 3.53 为什么抓到的 TCP 挥⼿是三次，⽽不是书上说的四次？

因为服务器端收到客户端的 FIN 后，服务器端同时也要关闭连接，这样就可以把 ACK 和 FIN 合并到⼀起发
送，节省了⼀个包，变成了“三次挥⼿”。

⽽通常情况下，服务器端收到客户端的 FIN 后，很可能还没发送完数据，所以就会先回复客户端⼀个 ACK
包，稍等⼀会⼉，完成所有数据包的发送后，才会发送 FIN 包，这也就是四次挥⼿了。


如下图，就是四次挥⼿的过程：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211160402.png)

### 3.54 TCP 三次握⼿异常情况实战分析
TCP 三次握⼿的过程相信⼤家都背的滚⽠烂熟，那么你有没有想过这三个异常情况：

- TCP 第⼀次握⼿的 SYN 丢包了，会发⽣了什么？

- TCP 第⼆次握⼿的 SYN、ACK 丢包了，会发⽣什么？

- TCP 第三次握⼿的 ACK 包丢了，会发⽣什么？


有的⼩伙伴可能说：“很简单呀，包丢了就会重传嘛。”

那我在继续问你：

- 那会重传⼏次？

- 超时重传的时间 RTO 会如何变化？

- 在 Linux 下如何设置重传次数？


是不是哑⼝⽆⾔，⽆法回答？

#### 实验场景

本次实验⽤了两台虚拟机，⼀台作为服务端，⼀台作为客户端，它们的关系如下：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211160819.png)


- 客户端和服务端都是 CentOs 6.5 Linux，Linux 内核版本 2.6.32
- 服务端 192.168.12.36，apache web 服务
- 客户端 192.168.12.37

##### 实验⼀：TCP 第⼀次握⼿ SYN 丢包
为了模拟 TCP 第⼀次握⼿ SYN 丢包的情况，我是在拔掉服务器的⽹线后，⽴刻在客户端执⾏ curl 命令：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211161037.png)

其间 tcpdump 抓包的命令如下：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211161132.png)

过了⼀会， curl 返回了超时连接的错误：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211161201.png)


从 date 返回的时间，可以发现在超时接近 1 分钟的时间后，curl 返回了错误。

接着，把 tcp_sys_timeout.pcap ⽂件⽤ Wireshark 打开分析，显示如下图：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211161424.jpg)


从上图可以发现， 客户端发起了 SYN 包后，⼀直没有收到服务端的 ACK ，所以⼀直超时重传了 5 次，并且每次RTO 超时时间是不同的：

- 第⼀次是在 1 秒超时重传

- 第⼆次是在 3 秒超时重传

- 第三次是在 7 秒超时重传

- 第四次是在 15 秒超时重传

- 第五次是在 31 秒超时重传

可以发现，每次超时时间 RTO 是指数（翻倍）上涨的，当超过最⼤重传次数后，客户端不再发送 SYN 包。

在 Linux 中，第⼀次握⼿的 SYN 超时重传次数，是如下内核参数指定的：


$ cat /proc/sys/net/ipv4/tcp_syn_retries
5

tcp_syn_retries 默认值为 5，也就是 SYN 最⼤重传次数是 5 次。


接下来，我们继续做实验，把 tcp_syn_retries 设置为 2 次：


$ echo 2 > /proc/sys/net/ipv4/tcp_syn_retries


重传抓包后，⽤ Wireshark 打开分析，显示如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211162151.png)


实验⼀的实验⼩结

通过实验⼀的实验结果，我们可以得知，当客户端发起的 TCP 第⼀次握⼿ SYN 包，在超时时间内没收到服务端的ACK，就会在超时重传 SYN 数据包，每次超时重传的 RTO 是翻倍上涨的，直到 SYN 包的重传次数到达tcp_syn_retries 值后，客户端不再发送 SYN 包。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211162606.png)


##### TCP 第⼆次握⼿ SYN、ACK 丢包
为了模拟客户端收不到服务端第⼆次握⼿ SYN、ACK 包，我的做法是在客户端加上防⽕墙限制，直接粗暴的把来⾃服务端的数据都丢弃，防⽕墙的配置如下：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211163044.png)


接着，在客户端执⾏ curl 命令：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211163109.png)


从 date 返回的时间前后，可以算出⼤概 1 分钟后，curl 报错退出了。

客户端在这其间抓取的数据包，⽤ Wireshark 打开分析，显示的时序图如下：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211163411.png)


从图中可以发现：
- 客户端发起 SYN 后，由于防⽕墙屏蔽了服务端的所有数据包，所以 curl 是⽆法收到服务端的 SYN、ACK
包，当发⽣超时后，就会重传 SYN 包。

- 服务端收到客户的 SYN 包后，就会回 SYN、ACK 包，但是客户端⼀直没有回 ACK，服务端在超时后，重传了 SYN、ACK 包，接着⼀会，客户端超时重传的 SYN 包⼜抵达了服务端，服务端收到后，超时定时器就重
新计时，然后回了 SYN、ACK 包，所以相当于服务端的超时定时器只触发了⼀次，⼜被重置了。

- 最后，客户端 SYN 超时重传次数达到了 5 次（tcp_syn_retries 默认值 5 次），就不再继续发送 SYN 包了。

所以，我们可以发现，当第⼆次握⼿的 SYN、ACK 丢包时，客户端会超时重发 SYN 包，服务端也会超时重传
SYN、ACK 包。

### 3.55 咦？客户端设置了防⽕墙，屏蔽了服务端的⽹络包，为什么 tcpdump 还能抓到服务端的⽹络包？
添加 iptables 限制后， tcpdump 是否能抓到包 ，这要看添加的 iptables 限制条件：

- 如果添加的是 INPUT 规则，则可以抓得到包
- 如果添加的是 OUTPUT 规则，则抓不到包

⽹络包进⼊主机后的顺序如下：

- 进来的顺序 Wire -> NIC -> tcpdump -> netfilter/iptables

- 出去的顺序 iptables -> tcpdump -> NIC -> Wire


### 3.55 tcp_syn_retries 是限制 SYN 重传次数，那第⼆次握⼿ SYN、ACK 限制最⼤重传次数是多少？

TCP 第⼆次握⼿ SYN、ACK 包的最⼤重传次数是通过 tcp_synack_retries 内核参数限制的，其默认值如下：


$ cat /proc/sys/net/ipv4/tcp_synack_retries
5

是的，TCP 第⼆次握⼿ SYN、ACK 包的最⼤ 传次数默认值是 5 次。


为了验证 SYN、ACK 包最⼤重传次数是 5 次，我们继续做下实验，我们先把客户端的 tcp_syn_retries 设置为1，表示客户端 SYN 最⼤超时次数是 1 次，⽬的是为了防⽌多次重传 SYN，把服务端 SYN、ACK 超时定时器重置。


接着，还是如上⾯的步骤：

- 1. 客户端配置防⽕墙屏蔽服务端的数据包

- 2. 客户端 tcpdump 抓取 curl 执⾏时的数据包


把抓取的数据包，⽤ Wireshark 打开分析，显示的时序图如下：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211164426.png)


从上图，我们可以分析出：
- 客户端的 SYN 只超时重传了 1 次，因为 tcp_syn_retries 值为 1

- 服务端应答了客户端超时重传的 SYN 包后，由于⼀直收不到客户端的 ACK 包，所以服务端⼀直在超时重传SYN、ACK 包，每次的 RTO 也是指数上涨的，⼀共超时重传了 5 次，因为 tcp_synack_retries 值为 5


接着，我把 tcp_synack_retries 设置为 2， tcp_syn_retries 依然设置为 1:

echo 2 > /proc/sys/net/ipv4/tcp_synack_retries

echo 1 > /proc/sys/net/ipv4/tcp_syn_retries


依然保持⼀样的实验步骤进⾏操作，接着把抓取的数据包，⽤ Wireshark 打开分析，显示的时序图如下：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211164654.png)



可⻅：

- 客户端的 SYN 包只超时重传了 1 次，符合 tcp_syn_retries 设置的值；

- 服务端的 SYN、ACK 超时重传了 2 次，符合 tcp_synack_retries 设置的值


实验⼆的实验⼩结

通过实验⼆的实验结果，我们可以得知，当 TCP 第⼆次握⼿ SYN、ACK 包丢了后，客户端 SYN 包会发⽣超时重传，服务端 SYN、ACK 也会发⽣超时重传。

客户端 SYN 包超时重传的最⼤次数，是由 tcp_syn_retries 决定的，默认值是 5 次；服务端 SYN、ACK 包时重传的最⼤次数，是由 tcp_synack_retries 决定的，默认值是 5 次。

##### 实验三：TCP 第三次握⼿ ACK 丢包

为了模拟 TCP 第三次握⼿ ACK 包丢，我的实验⽅法是在服务端配置防⽕墙，屏蔽客户端 TCP 报⽂中标志位是ACK 的包，也就是当服务端收到客户端的 TCP ACK 的报⽂时就会丢弃，iptables 配置命令如下：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211165136.png)


接着，在客户端执⾏如下 tcpdump 命令：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211165201.png)

然后，客户端向服务端发起 telnet，因为 telnet 命令是会发起 TCP 连接，所以⽤此命令做测试：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211165227.jpg)

此时，由于服务端收不到第三次握⼿的 ACK 包，所以⼀直处于 SYN_RECV 状态：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211165507.png)

⽽客户端是已完成 TCP 连接建⽴，处于 ESTABLISHED 状态：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211165532.png)

过了 1 分钟后，观察发现服务端的 TCP 连接不⻅了：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211165559.png)

过了 30 分别，客户端依然还是处于 ESTABLISHED 状态：
![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211165625.png)

接着，在刚才客户端建⽴的 telnet 会话，输⼊ 123456 字符，进⾏发送：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211165649.jpg)

持续「好⻓」⼀段时间，客户端的 telnet 才断开连接：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211165716.jpg)


以上就是本次的实现三的现象，这⾥存在两个疑点：

- 为什么服务端原本处于 SYN_RECV 状态的连接，过 1 分钟后就消失了？

- 为什么客户端 telnet 输⼊ 123456 字符后，过了好⻓⼀段时间，telnet 才断开连接？


不着急，我们把刚抓的数据包，⽤ Wireshark 打开分析，显示的时序图如下：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211165751.png)

上图的流程：
- 客户端发送 SYN 包给服务端，服务端收到后，回了个 SYN、ACK 包给客户端，此时服务端的 TCP 连接处于SYN_RECV 状态；

- 客户端收到服务端的 SYN、ACK 包后，给服务端回了个 ACK 包，此时客户端的 TCP 连接处于ESTABLISHED 状态


- 由于服务端配置了防⽕墙，屏蔽了客户端的 ACK 包，所以服务端⼀直处于 SYN_RECV 状态，没有进⼊ESTABLISHED 状态，tcpdump 之所以能抓到客户端的 ACK 包，是因为数据包进⼊系统的顺序是先进⼊tcpudmp，后经过 iptables；


- 接着，服务端超时 传了 SYN、ACK 包， 传了 5 次后，也就是超过 tcp_synack_retries 的值（默认值是5），然后就没有继续重传了，此时服务端的 TCP 连接主动中⽌了，所以刚才处于 SYN_RECV 状态的 TCP连接断开了，⽽客户端依然处于 ESTABLISHED 状态；


- 虽然服务端 TCP 断开了，但过了⼀段时间，发现客户端依然处于ESTABLISHED 状态，于是就在客户端的telnet 会话输⼊了 123456 字符；




- 此时由于服务端已经断开连接，客户端发送的数据报⽂，⼀直在超时重传，每⼀次重传，RTO 的值是指数增
⻓的，所以持续了好⻓⼀段时间，客户端的 telnet 才报错退出了，此时共重传了 15 次。


通过这⼀波分析，刚才的两个疑点已经解除了：

- 服务端在重传 SYN、ACK 包时，超过了最⼤重传次数 tcp_synack_retries ，于是服务端的 TCP 连接主动断开了。

- 客户端向服务端发送数据包时，由于服务端的 TCP 连接已经退出了，所以数据包⼀直在超时重传，共重传了15 次， telnet 就断开了连接。



### 3.56  TCP 第⼀次握⼿的 SYN 包超时重传最⼤次数是由 tcp_syn_retries 指定，TCP 第⼆次握⼿的 SYN、ACK 包超时重传最⼤次数是由 tcp_synack_retries 指定，那 TCP 建⽴连接后的数据包最⼤超时重传次数是由什么参数指定呢？

TCP 建⽴连接后的数据包传输，最⼤超时重传次数是由 tcp_retries2 指定，默认值是 15 次，如下：

$ cat /proc/sys/net/ipv4/tcp_retries2
15

如果 15 次重传都做完了，TCP 就会告诉应⽤层说：“搞不定了，包怎么都传不过去！”

### 3.57  那如果客户端不发送数据，什么时候才会断开处于 ESTABLISHED 状态的连接？
这⾥就需要提到 TCP 的 保活机制。这个机制的原理是这样的：

定义⼀个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作⽤，每隔⼀个时间间隔，发送⼀个「探测报⽂」，该探测报⽂包含的数据⾮常少，如果连续⼏个探测报⽂都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应⽤程序。

在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：

net.ipv4.tcp_keepalive_time=7200
net.ipv4.tcp_keepalive_intvl=75 
net.ipv4.tcp_keepalive_probes=9


- tcp_keepalive_time=7200：表示保活时间是 7200 秒（2⼩时），也就 2 ⼩时内如果没有任何连接相关的活动，则会启动保活机制

- tcp_keepalive_intvl=75：表示每次检测间隔 75 秒；

- tcp_keepalive_probes=9：表示检测 9 次⽆响应，认为对⽅是不可达的，从⽽中断本次的连接。


也就是说在 Linux 系统中，最少需要经过 2 ⼩时 11 分 15 秒才可以发现⼀个「死亡」连接。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211174528.png)


实验三的实验⼩结

在建⽴ TCP 连接时，如果第三次握⼿的 ACK，服务端⽆法收到，则服务端就会短暂处于 SYN_RECV 状态，⽽
客户端会处于 ESTABLISHED 状态。

由于服务端⼀直收不到 TCP 第三次握⼿的 ACK，则会⼀直重传 SYN、ACK 包，直到重传次数超过
tcp_synack_retries 值（默认值 5 次）后，服务端就会断开 TCP 连接。


⽽客户端则会有两种情况：

- 如果客户端没发送数据包，⼀直处于 ESTABLISHED 状态，然后经过 2 ⼩时 11 分 15 秒才可以发现⼀个
「死亡」连接，于是客户端连接就会断开连接。


- 如果客户端发送了数据包，⼀直没有收到服务端对该数据包的确认报⽂，则会⼀直重传该数据包，直到重传
次数超过 tcp_retries2 值（默认值 15 次）后，客户端就会断开 TCP 连接。


### 3.58 TCP 快速建⽴连接

客户端在向服务端发起 HTTP GET 请求时，⼀个完整的交互过程，需要 2.5 个 RTT 的时延。

由于第三次握⼿是可以携带数据的，这时如果在第三次握⼿发起 HTTP GET 请求，需要 2 个 RTT 的时延。

但是在下⼀次（不是同个 TCP 连接的下⼀次）发起 HTTP GET 请求时，经历的 RTT 也是⼀样，如下图：


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211175201.png)


在 Linux 3.7 内核版本中，提供了 TCP Fast Open 功能，这个功能可以减少 TCP 连接建⽴的时延。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211175355.png)

- 在第⼀次建⽴连接的时候，服务端在第⼆次握⼿产⽣⼀个 Cookie （已加密）并通过 SYN、ACK 包⼀起发
给客户端，于是客户端就会缓存这个 Cookie ，所以第⼀次发起 HTTP Get 请求的时候，还是需要 2 个 RTT
的时延；


- 在下次请求的时候，客户端在 SYN 包带上 Cookie 发给服务端，就提前可以跳过三次握⼿的过程，因为
Cookie 中维护了⼀些信息，服务端可以从 Cookie 获取 TCP 相关的信息，这时发起的 HTTP GET 请求就
只需要 1 个 RTT 的时延；

注：客户端在请求并存储了 Fast Open Cookie 之后，可以不断重复 TCP Fast Open 直⾄服务器认为 Cookie ⽆效（通常为过期）



### 3.59 在 Linux 上如何打开 Fast Open 功能？

可以通过设置 net.ipv4.tcp_fastopn 内核参数，来打开 Fast Open 功能。

net.ipv4.tcp_fastopn 各个值的意义:

- 0 关闭
- 1 作为客户端使⽤ Fast Open 功能
- 2 作为服务端使⽤ Fast Open 功能
- 3 ⽆论作为客户端还是服务器，都可以使⽤ Fast Open 功能


### 3.60 TCP Fast Open 抓包分析
在下图，数据包 7 号，客户端发起了第⼆次 TCP 连接时，SYN 包会携带 Cooike，并且⻓度为 5 的数据。

服务端收到后，校验 Cooike 合法，于是就回了 SYN、ACK 包，并且确认应答收到了客户端的数据包，ACK = 5 +1 = 6

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211175901.jpg)


### 3.61 TCP 重复确认和快速重传

当接收⽅收到乱序数据包时，会发送重复的 ACK，以便告知发送⽅要重发该数据包，当发送⽅收到 3 个重复 ACK时，就会触发快速重传，⽴刻重发丢失数据包。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211180144.png)


TCP 重复确认和快速重传的⼀个案例，⽤ Wireshark 分析，显示如下：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211180326.jpg)

- 数据包 1 期望的下⼀个数据包 Seq 是 1，但是数据包 2 发送的 Seq 却是 10945，说明收到的是乱序数据包，于是回了数据包 3 ，还是同样的 Seq = 1，Ack = 1，这表明是重复的 ACK；


- 数据包 4 和 6 依然是乱序的数据包，于是依然回了重复的 ACK；

- 当对⽅收到三次重复的 ACK 后，于是就快速重传了 Seq = 1 、Len = 1368 的数据包 8；

- 当收到重传的数据包后，发现 Seq = 1 是期望的数据包，于是就发送了个确认收到快速重传的 ACK


注意：快速 传和 复 ACK 标记信息是 Wireshark 的功能，⾮数据包本身的信息。


以上案例在 TCP 三次握⼿时协商开启了选择性确认 SACK，因此⼀旦数据包丢失并收到重复 ACK ，即使在丢失数据包之后还成功接收了其他数据包，也只需要重传丢失的数据包。如果不启⽤ SACK，就必须重传丢失包之后的每个数据包。


如果要⽀持 SACK ，必须双⽅都要⽀持。在 Linux 下，可以通过 net.ipv4.tcp_sack 参数打开这个功能（Linux2.4 后默认打开）。



### 3.62 TCP 流量控制

TCP 为了防⽌发送⽅⽆脑的发送数据，导致接收⽅缓冲区被填满，所以就有了滑动窗⼝的机制，它可利⽤接收⽅的接收窗⼝来控制发送⽅要发送的数据 ，也就是流量控制。

接收窗⼝是由接收⽅指定的值，存储在 TCP 头部中，它可以告诉发送⽅⾃⼰的 TCP 缓冲空间区⼤⼩，这个缓冲区是给应⽤程序读取数据的空间：

- 如果应⽤程序读取了缓冲区的数据，那么缓冲空间区就会把被读取的数据移除

- 如果应⽤程序没有读取数据，则数据会⼀直滞留在缓冲区。

接收窗⼝的⼤⼩，是在 TCP 三次握⼿中协商好的，后续数据传输时，接收⽅发送确认应答 ACK 报⽂时，会携带当前的接收窗⼝的⼤⼩，以此来告知发送⽅。


假设接收⽅接收到数据后，应⽤层能很快的从缓冲区⾥读取数据，那么窗⼝⼤⼩会⼀直保持不变，过程如下：

但是现实中服务器会出现繁忙的情况，当应⽤程序读取速度慢，那么缓存空间会慢慢被占满，于是为了保证发送⽅发送的数据不会超过缓冲区⼤⼩，服务器则会调整窗⼝⼤⼩的值，接着通过 ACK 报⽂通知给对⽅，告知现在的接收窗⼝⼤⼩，从⽽控制发送⽅发送的数据⼤⼩。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211183107.png)


#### 零窗⼝通知与窗⼝探测
假设接收⽅处理数据的速度跟不上接收数据的速度，缓存就会被占满，从⽽导致接收窗⼝为 0，当发送⽅接收到零窗⼝通知时，就会停⽌发送数据。

如下图，可以看到接收⽅的窗⼝⼤⼩在不断的收缩⾄ 0：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211183358.png)



接着，发送⽅会**定时发送窗⼝⼤⼩探测报⽂**，以便及时知道接收⽅窗⼝⼤⼩的变化。


以下图 Wireshark 分析图作为例⼦说明：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211183512.png)

- 发送⽅发送了数据包 1 给接收⽅，接收⽅收到后，由于缓冲区被占满，回了个零窗⼝通知；

- 发送⽅收到零窗⼝通知后，就不再发送数据了，直到过了 3.4 秒后，发送了⼀个 TCP Keep-Alive 报⽂，也就是窗⼝⼤⼩探测报⽂；

- 当接收⽅收到窗⼝探测报⽂后，就⽴⻢回⼀个窗⼝通知，但是窗⼝⼤⼩还是 0；

- 发送⽅发现窗⼝还是 0，于是继续等待了 6.8 （翻倍） 秒后，⼜发送了窗⼝探测报⽂，接收⽅依然还是回了窗⼝为 0 的通知；

- 发送⽅发现窗⼝还是 0，于是继续等待了 13.5 （翻倍） 秒后，⼜发送了窗⼝探测报⽂，接收⽅依然还是回了窗⼝为 0 的通知；

可以发现，这些窗⼝探测报⽂以 3.4s、6.5s、13.5s 的间隔出现，说明超时时间会翻倍递增。

这连接暂停了 25s，想象⼀下你在打王者的时候，25s 的延迟你还能上王者吗？


### 3.63  在 Wireshark 看到的 Windows size 也就是 " win = "，这个值表示发送窗⼝吗？

这不是发送窗⼝，⽽是在向对⽅声明⾃⼰的**接收窗⼝。**


你可能会好奇，抓包⽂件⾥有「Window size scaling factor」，它其实是算出实际窗⼝⼤⼩的乘法因⼦，
「Window size value」实际上并不是真实的窗⼝⼤⼩，真实窗⼝⼤⼩的计算公式如下：

「Window size value」 * 「Window size scaling factor」 = 「Caculated window size 」


对应的下图案例，也就是 32 * 2048 = 65536。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211184307.jpg)

实际上是 Caculated window size 的值是 Wireshark ⼯具帮我们算好的，Window size scaling factor 和 Windossize value 的值是在 TCP 头部中，其中 Window size scaling factor 是在三次握⼿过程中确定的，如果你抓包的数据没有 TCP 三次握⼿，那可能就⽆法算出真实的窗⼝⼤⼩的值，如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211184440.jpg)



### 3.64 如何在包⾥看出发送窗⼝的⼤⼩？

很遗憾，没有简单的办法，发送窗⼝虽然是由接收窗⼝决定，但是它⼜可以被⽹络因素影响，也就是拥塞窗⼝，实际上发送窗⼝是值是 min(拥塞窗⼝，接收窗⼝)。

### 3.65 发送窗⼝和 MSS 有什么关系？
发送窗⼝决定了⼀⼝⽓能发多少字节，⽽ MSS 决定了这些字节要分多少包才能发完。

举个例⼦，如果发送窗⼝为 16000 字节的情况下，如果 MSS 是 1000 字节，那就需要发送 1600/1000 = 16 个包。

### 3.66 发送⽅在⼀个窗⼝发出 n 个包，是不是需要 n 个 ACK 确认报⽂？
不⼀定，因为 TCP 有累计确认机制，所以当收到多个数据包时，只需要应答最后⼀个数据包的 ACK 报⽂就可以了。


### 3.67 TCP 延迟确认与 Nagle 算法

当我们 TCP 报⽂的承载的数据⾮常⼩的时候，例如⼏个字节，那么整个⽹络的效率是很低的，因为每个 TCP 报⽂中都会有 20 个字节的 TCP 头部，也会有 20 个字节的 IP 头部，⽽数据只有⼏个字节，所以在整个报⽂中有效数据占有的⽐ 就会⾮常低。

这就好像快递员开着⼤货⻋送⼀个⼩包裹⼀样浪费。

那么就出现了常⻅的两种策略，来减少⼩报⽂的传输，分别是

- Nagle 算法

- 延迟确认


### 3.68 Nagle 算法是如何避免⼤量 TCP ⼩数据报⽂的传输？

Nagle 算法做了⼀些策略来避免过多的⼩数据报⽂发送，这可提⾼传输效率。

Nagle 算法的策略：

- 没有已发送未确认报⽂时，⽴刻发送数据。

- 存在未确认报⽂时，直到「没有已发送未确认报⽂」或「数据⻓度达到 MSS ⼤⼩」时，再发送数据。

只要没满⾜上⾯条件中的⼀条，发送⽅⼀直在囤积数据，直到满⾜上⾯的发送条件。


![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211205620.png)


上图右侧启⽤了 Nagle 算法，它的发送数据的过程：

- ⼀开始由于没有已发送未确认的报⽂，所以就⽴刻发了 H 字符；

- 接着，在还没收到对 H 字符的确认报⽂时，发送⽅就⼀直在囤积数据，直到收到了确认报⽂后，此时没有已发送未确认的报⽂，于是就把囤积后的 ELL 字符⼀起发给了接收⽅；

- 待收到对 ELL 字符的确认报⽂后，于是把最后⼀个 O 字符发送了出去

可以看出，Nagle 算法⼀定会有⼀个⼩报⽂，也就是在最开始的时候。

另外，Nagle 算法默认是打开的，如果对于⼀些需要⼩数据包交互的场景的程序，⽐如，telnet 或 ssh 这样的交互性⽐较强的程序，则需要关闭 Nagle 算法。

可以在 Socket 设置 TCP_NODELAY 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应⽤⾃⼰的特点来关闭）。





### 3.69 那延迟确认⼜是什么？

事实上当没有携带数据的 ACK，它的⽹络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP 头，但却没有携带数据报⽂。

为了解决 ACK 传输效率低问题，所以就衍⽣出了 TCP 延迟确认。

TCP 延迟确认的策略：

- 当有响应数据要发送时，ACK 会随着响应数据⼀起⽴刻发送给对⽅

- 当没有响应数据要发送时，ACK 将会延迟⼀段时间，以等待是否有响应数据可以⼀起发送

- 如果在延迟等待发送 ACK 期间，对⽅的第⼆个数据报⽂⼜到达了，这时就会⽴刻发送 ACK



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211211507.png)



延迟等待的时间是在 Linux 内核中定义的，如下图：

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211211621.png)



知道了 HZ 的⼤⼩，那么就可以算出：

- 最⼤延迟确认时间是 200 ms （1000/5）

- 最短延迟确认时间是 40 ms （1000/25）


TCP 延迟确认可以在 Socket 设置 TCP_QUICKACK 选项来关闭这个算法。

![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211211806.png)

### 3.70 延迟确认 和 Nagle 算法混合使⽤时，会产⽣新的问题


当 TCP 延迟确认 和 Nagle 算法混合使⽤时，会导致时耗增⻓，如下图：



![](https://cdn.jsdelivr.net/gh/Gpslypy/mediaImage01@master/img202111/QQ图片20211211211927.png)


发送⽅使⽤了 Nagle 算法，接收⽅使⽤了 TCP 延迟确认会发⽣如下的过程：

- 发送⽅先发出⼀个⼩报⽂，接收⽅收到后，由于延迟确认机制，⾃⼰⼜没有要发送的数据，只能⼲等着发送
⽅的下⼀个报⽂到达；

- ⽽发送⽅由于 Nagle 算法机制，在未收到第⼀个报⽂的确认前，是不会发送后续的数据；

- 所以接收⽅只能等待最⼤时间 200 ms 后，才回 ACK 报⽂，发送⽅收到第⼀个报⽂的确认报⽂后，也才可以发送后续的数据。

很明显，这两个同时使⽤会造成额外的时延，这就会使得⽹络"很慢"的感觉。

要解决这个问题，只有两个办法：

- 要不发送⽅关闭 Nagle 算法

- 要不接收⽅关闭 TCP 延迟确认


### 3.70 tcp_retries1 参数，是什么场景下⽣效？tcp_retries2是不是只受限于规定的次数，还是受限于次数和时间限制的最⼩值？”

tcp_retries1和tcp_retries2都是在TCP三次握⼿之后的场景。

- 当重传次数超过tcp_retries1就会指示 IP 层进⾏ MTU 探测、刷新路由等过程，并不会断开TCP连接，当 传次数超过 tcp_retries2 才会断开TCP流


- tcp_retries1 和 tcp_retries2 两个重传次数都是受⼀个 timeout 值限制的，timeout 的值是根据它俩的值计算出来的，当重传时间超过 timeout，就不会继续重传了，即使次数还没到达。

### 3.71 tcp_orphan_retries也是控制tcp连接的关闭。这个跟tcp_retries1 tcp_retries2有什么区别吗？













































































































































































































